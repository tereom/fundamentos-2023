<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Sección 6 Estimación por máxima verosimilitud | Fundamentos de Estadística con Remuestreo</title>
  <meta name="description" content="Curso de Fundamentos de Estadística con Remuestreo, maestría en Ciencia de Datos, ITAM, Otoño 2023." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Sección 6 Estimación por máxima verosimilitud | Fundamentos de Estadística con Remuestreo" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Curso de Fundamentos de Estadística con Remuestreo, maestría en Ciencia de Datos, ITAM, Otoño 2023." />
  <meta name="github-repo" content="tereom/fundamentos-2023" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Sección 6 Estimación por máxima verosimilitud | Fundamentos de Estadística con Remuestreo" />
  
  <meta name="twitter:description" content="Curso de Fundamentos de Estadística con Remuestreo, maestría en Ciencia de Datos, ITAM, Otoño 2023." />
  

<meta name="author" content="Teresa Ortiz, Alfredo Garbuno, Felipe González" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intervalos-de-confianza-y-remuestreo.html"/>
<link rel="next" href="bootstrap-paramétrico.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Fundamentos de Estadística con Remuestreo</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a>
<ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#plan-semanal"><i class="fa fa-check"></i>Plan semanal</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#evaluación"><i class="fa fa-check"></i>Evaluación</a></li>
<li class="chapter" data-level="0.1" data-path="temario.html"><a href="temario.html#referencias"><i class="fa fa-check"></i><b>0.1</b> Referencias</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html"><i class="fa fa-check"></i><b>1</b> Análisis exploratorio</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#el-papel-de-la-exploración-en-el-análisis-de-datos"><i class="fa fa-check"></i>El papel de la exploración en el análisis de datos</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#preguntas-y-datos"><i class="fa fa-check"></i>Preguntas y datos</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#algunos-conceptos-básicos"><i class="fa fa-check"></i>Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#histogramas"><i class="fa fa-check"></i>Histogramas</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#media-y-desviación-estándar"><i class="fa fa-check"></i>Media y desviación estándar</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#ejemplos"><i class="fa fa-check"></i>Ejemplos</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#precios-de-casas"><i class="fa fa-check"></i>Precios de casas</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#prueba-enlace"><i class="fa fa-check"></i>Prueba Enlace</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#estados-y-calificaciones-en-sat"><i class="fa fa-check"></i>Estados y calificaciones en SAT</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#tablas-de-conteos"><i class="fa fa-check"></i>Tablas de conteos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#suavizamiento-loess"><i class="fa fa-check"></i>Suavizamiento loess</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#opcional-cálculo-del-suavizador"><i class="fa fa-check"></i>Opcional: cálculo del suavizador</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#caso-de-estudio-nacimientos-en-méxico"><i class="fa fa-check"></i>Caso de estudio: nacimientos en México</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#datos-de-natalidad-para-méxico"><i class="fa fa-check"></i>Datos de natalidad para México</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#tendencia"><i class="fa fa-check"></i>Tendencia</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#componente-anual"><i class="fa fa-check"></i>Componente anual</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#día-de-la-semana"><i class="fa fa-check"></i>Día de la semana</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#residuales"><i class="fa fa-check"></i>Residuales</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#reestimación"><i class="fa fa-check"></i>Reestimación</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#análisis-de-componentes"><i class="fa fa-check"></i>Análisis de componentes</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#residuales-antes-y-después-de-2006"><i class="fa fa-check"></i>Residuales: antes y después de 2006</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#otros-días-especiales-más-de-residuales"><i class="fa fa-check"></i>Otros días especiales: más de residuales</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#semana-santa"><i class="fa fa-check"></i>Semana santa</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html"><i class="fa fa-check"></i><b>2</b> Tipos de estudio y experimentos</a>
<ul>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#motivación"><i class="fa fa-check"></i>Motivación</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#proceso-generador-de-datos"><i class="fa fa-check"></i>Proceso Generador de Datos</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#ejemplo-prevalencia-de-anemia"><i class="fa fa-check"></i>Ejemplo: Prevalencia de anemia</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#muestreo-aleatorio"><i class="fa fa-check"></i>Muestreo aleatorio</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#pero-si-no-podemos-hacer-muestreo-aleatorio"><i class="fa fa-check"></i>Pero si no podemos hacer muestreo aleatorio?</a>
<ul>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#ejemplo-policías-y-tráfico"><i class="fa fa-check"></i>Ejemplo: Policías y tráfico</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#el-estimador-estándar"><i class="fa fa-check"></i>El estimador estándar</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#experimentos-tradicionales"><i class="fa fa-check"></i>Experimentos tradicionales</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#bloqueo"><i class="fa fa-check"></i>Bloqueo</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#variables-desconocidas"><i class="fa fa-check"></i>Variables desconocidas</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#aleatorizando-el-tratamiento"><i class="fa fa-check"></i>Aleatorizando el tratamiento</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#selección-de-unidades-y-tratamiento"><i class="fa fa-check"></i>Selección de unidades y tratamiento</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#asignación-natural-del-tratamiento"><i class="fa fa-check"></i>Asignación natural del tratamiento</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>3</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#comparación-con-poblaciones-de-referencia"><i class="fa fa-check"></i>Comparación con poblaciones de referencia</a>
<ul>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#comparando-distribuciones"><i class="fa fa-check"></i>Comparando distribuciones</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#prueba-de-permutaciones-y-el-lineup"><i class="fa fa-check"></i>Prueba de permutaciones y el <em>lineup</em></a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#comparaciones-usando-lineup-continuación"><i class="fa fa-check"></i>Comparaciones usando <em>lineup</em> (continuación)</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#prueba-de-permutaciones-para-proporciones"><i class="fa fa-check"></i>Prueba de permutaciones para proporciones</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis-tradicionales"><i class="fa fa-check"></i>Pruebas de hipótesis tradicionales</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tomadores-de-té-continuación"><i class="fa fa-check"></i>Tomadores de té (continuación)</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-permutación-implementación."><i class="fa fa-check"></i>Pruebas de permutación: implementación.</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo-tiempos-de-fusión"><i class="fa fa-check"></i>Ejemplo: tiempos de fusión</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo-tiempos-de-fusión-continuación"><i class="fa fa-check"></i>Ejemplo: tiempos de fusión (continuación)</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#separación-de-grupos"><i class="fa fa-check"></i>Separación de grupos</a>
<ul>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#avispas-opcional"><i class="fa fa-check"></i>Avispas (opcional)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#la-crisis-de-replicabilidad"><i class="fa fa-check"></i>La “crisis de replicabilidad”</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-jardín-de-los-senderos-que-se-bifurcan"><i class="fa fa-check"></i>El jardín de los senderos que se bifurcan</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo-decisiones-de-análisis-y-valores-p"><i class="fa fa-check"></i>Ejemplo: decisiones de análisis y valores <em>p</em></a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#alternativas-o-soluciones"><i class="fa fa-check"></i>Alternativas o soluciones</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html"><i class="fa fa-check"></i><b>4</b> Estimación y distribución de muestreo</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-precios-de-casas"><i class="fa fa-check"></i>Ejemplo: precios de casas</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#distribución-de-muestreo"><i class="fa fa-check"></i>Distribución de muestreo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#más-ejemplos"><i class="fa fa-check"></i>Más ejemplos</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#el-error-estándar"><i class="fa fa-check"></i>El error estándar</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-valor-de-casas"><i class="fa fa-check"></i>Ejemplo: valor de casas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#calculando-la-distribución-de-muestreo"><i class="fa fa-check"></i>Calculando la distribución de muestreo</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-1"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#teorema-central-del-límite"><i class="fa fa-check"></i>Teorema central del límite</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#normalidad-y-gráficas-de-cuantiles-normales"><i class="fa fa-check"></i>Normalidad y gráficas de cuantiles normales</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#prueba-de-hipótesis-de-normalidad"><i class="fa fa-check"></i>Prueba de hipótesis de normalidad</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-3"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-4"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-5"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#más-del-teorema-central-del-límite"><i class="fa fa-check"></i>Más del Teorema central del límite</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html"><i class="fa fa-check"></i><b>5</b> Intervalos de confianza y remuestreo</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-introductorio"><i class="fa fa-check"></i>Ejemplo introductorio</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#la-idea-del-bootstrap"><i class="fa fa-check"></i>La idea del bootstrap</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#el-principio-de-plug-in"><i class="fa fa-check"></i>El principio de plug-in</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-6"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#discusión-propiedades-de-la-distribución-bootstrap"><i class="fa fa-check"></i>Discusión: propiedades de la distribución bootstrap</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-7"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#variación-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#error-estándar-bootstrap-e-intervalos-normales"><i class="fa fa-check"></i>Error estándar bootstrap e intervalos normales</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-tomadores-de-té-negro"><i class="fa fa-check"></i>Ejemplo: tomadores de té negro</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-inventario-de-casas-vendidas"><i class="fa fa-check"></i>Ejemplo: inventario de casas vendidas</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#calibración-de-intervalos-de-confianza"><i class="fa fa-check"></i>Calibración de intervalos de confianza</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#interpretación-de-intervalos-de-confianza"><i class="fa fa-check"></i>Interpretación de intervalos de confianza</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#sesgo"><i class="fa fa-check"></i>Sesgo</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#intervalos-bootstrap-de-percentiles"><i class="fa fa-check"></i>Intervalos bootstrap de percentiles</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-8"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-para-dos-muestras"><i class="fa fa-check"></i>Bootstrap para dos muestras</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-9"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#datos-pareados"><i class="fa fa-check"></i>Datos pareados</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-y-otras-estadísticas"><i class="fa fa-check"></i>Bootstrap y otras estadísticas</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-estimadores-de-razón"><i class="fa fa-check"></i>Ejemplo: estimadores de razón</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-suavizadores"><i class="fa fa-check"></i>Ejemplo: suavizadores</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-y-estimadores-complejos-tablas-de-perfiles"><i class="fa fa-check"></i>Bootstrap y estimadores complejos: tablas de perfiles</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-y-muestras-complejas"><i class="fa fa-check"></i>Bootstrap y muestras complejas</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-en-r"><i class="fa fa-check"></i>Bootstrap en R</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#conclusiones-y-observaciones"><i class="fa fa-check"></i>Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html"><i class="fa fa-check"></i><b>6</b> Estimación por máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#introducción-a-estimación-por-máxima-verosimilitud"><i class="fa fa-check"></i>Introducción a estimación por máxima verosimilitud</a></li>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#máxima-verosimilitud-para-observaciones-continuas"><i class="fa fa-check"></i>Máxima verosimilitud para observaciones continuas</a></li>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#aspectos-numéricos"><i class="fa fa-check"></i>Aspectos numéricos</a></li>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#máxima-verosimilitud-para-más-de-un-parámetro"><i class="fa fa-check"></i>Máxima verosimilitud para más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html"><i class="fa fa-check"></i><b>7</b> <em>Bootstrap</em> paramétrico</a>
<ul>
<li class="chapter" data-level="" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html#ventajas-y-desventajas-de-bootstrap-paramétrico"><i class="fa fa-check"></i>Ventajas y desventajas de <em>bootstrap</em> paramétrico</a></li>
<li class="chapter" data-level="" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html#verificando-los-supuestos-distribucionales"><i class="fa fa-check"></i>Verificando los supuestos distribucionales</a></li>
<li class="chapter" data-level="" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html#modelos-mal-identificados"><i class="fa fa-check"></i>Modelos mal identificados</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html"><i class="fa fa-check"></i><b>8</b> Propiedades teóricas de MLE</a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-10"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#consistencia"><i class="fa fa-check"></i>Consistencia</a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-11"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#equivarianza-del-textsfmle"><i class="fa fa-check"></i>Equivarianza del <span class="math inline">\(\textsf{MLE}\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-12"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#normalidad-asintótica"><i class="fa fa-check"></i>Normalidad asintótica</a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-información-de-fisher"><i class="fa fa-check"></i>Ejemplo: Información de Fisher</a></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-normalidad"><i class="fa fa-check"></i>Ejemplo: Normalidad</a></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#el-método-delta"><i class="fa fa-check"></i>El método delta</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#optimalidad-del-textsfmle"><i class="fa fa-check"></i>Optimalidad del <span class="math inline">\(\textsf{MLE}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html"><i class="fa fa-check"></i><b>9</b> Más de pruebas de hipótesis e intervalos</a>
<ul>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#prueba-de-wald"><i class="fa fa-check"></i>Prueba de Wald</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#observación-pruebas-t-y-práctica-estadística"><i class="fa fa-check"></i>Observación: pruebas <span class="math inline">\(t\)</span> y práctica estadística</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#prueba-de-wald-para-dos-medias-o-proporciones"><i class="fa fa-check"></i>Prueba de Wald para dos medias o proporciones</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#datos-pareados-1"><i class="fa fa-check"></i>Datos pareados</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#pruebas-de-cociente-de-verosimilitud"><i class="fa fa-check"></i>Pruebas de cociente de verosimilitud</a>
<ul>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#distribución-de-referencia-para-pruebas-de-cocientes"><i class="fa fa-check"></i>Distribución de referencia para pruebas de cocientes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#otro-tipo-de-pruebas"><i class="fa fa-check"></i>Otro tipo de pruebas</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#errores-tipo-i-y-tipo-ii"><i class="fa fa-check"></i>Errores tipo I y tipo II</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#consideraciones-prácticas"><i class="fa fa-check"></i>Consideraciones prácticas</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#pruebas-múltiples"><i class="fa fa-check"></i>Pruebas múltiples</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html"><i class="fa fa-check"></i><b>10</b> Introducción a inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#un-primer-ejemplo-completo-de-inferencia-bayesiana"><i class="fa fa-check"></i>Un primer ejemplo completo de inferencia bayesiana</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-estimando-una-proporción"><i class="fa fa-check"></i>Ejemplo: estimando una proporción</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-observaciones-uniformes"><i class="fa fa-check"></i>Ejemplo: observaciones uniformes</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#probabilidad-a-priori"><i class="fa fa-check"></i>Probabilidad a priori</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#análisis-conjugado"><i class="fa fa-check"></i>Análisis conjugado</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-13"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#pasos-de-un-análisis-de-datos-bayesiano"><i class="fa fa-check"></i>Pasos de un análisis de datos bayesiano</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#verificación-predictiva-posterior"><i class="fa fa-check"></i>Verificación predictiva posterior</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-estaturas-de-tenores"><i class="fa fa-check"></i>Ejemplo: estaturas de tenores</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-modelo-poisson"><i class="fa fa-check"></i>Ejemplo: modelo Poisson</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#predicción"><i class="fa fa-check"></i>Predicción</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-cantantes"><i class="fa fa-check"></i>Ejemplo: cantantes</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-posterior-predictiva-de-pareto-uniforme."><i class="fa fa-check"></i>Ejemplo: posterior predictiva de Pareto-Uniforme.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html"><i class="fa fa-check"></i><b>11</b> Calibración bayesiana y Regularización</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#enfoque-bayesiano-y-frecuentista"><i class="fa fa-check"></i>Enfoque bayesiano y frecuentista</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-estimación-de-una-proporción"><i class="fa fa-check"></i>Ejemplo: estimación de una proporción</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#intervalos-de-agresti-coull"><i class="fa fa-check"></i>Intervalos de Agresti-Coull</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#incorporando-información-inicial"><i class="fa fa-check"></i>Incorporando información inicial</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-porporción-de-hogares-de-ingresos-grandes"><i class="fa fa-check"></i>Ejemplo: porporción de hogares de ingresos grandes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#inferencia-bayesiana-y-regularización"><i class="fa fa-check"></i>Inferencia bayesiana y regularización</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-modelo-normal-y-estaturas"><i class="fa fa-check"></i>Ejemplo: modelo normal y estaturas</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-estimación-de-proporciones"><i class="fa fa-check"></i>Ejemplo: estimación de proporciones</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#teoría-de-decisión"><i class="fa fa-check"></i>Teoría de decisión</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-riesgo-frecuentista"><i class="fa fa-check"></i>Ejemplo: riesgo frecuentista</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-riesgo-posterior"><i class="fa fa-check"></i>Ejemplo: riesgo posterior</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#riesgo-de-bayes"><i class="fa fa-check"></i>Riesgo de Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-14"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html"><i class="fa fa-check"></i><b>12</b> Métodos de Cadenas de Markov Monte Carlo</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#integrales-mediante-subdivisiones"><i class="fa fa-check"></i>Integrales mediante subdivisiones</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-estimación-de-una-proporción-1"><i class="fa fa-check"></i>Ejemplo: estimación de una proporción</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#más-de-un-parámetro"><i class="fa fa-check"></i>Más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#métodos-monte-carlo"><i class="fa fa-check"></i>Métodos Monte Carlo</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-15"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-varias-pruebas-independientes"><i class="fa fa-check"></i>Ejemplo: varias pruebas independientes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#simulando-de-la-posterior"><i class="fa fa-check"></i>Simulando de la posterior</a></li>
<li class="chapter" data-level="12.1" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-de-islas"><i class="fa fa-check"></i><b>12.1</b> Ejemplo de islas</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#por-qué-funciona-metrópolis"><i class="fa fa-check"></i>¿Por qué funciona Metrópolis?</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#método-de-metrópolis"><i class="fa fa-check"></i>Método de Metrópolis</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ajustando-el-tamaño-de-salto"><i class="fa fa-check"></i>Ajustando el tamaño de salto</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-16"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#metrópolis-con-varios-parámetros"><i class="fa fa-check"></i>Metrópolis con varios parámetros</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-el-modelo-normal"><i class="fa fa-check"></i>Ejemplo: el modelo normal</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-observaciones-normales-no-conjugado"><i class="fa fa-check"></i>Ejemplo: observaciones normales, no conjugado</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-exámenes"><i class="fa fa-check"></i>Ejemplo: exámenes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#muestreador-de-gibbs"><i class="fa fa-check"></i>Muestreador de Gibbs</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-dos-proporciones"><i class="fa fa-check"></i>Ejemplo: dos proporciones</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-modelo-normal-no-conjugado"><i class="fa fa-check"></i>Ejemplo: Modelo normal no conjugado</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-17"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#conclusiones-y-observaciones-metrópolis-y-gibbs"><i class="fa fa-check"></i>Conclusiones y observaciones Metrópolis y Gibbs</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#hmc-y-stan"><i class="fa fa-check"></i>HMC y Stan</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#diagnósticos-generales-para-mcmc"><i class="fa fa-check"></i>Diagnósticos generales para MCMC</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#representatividad"><i class="fa fa-check"></i>Representatividad</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#precisión"><i class="fa fa-check"></i>Precisión</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#eficiencia"><i class="fa fa-check"></i>Eficiencia</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#recomendaciones-generales"><i class="fa fa-check"></i>Recomendaciones generales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html"><i class="fa fa-check"></i>Apéndice: Principios de visualizacion</a>
<ul>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#el-cuarteto-de-anscombe"><i class="fa fa-check"></i>El cuarteto de Anscombe</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#introducción"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#visualización-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#teoría-de-visualización-de-datos"><i class="fa fa-check"></i>Teoría de visualización de datos</a>
<ul>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#principios-generales-del-diseño-analítico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#técnicas-de-visualización"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#indicadores-de-calidad-gráfica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#factor-de-engaño-y-chartjunk"><i class="fa fa-check"></i>Factor de engaño y Chartjunk</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#pequeños-múltiplos-y-densidad-gráfica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#decoración"><i class="fa fa-check"></i>Decoración</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#percepción-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#ejemplo-gráfica-de-minard"><i class="fa fa-check"></i>Ejemplo: gráfica de Minard</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a>
<ul>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html#análisis-exploratorio-1"><i class="fa fa-check"></i>1. Análisis Exploratorio</a></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html#análisis-exploratorio---loess"><i class="fa fa-check"></i>2. Análisis Exploratorio - loess</a></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html#tipos-de-estudio-y-pgd"><i class="fa fa-check"></i>3. Tipos de estudio y PGD</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias-1.html"><a href="referencias-1.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/tereom/fundamentos-2023" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Estadística con Remuestreo</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimación-por-máxima-verosimilitud" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Sección 6</span> Estimación por máxima verosimilitud<a href="estimación-por-máxima-verosimilitud.html#estimación-por-máxima-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Los ejemplos que hemos visto han sido todos de estimadores <em>plug-in</em> (o por sustitución):
si queremos saber una cantidad poblacional, y tenemos una muestra dada, entonces
calculamos la estadística de interés <em>como si la muestra fuera la población</em>. Por ejemplo,
para estimar la mediana poblacional usamos la mediana muestral, si queremos estimar
la media poblacional usamos la media muestral, y así sucesivamente. Estos estimadores
usualmente dan resultados razonables (pero hay que checar usando muestra bootstraps, por ejemplo,
y pensar lo que estamos haciendo).</p>
<p>Cuando sabemos más acerca de la población y usamos un modelo teórico es posible
hacer más: dependiendo de qué cantidades se quieren estimar, podemos construir estimadores
que sean <em>óptimos</em> en algún sentido siempre y cuando se cumplan los supuestos teóricos, como veremos ahora.</p>
<p>Por ejemplo: ¿deberíamos estimar el centro de una distribución simétrica con la
media o con la mediana, o quizá con una media recortada?</p>
<p>En esta parte construiremos la teoría básica de estimación cuando trabajamos con
modelos teóricos conocidos. El objetivo es entender <strong>las ideas básicas</strong> de estos procedimientos,
y cómo evaluar sus resultados.</p>
<p><strong>Recordatorio</strong>: las ventajas de usar modelos teóricos para describir distribuciones de
datos está en que es posible comprimir más eficientemente la información, es posible construir
modelos más complejos juntando varios de estos modelos y de sus dependencias, y de que es
posible hacer más teoría útil que nos guíe. La desventaja es que es necesario que esos supuestos teóricos sean razonables.</p>
<div id="introducción-a-estimación-por-máxima-verosimilitud" class="section level2 unnumbered hasAnchor">
<h2>Introducción a estimación por máxima verosimilitud<a href="estimación-por-máxima-verosimilitud.html#introducción-a-estimación-por-máxima-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Uno de los procedimientos más estándar en esta situación es el <strong>método
de máxima verosimilitud</strong>. Los estimadores de máxima verosimilitud tienen propiedades
convenientes, y dan en general resultados razonables siempre y cuando los supuestos
sean razonables.</p>
<p><strong>Máxima verosimilitud es un proceso intuitivo, y consiste en aprender o estimar valores de parámetros desconocidos suponiendo para los datos su explicación más probable</strong>. Para
esto, usando supuestos y modelos, requeriremos calcular la probabilidad de un conjunto
de observaciones.</p>
<p><strong>Ejemplo.</strong> Adaptado de <span class="citation">(<a href="#ref-Chihara" role="doc-biblioref">Chihara and Hesterberg 2018</a>)</span>. Supongamos que una máquina produce dos tipos de bolsas de 25 galletas: la mitad de las veces produce una bolsa con 5 galletas de avena y 20 de chispas de chocolate, y
la otra mitad produce bolsas con 23 galletas de avena y 2 de chispas de chocolate.</p>
<p>Tomamos una bolsa, y no sabemos qué tipo de bolsa es (parámetro desconocido). Extraemos al azar una de las galletas, y es de chispas de chocolate (observación).</p>
<p>Por máxima verosimilitud, inferimos que la bolsa que estamos considerando tiene 5 galletas de avena. Esto es porque es más probable observar una galleta de chispas en las bolsas que contienen 5 galletas de avena que en las bolsas que contienen 23 galletas de avena. Podemos cuantificar la probabilidad que “acertemos” en nuestra inferencia.</p>
<p>Cómo se aprecia en el ejemplo anterior, el esquema general es:</p>
<ol style="list-style-type: decimal">
<li>Existe un proceso del que podemos obtener observaciones de algún sistema
o población real.</li>
<li>Tenemos un modelo probabilístico que dice cómo se producen esas observaciones a partir del sistema o población real.</li>
<li>Usualmente este modelo tiene algunas cantidades que no conocemos, que rigen el proceso y cómo se relaciona el proceso con las observaciones.</li>
</ol>
<p>Nuestro propósito es:</p>
<ol start="4" style="list-style-type: decimal">
<li>Extraemos observaciones del proceso<br />
<span class="math display">\[x_1, x_2, \ldots, x_n.\]</span></li>
<li>Queremos aprender de los parámetros desconocidos del proceso para calcular cantidades de interés acerca del sistema o población real</li>
</ol>
<p>En principio, los modelos que consideramos pueden ser complicados y tener varias partes o parámetros. Veamos primero un ejemplo clásico con un solo parámetro, y cómo lo resolveríamos
usando máxima verosimilitud.</p>
<p><strong>Nota</strong>: Cuando decimos <em>muestra</em> en general nos referimos a observaciones
independientes obtenidas del mismo proceso (ver la sección de distribución de muestreo) para ver qué
significa que sea independientes. Este esquema es un supuesto
que simplifica mucho los cálculos, como discutimos antes. Muchas veces este supuesto
sale del diseño de la muestra o del estudio, pero en todo caso es importante considerar
si es razonable o no para nuestro problema particular.</p>
<div class="mathblock">
<p>
Denotemos por <span class="math inline"><span class="math inline">\(f(x; \theta)\)</span></span> la
función de densidad para una variable aleatoria continua con párametro
asociado <span class="math inline"><span class="math inline">\(\theta.\)</span></span> Denotamos por
<span class="math inline"><span class="math inline">\(X_1, \ldots, X_n,\)</span></span> una muestra
aleatoria de <span class="math inline"><span class="math inline">\(n\)</span></span> observaciones de
esta distribución y por <span class="math inline"><span class="math inline">\(x_1, \ldots, x_n\)</span></span> los valores observados de esta muestra aleatoria.
</p>
</div>
<p><strong>Ejemplo.</strong> Supongamos que queremos saber qué proporción de registros de una base de datos tiene algún error menor de captura. No podemos revisar todos los registros, así que tomamos una muestra
de 8 registros, escogiendo uno por uno al azar de manera independiente. Revisamos los
8 registros, y obtenemos los siguientes datos:</p>
<p><span class="math display">\[x_1 = 0, x_2 = 1, x_3 = 0, x_4 = 0, x_5 =1, x_6 =0, x_7 =0, x_8 =0\]</span></p>
<p>donde 1 indica un error menor. Encontramos dos errores menores. ¿Cómo estimamos el número de
registros con errores leves en la base de datos?</p>
<p>Ya sabemos una respuesta razonable para nuestro estimador puntual, que sería <span class="math inline">\(\hat{p}=2/8=0.25\)</span>.
Veamos cómo se obtendría por máxima verosimilitud.</p>
<p>Según el proceso con el que se construyó la muestra, debemos dar una probabilidad de observar
los 2 errores en 8 registros. Supongamos que en realidad existe una proporción <span class="math inline">\(p\)</span>
de que un registro tenga un error. Entonces calculamos</p>
<p>Probabilidad de observar la muestra:</p>
<p><span class="math display">\[P(X_1 = 0, X_2 = 1, X_3 = 0, X_4 = 0, X_5 =1, X_6 =0, X_7 =0, X_8 =0)\]</span></p>
<p>es igual a</p>
<p><span class="math display">\[P(X_1 = 0)P(X_2 = 1)P(X_3 = 0)P( X_4 = 0)P(X_5 =1)P(X_6 =0)P(X_7 =0)P(X_8 =0)\]</span>
pues la probabilidad de que cada observación sea 0 o 1 no depende de las observaciones restantes (la muestra se extrajo de manera independiente).</p>
<p>Esta última cantidad tiene un parámetro que no conocemos: la proporcion <span class="math inline">\(p\)</span> de registros
con errores. Así que lo denotamos como una cantidad desconocida <span class="math inline">\(p\)</span>. Nótese
entonces que <span class="math inline">\(P(X_2=1) = p\)</span>, <span class="math inline">\(P(X_3=0) = 1-p\)</span> y así sucesivamente, así que la cantidad
de arriba es igual a</p>
<p><span class="math display">\[(1-p)p(1-p)(1-p)p(1-p)(1-p)(1-p) \]</span></p>
<p>que se simplifica a</p>
<p><span class="math display">\[ \mathcal{L}(p) = p^2(1-p)^6\]</span></p>
<p>Ahora la idea es <strong>encontrar la p que maximiza la probabilidad de lo que observamos</strong>. En
este caso se puede hacer con cálculo, pero vamos a ver una gráfica de esta función y
cómo resolverla de manera numérica.</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="estimación-por-máxima-verosimilitud.html#cb279-1" aria-hidden="true" tabindex="-1"></a>verosimilitud <span class="ot">&lt;-</span> <span class="cf">function</span>(p){</span>
<span id="cb279-2"><a href="estimación-por-máxima-verosimilitud.html#cb279-2" aria-hidden="true" tabindex="-1"></a>  p<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span><span class="dv">6</span></span>
<span id="cb279-3"><a href="estimación-por-máxima-verosimilitud.html#cb279-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb279-4"><a href="estimación-por-máxima-verosimilitud.html#cb279-4" aria-hidden="true" tabindex="-1"></a>dat_verosim <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">prob =</span> <span class="fu">map_dbl</span>(x, verosimilitud))</span>
<span id="cb279-5"><a href="estimación-por-máxima-verosimilitud.html#cb279-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat_verosim, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> prob)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb279-6"><a href="estimación-por-máxima-verosimilitud.html#cb279-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.25</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb279-7"><a href="estimación-por-máxima-verosimilitud.html#cb279-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;p&quot;</span>)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Nótese que esta gráfica:</p>
<ul>
<li>Depende de los datos, que pensamos fijos.</li>
<li>Cuando cambiamos la <span class="math inline">\(p\)</span>, la probabilidad de observar la muestra cambia. Nos interesa
ver las regiones donde la probabilidad es relativamente alta.</li>
<li>El máximo está en 0.25.</li>
<li>Así que el estimador de máxima verosimilitud es <span class="math inline">\(\hat{p} = 0.25\)</span>, <strong>que es también
el estimador usual de plugin</strong> en este caso.</li>
</ul>
<p>Para uniformizar la notación con el caso continuo que veremos más adelante, usaremos
la notación</p>
<p><span class="math display">\[P(X=x) = f(x)\]</span>
donde <span class="math inline">\(f\)</span> es la función de densidad (en este caso, función de masa de probabilidad) de <span class="math inline">\(X\)</span>. Si esta función depende
de un parámetro, escribimos <span class="math display">\[f(x ;\theta)\]</span></p>
<div class="mathblock">
<p>
<strong>Definición.</strong> Sean <span class="math inline"><span class="math inline">\(X_1, \ldots, X_n\)</span></span> una muestra de una densidad <span class="math inline"><span class="math inline">\(f(x; \theta)\)</span></span> y sean <span class="math inline"><span class="math inline">\(x_1,x_2,\ldots, x_n\)</span></span> los valores
observados.
</p>
<p>
La <em>función de verosimilitud</em> del párametro de interés <span class="math inline"><span class="math inline">\(\theta\)</span></span> está definida por <span class="math display"><span class="math display">\[\begin{align}
\mathcal{L}(\theta; x_1, \ldots, x_n) = \prod_{i = 1}^n f(x_i; \theta).
\end{align}\]</span></span>
</p>
<p>
Esta función nos dice qué tan creible es el valor del parámetro <span class="math inline"><span class="math inline">\(\theta\)</span></span> dada la muestra observada. A veces
también la denotamos por <span class="math inline"><span class="math inline">\(\mathcal{L}_n(\theta)\)</span></span>.
</p>
</div>
<p>Ahora definimos qué es un estimador de máxima verosimilitud.</p>
<div class="mathblock">
<p>
<strong>Definición.</strong> Un estimador de máxima verosimilitud lo
denotamos por <span class="math inline"><span class="math inline">\(\hat \theta_{\textsf{MLE}}\)</span></span> y es un valor que satisface <span class="math display"><span class="math display">\[\begin{align}
\hat \theta_{\textsf{MLE}} =  \underset{\theta \, \in \,
\Theta}{\arg\max}\,  \mathcal{L}(\theta; x_1, \ldots, x_n),
\end{align}\]</span></span> donde <span class="math inline"><span class="math inline">\(\Theta\)</span></span>
denota el espacio parametral. Es decir, el espacio válido de búsqueda
congruente con la definición del modelo.
</p>
</div>
<div class="ejercicio">
<ul>
<li>
Considera el caso de una normal con media y varianza desconocidas.
¿Cuáles son los espacios parametrales para efectuar <span class="math inline"><span class="math inline">\(\mathsf{MLE}\)</span></span>?
</li>
<li>
Considera el caso de una Binomial con parámetro <span class="math inline"><span class="math inline">\(p\)</span></span> desconocidos. ¿Cuál es el espacio
parametral para la búsqueda del <span class="math inline"><span class="math inline">\(\mathsf{MLE}\)</span></span>?
</li>
</ul>
</div>
<p>Obsérvese que para construir la verosimilitud y en consecuencia buscar por
estimadores de máxima verosimlitud necesitamos:</p>
<ul>
<li>Un modelo teórico de cómo es la población con parámetros e<br />
</li>
<li>Información de cómo se extrajo la muestra,</li>
</ul>
<p>y entonces podemos resolver nuestro problema de estimación
convirtiéndolo en uno de optimización.</p>
<p>Probamos esta idea con un proceso más complejo.</p>
<p><strong>Ejemplo.</strong> Supongamos que una máquina puede estar funcionando correctamente o no en cada
corrida. Cada corrida se producen 500 productos, y se muestrean 10 para
detectar defectos. Cuando la máquina funciona correctamente, la tasa de defectos
es de 3%. Cuando la máquina no está funcionando correctamente la tasa de defectos
es de 20%</p>
<p>Supongamos que escogemos al azar 11 corridas, y obervamos los siguientes
número de defectuosos:</p>
<p><span class="math display">\[1, 0, 0, 3 ,0, 0, 0, 2, 1, 0, 0\]</span></p>
<p>La pregunta es: ¿qué porcentaje del tiempo la máquina está funcionando correctamente?</p>
<p>Primero pensemos en una corrida. La probabilidad de observar una sucesión particular de
<span class="math inline">\(r\)</span> defectos es</p>
<p><span class="math display">\[0.03^r(0.97)^{(10-r)}\]</span>
cuando la máquina está funcionando correctamente.</p>
<p>Si la máquina está fallando, la misma probabilidad es</p>
<p><span class="math display">\[0.2^r(0.8)^{(10-r)}.\]</span></p>
<p>Ahora supongamos que la máquina trabaja
correctamente en una proporción <span class="math inline">\(p\)</span> de las corridas. Entonces la probabilidad
de observar <span class="math inline">\(r\)</span> fallas se calcula promediando (probabilidad
total) sobre las probabilidades de que la máquina esté funcionando
bien o no:</p>
<p><span class="math display">\[0.03^r(0.97)^{(10-r)}p + 0.2^r(0.8)^{(10-r)}(1-p)\]</span>
Y esta es nuestra función de verosimilitud para una observación.</p>
<p>Suponemos que las <span class="math inline">\(r_1,r_2, \ldots, r_{11}\)</span> observaciones son independientes
(por ejemplo, después de cada corrida la máquina se prepara de una manera estándar,
y es como si el proceso comenzara otra vez). Entonces tenemos que multiplicar
estas probabilidades para cada observación <span class="math inline">\(r_1\)</span>:</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="estimación-por-máxima-verosimilitud.html#cb280-1" aria-hidden="true" tabindex="-1"></a>calc_verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(r){</span>
<span id="cb280-2"><a href="estimación-por-máxima-verosimilitud.html#cb280-2" aria-hidden="true" tabindex="-1"></a>  q_func <span class="ot">&lt;-</span> <span class="fl">0.03</span> <span class="sc">^</span> r <span class="sc">*</span> (<span class="fl">0.97</span>) <span class="sc">^</span> (<span class="dv">10</span> <span class="sc">-</span> r)</span>
<span id="cb280-3"><a href="estimación-por-máxima-verosimilitud.html#cb280-3" aria-hidden="true" tabindex="-1"></a>  q_falla <span class="ot">&lt;-</span> <span class="fl">0.2</span> <span class="sc">^</span> r <span class="sc">*</span> (<span class="fl">0.8</span>) <span class="sc">^</span> (<span class="dv">10</span> <span class="sc">-</span> r)</span>
<span id="cb280-4"><a href="estimación-por-máxima-verosimilitud.html#cb280-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(p){</span>
<span id="cb280-5"><a href="estimación-por-máxima-verosimilitud.html#cb280-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#nota: esta no es la mejor manera de calcularlo, hay </span></span>
<span id="cb280-6"><a href="estimación-por-máxima-verosimilitud.html#cb280-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># que usar logaritmos.</span></span>
<span id="cb280-7"><a href="estimación-por-máxima-verosimilitud.html#cb280-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prod</span>(p <span class="sc">*</span> q_func <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">*</span> q_falla)</span>
<span id="cb280-8"><a href="estimación-por-máxima-verosimilitud.html#cb280-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb280-9"><a href="estimación-por-máxima-verosimilitud.html#cb280-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb280-10"><a href="estimación-por-máxima-verosimilitud.html#cb280-10" aria-hidden="true" tabindex="-1"></a>verosim <span class="ot">&lt;-</span> <span class="fu">calc_verosim</span>(<span class="at">r =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb280-11"><a href="estimación-por-máxima-verosimilitud.html#cb280-11" aria-hidden="true" tabindex="-1"></a><span class="fu">verosim</span>(<span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] 2.692087e-14</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="estimación-por-máxima-verosimilitud.html#cb282-1" aria-hidden="true" tabindex="-1"></a>dat_verosim <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb282-2"><a href="estimación-por-máxima-verosimilitud.html#cb282-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prob =</span> <span class="fu">map_dbl</span>(x, verosim))</span>
<span id="cb282-3"><a href="estimación-por-máxima-verosimilitud.html#cb282-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat_verosim, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> prob)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb282-4"><a href="estimación-por-máxima-verosimilitud.html#cb282-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.773</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb282-5"><a href="estimación-por-máxima-verosimilitud.html#cb282-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;prop funcionado&quot;</span>)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y nuestra estimación puntual sería de alrededor de 80%.</p>
</div>
<div id="máxima-verosimilitud-para-observaciones-continuas" class="section level2 unnumbered hasAnchor">
<h2>Máxima verosimilitud para observaciones continuas<a href="estimación-por-máxima-verosimilitud.html#máxima-verosimilitud-para-observaciones-continuas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando las observaciones <span class="math inline">\(x_1,\ldots, x_n\)</span> provienen de una distribución
continua, no tiene sentido considerar <span class="math inline">\(P(X = x_i)\)</span>, pues siempre es igual
a cero.</p>
<p>Sin embargo, podemos
escribir para pequeños valores <span class="math inline">\(\epsilon \ll 1\)</span>
<span class="math display">\[\begin{align}
  P(x - \epsilon &lt; X &lt; x + \epsilon | \theta) = \int_{x - \epsilon}^{x + \epsilon} f(t; \theta) \, \text{d} t \approx 2 \epsilon f(x; \theta),
\end{align}\]</span>
donde <span class="math inline">\(f(x; \theta)\)</span> es la función de densidad de <span class="math inline">\(X.\)</span> Por lo tanto,
<span class="math display">\[\begin{align}
\begin{split}
  P&amp;(x_1 - \epsilon &lt; X_1 &lt; x_1 + \epsilon, \ldots, x_n - \epsilon &lt; X_n &lt; x_n + \epsilon | \theta) \\
  &amp;= \prod_{i = 1}^n P(x_i - \epsilon &lt; X_i &lt; x_i + \epsilon | \theta) \\
  &amp;= \prod_{i = 1}^n 2 \epsilon f(x_i; \theta) = (2\epsilon)^n \prod_{i = 1}^n f(x_i; \theta).
\end{split}
\end{align}\]</span></p>
<p>Notemos que si <span class="math inline">\(\epsilon \rightarrow 0\)</span> la ecuación rápidamente converge a cero. Pero para pequeños
valores de <span class="math inline">\(\epsilon\)</span> la ecuación que nos interesa es proporcional a <span class="math inline">\(\prod_{i = 1}^n f(x_i; \theta).\)</span></p>
<p>De esta forma, nuestra definición de máxima verosimilitud y estimadores
de máxima verosimilitud es la misma para el caso continuo (verifica las definiciones
de la sección anterior).</p>
<p><strong>Ejemplo.</strong> Supongamos que tenemos una muestra <span class="math inline">\(x_1\ldots, x_n\)</span> extraidas de una distribución
exponencial con tasa <span class="math inline">\(\lambda&gt;0\)</span> donde no conocemos <span class="math inline">\(\lambda\)</span>. ¿Cuál es
el estimador de máxima verosimilitud de <span class="math inline">\(\lambda\)</span>?</p>
<p>Para <span class="math inline">\(\lambda&gt;0\)</span>, tenemos que</p>
<p><span class="math display">\[{\mathcal L}(\lambda) = \prod_{i=1}^n \lambda e^{-\lambda x_i}\]</span>
de modo que</p>
<p><span class="math display">\[{\mathcal L}(\lambda) = \lambda^n e^{-\lambda \sum_{i=1}^nx_i} = \lambda^n e^{-n\lambda\bar{x}} = e^{n(\log\lambda - \lambda\bar{x})}\]</span>
Que podemos maximizar usando cálculo para obtener
<span class="math inline">\(\hat{\lambda}_{\mathsf{ML}} = \frac{1}{\bar{x}}\)</span> (demuéstralo). Discute
por qué esto es intuitivamente razonable: ¿cuál es
el valor esperado de una exponencial con parámetro <span class="math inline">\(\lambda\)</span>?</p>
</div>
<div id="aspectos-numéricos" class="section level2 unnumbered hasAnchor">
<h2>Aspectos numéricos<a href="estimación-por-máxima-verosimilitud.html#aspectos-numéricos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Encontrar el estimador de máxima verosimilitud (<span class="math inline">\(\textsf{MLE}\)</span>) es automático en la mayoría de los casos.
En teoría, podemos reutilizar la misma rutina numérica para encontrar el estimador sin ninguna ayuda de la analista.
Esto contrasta con otras técnicas de estimación en donde se requieren cálculos y manipulación de ecuaciones.</p>
<p>Sin embargo, hay situaciones que se pueden evitar de manera general. Por ejemplo, cuando calculamos la verosimilitud arriba, nótese que estamos multiplicando
números que pueden ser muy chicos (por ejemplo <span class="math inline">\(p^6\)</span>, etc). Esto puede producir
desbordes numéricos fácilmente. Por ejemplo para un tamaño de muestra de 1000, podríamos
tener que calcular</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="estimación-por-máxima-verosimilitud.html#cb283-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.1</span></span>
<span id="cb283-2"><a href="estimación-por-máxima-verosimilitud.html#cb283-2" aria-hidden="true" tabindex="-1"></a>proba <span class="ot">&lt;-</span> (p <span class="sc">^</span> <span class="dv">800</span>)<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span><span class="dv">200</span></span>
<span id="cb283-3"><a href="estimación-por-máxima-verosimilitud.html#cb283-3" aria-hidden="true" tabindex="-1"></a>proba</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>En estos casos, es mejor hacer los cálculos en escala logarítmica. El logaritmo
convierte productos en sumas, y baja exponentes multiplicando. Si calculamos en escala
logaritmica la cantidad de arriba, no tenemos problema:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="estimación-por-máxima-verosimilitud.html#cb285-1" aria-hidden="true" tabindex="-1"></a>log_proba <span class="ot">&lt;-</span> <span class="dv">800</span> <span class="sc">*</span> <span class="fu">log</span>(p) <span class="sc">+</span> <span class="dv">200</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>p)</span>
<span id="cb285-2"><a href="estimación-por-máxima-verosimilitud.html#cb285-2" aria-hidden="true" tabindex="-1"></a>log_proba</span></code></pre></div>
<pre><code>## [1] -1863.14</code></pre>
<p>Ahora notemos que</p>
<ul>
<li>Maximizar la verosimilitud <strong>es lo mismo</strong> que maximizar la log-verosimilitud, pues el logaritmo es una función creciente. Si <span class="math inline">\(x_{\max}\)</span> es el máximo de <span class="math inline">\(f\)</span>, tenemos que <span class="math inline">\(f(x_{\max})&gt;f(x)\)</span> para cualquier <span class="math inline">\(x\)</span>, entonces tomando logaritmo,
<span class="math display">\[\log(f(x_{max}))&gt;\log(f(x)),\]</span> para cualquier <span class="math inline">\(x.\)</span> Pues el logaritmo respeta la desigualdad por ser creciente.</li>
<li>Usualmente usamos la log-verosimilitud para encontrar el estimador de máxima verosimilitud.</li>
<li>Hay razónes teóricas y de interpretación por las que también es conveniente hacer esto.</li>
</ul>
<div class="mathblock">
<p>
<strong>Definición.</strong> La log-verosimilitud la denotamos
usualmente por <span class="math display"><span class="math display">\[\ell_n(\theta) = \log
\left(\mathcal{L}_n(\theta)\right),\]</span></span> donde hemos suprimido la
dependencia en la muestra por conveniencia.
</p>
</div>
<p><strong>Ejemplo.</strong> En nuestro primer ejemplo,</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="estimación-por-máxima-verosimilitud.html#cb287-1" aria-hidden="true" tabindex="-1"></a>log_verosimilitud <span class="ot">&lt;-</span> <span class="cf">function</span>(p){</span>
<span id="cb287-2"><a href="estimación-por-máxima-verosimilitud.html#cb287-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span><span class="sc">*</span><span class="fu">log</span>(p) <span class="sc">+</span> <span class="dv">6</span><span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>p)</span>
<span id="cb287-3"><a href="estimación-por-máxima-verosimilitud.html#cb287-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb287-4"><a href="estimación-por-máxima-verosimilitud.html#cb287-4" aria-hidden="true" tabindex="-1"></a>dat_verosim <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="fl">0.01</span>)) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">log_prob =</span> <span class="fu">map_dbl</span>(x, log_verosimilitud))</span>
<span id="cb287-5"><a href="estimación-por-máxima-verosimilitud.html#cb287-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat_verosim, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> log_prob)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb287-6"><a href="estimación-por-máxima-verosimilitud.html#cb287-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.25</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb287-7"><a href="estimación-por-máxima-verosimilitud.html#cb287-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;p&quot;</span>)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-8-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Obtenemos el mismo máximo. Podemos incluso resolver numéricamente:</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="estimación-por-máxima-verosimilitud.html#cb288-1" aria-hidden="true" tabindex="-1"></a>solucion <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">p =</span> <span class="fl">0.5</span>, log_verosimilitud, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">fnscale =</span> <span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb288-2"><a href="estimación-por-máxima-verosimilitud.html#cb288-2" aria-hidden="true" tabindex="-1"></a>solucion<span class="sc">$</span>par</span></code></pre></div>
<pre><code>## [1] 0.25</code></pre>
<p>Y en nuestro segundo ejemplo:</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="estimación-por-máxima-verosimilitud.html#cb290-1" aria-hidden="true" tabindex="-1"></a>calc_log_verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(r){</span>
<span id="cb290-2"><a href="estimación-por-máxima-verosimilitud.html#cb290-2" aria-hidden="true" tabindex="-1"></a>  q_func <span class="ot">&lt;-</span> <span class="fl">0.03</span><span class="sc">^</span>r<span class="sc">*</span>(<span class="fl">0.97</span>)<span class="sc">^</span>(<span class="dv">10</span><span class="sc">-</span>r)</span>
<span id="cb290-3"><a href="estimación-por-máxima-verosimilitud.html#cb290-3" aria-hidden="true" tabindex="-1"></a>  q_falla <span class="ot">&lt;-</span> <span class="fl">0.2</span><span class="sc">^</span>r<span class="sc">*</span>(<span class="fl">0.8</span>)<span class="sc">^</span>(<span class="dv">10</span><span class="sc">-</span>r)</span>
<span id="cb290-4"><a href="estimación-por-máxima-verosimilitud.html#cb290-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(p){</span>
<span id="cb290-5"><a href="estimación-por-máxima-verosimilitud.html#cb290-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#nota: esta no es la mejor manera de calcularlo, hay </span></span>
<span id="cb290-6"><a href="estimación-por-máxima-verosimilitud.html#cb290-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># que usar logaritmos.</span></span>
<span id="cb290-7"><a href="estimación-por-máxima-verosimilitud.html#cb290-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">log</span>(p <span class="sc">*</span> q_func <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">*</span> q_falla))</span>
<span id="cb290-8"><a href="estimación-por-máxima-verosimilitud.html#cb290-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb290-9"><a href="estimación-por-máxima-verosimilitud.html#cb290-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb290-10"><a href="estimación-por-máxima-verosimilitud.html#cb290-10" aria-hidden="true" tabindex="-1"></a>log_verosim <span class="ot">&lt;-</span> <span class="fu">calc_log_verosim</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb290-11"><a href="estimación-por-máxima-verosimilitud.html#cb290-11" aria-hidden="true" tabindex="-1"></a><span class="fu">log_verosim</span>(<span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] -31.24587</code></pre>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="estimación-por-máxima-verosimilitud.html#cb292-1" aria-hidden="true" tabindex="-1"></a>dat_verosim <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">log_verosimilitud =</span> <span class="fu">map_dbl</span>(x, log_verosim))</span>
<span id="cb292-2"><a href="estimación-por-máxima-verosimilitud.html#cb292-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat_verosim, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> log_verosimilitud)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb292-3"><a href="estimación-por-máxima-verosimilitud.html#cb292-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.775</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb292-4"><a href="estimación-por-máxima-verosimilitud.html#cb292-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;prop funcionado&quot;</span>)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-11-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Nótese que la verosimilitud la consideramos <strong>función de los parámetros</strong>,
donde <strong>los datos están fijos</strong>.</p>
<p>Podemos construir una función que genera la función de verosimilitud dependiendo de los datos. En nuestro primer ejemplo de muestras de registros erróneos,
podríamos construir una función que genera la log verosimilitud dependiendo
del tamaño de muestra y del número de errores encontrado:</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="estimación-por-máxima-verosimilitud.html#cb293-1" aria-hidden="true" tabindex="-1"></a>construir_log_verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(n, n_err){</span>
<span id="cb293-2"><a href="estimación-por-máxima-verosimilitud.html#cb293-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># n es tamaño de muestra </span></span>
<span id="cb293-3"><a href="estimación-por-máxima-verosimilitud.html#cb293-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># n_err el número de errores detectados (datos)</span></span>
<span id="cb293-4"><a href="estimación-por-máxima-verosimilitud.html#cb293-4" aria-hidden="true" tabindex="-1"></a>  n_corr <span class="ot">&lt;-</span> n <span class="sc">-</span> n_err</span>
<span id="cb293-5"><a href="estimación-por-máxima-verosimilitud.html#cb293-5" aria-hidden="true" tabindex="-1"></a>  log_verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(p){</span>
<span id="cb293-6"><a href="estimación-por-máxima-verosimilitud.html#cb293-6" aria-hidden="true" tabindex="-1"></a>    n_err <span class="sc">*</span> <span class="fu">log</span>(p) <span class="sc">+</span> n_corr <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>p)</span>
<span id="cb293-7"><a href="estimación-por-máxima-verosimilitud.html#cb293-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb293-8"><a href="estimación-por-máxima-verosimilitud.html#cb293-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Cuando fijamos <span class="math inline">\(n\)</span> y <span class="math inline">\(n_{\textsf{err}}\)</span>, esta función genera otra función, la log verosimilitud, que es la que queremos optimizar.</p>
<p>Supongamos entonces que sacamos 20 registros al azar y observamos 10 incorrectos. La función
de verosimilitud es</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="estimación-por-máxima-verosimilitud.html#cb294-1" aria-hidden="true" tabindex="-1"></a>log_vero <span class="ot">&lt;-</span> <span class="fu">construir_log_verosim</span>(<span class="dv">20</span>, <span class="dv">10</span>)</span></code></pre></div>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="estimación-por-máxima-verosimilitud.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.001</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb295-2"><a href="estimación-por-máxima-verosimilitud.html#cb295-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">log_ver =</span> <span class="fu">log_vero</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb295-3"><a href="estimación-por-máxima-verosimilitud.html#cb295-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> log_ver)) <span class="sc">+</span> </span>
<span id="cb295-4"><a href="estimación-por-máxima-verosimilitud.html#cb295-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb295-5"><a href="estimación-por-máxima-verosimilitud.html#cb295-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">&#39;red&#39;</span>)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-14-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><strong>Ejemplo.</strong> Supongamos que en una población de transacciones hay un porcentaje <span class="math inline">\(p\)</span> (desconocido)
que son fraudulentas. Tenemos un sistema de clasificación humana que que marca transacciones como sospechosas.
Con este sistema hemos medido que la proporción de transacciones normales que son marcadas como sospechosas es de 0.1%, y que la proporción de transacciones fraudulentas que son marcadas
como sospechosas es de 98%. Supongamos que extraemos una muestra de 2000 transacciones, de manera que todas ellas tiene la misma probabilidad de ser fraudulentas. El sistema de clasificación marca 4 transacciones como fraudulentas. ¿Cómo estimamos la proporción de transacciones fraudulentas en la población?</p>
<p>Solución: sea <span class="math inline">\(p\)</span> la proporción de transacciones fraudulentas. Entonces la probabilidad
de que una transacción sea marcada como sospechosa es (proba total):</p>
<p><span class="math display">\[0.98p + 0.001(1-p)\]</span></p>
<p>Pues tenemos que contar 98% de la proporción <span class="math inline">\(p\)</span> de fraudulentas
(correctamente detectadas) más 0.1% de la proporción <span class="math inline">\((1-p)\)</span> de fraudulentas.
Escribimos entonces nuestra función de verosimilitud</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="estimación-por-máxima-verosimilitud.html#cb296-1" aria-hidden="true" tabindex="-1"></a>crear_log_verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(n, n_sosp){</span>
<span id="cb296-2"><a href="estimación-por-máxima-verosimilitud.html#cb296-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># devolver la función log verosimilitud </span></span>
<span id="cb296-3"><a href="estimación-por-máxima-verosimilitud.html#cb296-3" aria-hidden="true" tabindex="-1"></a>  log_verosimilitud_pct <span class="ot">&lt;-</span> <span class="cf">function</span>(pct){</span>
<span id="cb296-4"><a href="estimación-por-máxima-verosimilitud.html#cb296-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sup que pct es la proporcentaje de fraudes,</span></span>
<span id="cb296-5"><a href="estimación-por-máxima-verosimilitud.html#cb296-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># que es el parámetro que queremos estimar</span></span>
<span id="cb296-6"><a href="estimación-por-máxima-verosimilitud.html#cb296-6" aria-hidden="true" tabindex="-1"></a>    prob_sosp <span class="ot">&lt;-</span> <span class="fl">0.98</span> <span class="sc">*</span> pct <span class="sc">/</span> <span class="dv">100</span> <span class="sc">+</span> <span class="fl">0.001</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> pct <span class="sc">/</span> <span class="dv">100</span>)</span>
<span id="cb296-7"><a href="estimación-por-máxima-verosimilitud.html#cb296-7" aria-hidden="true" tabindex="-1"></a>    log_prob <span class="ot">&lt;-</span> n_sosp <span class="sc">*</span> <span class="fu">log</span>(prob_sosp) <span class="sc">+</span> (n <span class="sc">-</span> n_sosp) <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span> prob_sosp)</span>
<span id="cb296-8"><a href="estimación-por-máxima-verosimilitud.html#cb296-8" aria-hidden="true" tabindex="-1"></a>    log_prob</span>
<span id="cb296-9"><a href="estimación-por-máxima-verosimilitud.html#cb296-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb296-10"><a href="estimación-por-máxima-verosimilitud.html#cb296-10" aria-hidden="true" tabindex="-1"></a>  log_verosimilitud_pct</span>
<span id="cb296-11"><a href="estimación-por-máxima-verosimilitud.html#cb296-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>La verosimilitud es una función de <span class="math inline">\(p\)</span>.</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="estimación-por-máxima-verosimilitud.html#cb297-1" aria-hidden="true" tabindex="-1"></a>log_verosim <span class="ot">&lt;-</span> <span class="fu">crear_log_verosim</span>(<span class="at">n =</span> <span class="dv">2000</span>, <span class="at">n_sosp =</span> <span class="dv">4</span>)</span></code></pre></div>
<p>A continuación la mostramos de manera gráfica.</p>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-17-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>No se ve muy claro dónde ocurre el máximo, pero podemos ampliar cerca de cero la
misma gráfica:</p>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-18-1.png" width="480" style="display: block; margin: auto;" /></p>
<ul>
<li>Vemos que alrededor de 0.1% maximiza la probabilidad de haber observado 4
transacciones sospechosas.</li>
<li>Notamos sin embargo que varios valores alrededor de este valor tienen probabilidad similar,
así que también son consistentes con los datos (por ejemplo, valores como 0.05 o 0.15 tienen probabilidad similar). Tendremos que considerar esto para evaluar la incertidumbre en nuestra estimación.</li>
<li>Obsérvese adicionalmente que si no tomáramos en cuenta las probabilidades de falsos
negativos y falsos positivos la estimación simple daría <span class="math inline">\(4/2000 = 0.002\)</span> (0.2%), que es
dos veces más grande que nuestra estimación puntual por máxima verosimilitud.</li>
</ul>
<p><strong>Ejemplo.</strong> Este es un ejemplo donde mostramos que cuando el soporte
de las densidades teóricas es acotado hay que tener cuidado en la definición de la
verosimilitud. En este caso, el soporte de la variable aleatoria es el párametro de interés. Supongamos
que nuestros datos son generados por medio de una distribución uniforme en el intervalo <span class="math inline">\([0,b].\)</span>
Contamos con una muestra de <span class="math inline">\(n\)</span> observaciones generadas
de manera independiente <span class="math inline">\(X_i \sim U[0,b]\)</span> para <span class="math inline">\(i= 1, \ldots, n.\)</span>
Sin embargo, no conocemos el valor de <span class="math inline">\(b\)</span>.</p>
<p>¿Cómo es la función de log verosimilitud <span class="math inline">\({\mathcal L}_n(b)\)</span> para este caso? Nótese
que cuando el parámetro <span class="math inline">\(b\)</span> es menor que alguna <span class="math inline">\(x_i\)</span>, tenemos que
<span class="math inline">\({\mathcal L}_n(b) = 0\)</span>: la verosimilitud es cero si tomamos una <span class="math inline">\(b\)</span> más chica
que algún dato, pues este valor es incosistente del todo con los datos observados.
En otro caso,</p>
<p><span class="math display">\[{\mathcal L}_n(b) = \frac{1}{b^n},\]</span>
pues la función de densidad de una uniforme en <span class="math inline">\([0,b]\)</span> es igual a <span class="math inline">\(1/b\)</span> en
el intervalo <span class="math inline">\([0,b]\)</span>, y 0 en otro caso. Podemos escribir entonces:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="estimación-por-máxima-verosimilitud.html#cb298-1" aria-hidden="true" tabindex="-1"></a>crear_verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb298-2"><a href="estimación-por-máxima-verosimilitud.html#cb298-2" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb298-3"><a href="estimación-por-máxima-verosimilitud.html#cb298-3" aria-hidden="true" tabindex="-1"></a>  verosim <span class="ot">&lt;-</span> <span class="cf">function</span>(b){</span>
<span id="cb298-4"><a href="estimación-por-máxima-verosimilitud.html#cb298-4" aria-hidden="true" tabindex="-1"></a>    indicadora <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="fu">all</span>(x <span class="sc">&lt;=</span> b), <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb298-5"><a href="estimación-por-máxima-verosimilitud.html#cb298-5" aria-hidden="true" tabindex="-1"></a>    indicadora <span class="sc">/</span> b<span class="sc">^</span>n</span>
<span id="cb298-6"><a href="estimación-por-máxima-verosimilitud.html#cb298-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb298-7"><a href="estimación-por-máxima-verosimilitud.html#cb298-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Ahora podemos hacer máxima verosimilitud para un ejemplo:</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="estimación-por-máxima-verosimilitud.html#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb299-2"><a href="estimación-por-máxima-verosimilitud.html#cb299-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">3</span>)</span>
<span id="cb299-3"><a href="estimación-por-máxima-verosimilitud.html#cb299-3" aria-hidden="true" tabindex="-1"></a>verosim <span class="ot">&lt;-</span> <span class="fu">crear_verosim</span>(x)</span>
<span id="cb299-4"><a href="estimación-por-máxima-verosimilitud.html#cb299-4" aria-hidden="true" tabindex="-1"></a>res_opt <span class="ot">&lt;-</span> <span class="fu">optimize</span>(verosim, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1000</span>, <span class="dv">1000</span>), <span class="at">maximum =</span> <span class="cn">TRUE</span>)</span>
<span id="cb299-5"><a href="estimación-por-máxima-verosimilitud.html#cb299-5" aria-hidden="true" tabindex="-1"></a>res_opt<span class="sc">$</span>maximum</span></code></pre></div>
<pre><code>## [1] 2.788167</code></pre>
<p>Y nótese que, como esperaríamos, este valor es el máximo de la muestra:</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="estimación-por-máxima-verosimilitud.html#cb301-1" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(x)</span></code></pre></div>
<pre><code>## [1] 2.788158</code></pre>
<p>La gráfica de la función de verosimilitud es:</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="estimación-por-máxima-verosimilitud.html#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">b =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb303-2"><a href="estimación-por-máxima-verosimilitud.html#cb303-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">verosim_1 =</span> <span class="fu">map_dbl</span>(b, <span class="sc">~</span> <span class="fu">verosim</span>(.x))) <span class="sc">%&gt;%</span> </span>
<span id="cb303-3"><a href="estimación-por-máxima-verosimilitud.html#cb303-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb303-4"><a href="estimación-por-máxima-verosimilitud.html#cb303-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> b, <span class="at">y =</span> verosim_1)) <span class="sc">+</span></span>
<span id="cb303-5"><a href="estimación-por-máxima-verosimilitud.html#cb303-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rug</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">x =</span> x), <span class="fu">aes</span>(<span class="at">x =</span> x), <span class="at">colour =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-22-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Podemos escribir en una fórmula como:</p>
<p><span class="math display">\[\begin{align}
\mathcal{L}(b; x_1, \ldots, x_n) = \prod_{i = 1}^n 1_{[0,b]}(x_i) \frac1b.
\end{align}\]</span></p>
<p>Y podríamos resolver analíticamente como sigue:</p>
<p>Si consideramos
<span class="math display">\[ \hat b_{\textsf{MLE}} = x_{\max} = \max\{x_i\},\]</span>
notemos que cualquier valor observado necesariamente satisface
<span class="math display">\[x_i \leq \hat b_{\textsf{MLE}},\]</span>
y por lo tanto todas las funciones indicadoras están <em>encendidas</em>. El valor de la verosimilitud es igual a
<span class="math display">\[\mathcal{L}(\hat b_{\textsf{MLE}}; x_1, \ldots, x_n) = \left(\frac{1}{x_{\max}}\right)^n \geq \left (\frac1b\right )^n\]</span>
para cualquier <span class="math inline">\(b\geq x_{\max}\)</span>. Como la verosimilitud para <span class="math inline">\(b&lt;x_{\max}\)</span> es igual
a cero, esto demuestra que el máximo de la muestra es el estimador de máxima
verosimilitud de <span class="math inline">\(b\)</span>.</p>
<p><strong>Observación.</strong> Este ejemplo también tiene dificultades numéricas, pues
la verosimilitud presenta discontinuidades y regiones con derivada igual a cero, y
la mayoria de los algoritmos numéricos no tienen garantías buenas de
covergencia al máximo en estos casos.
Si aplicamos sin cuidado descenso en gradiente, por ejemplo, podríamos comenzar
incorrectamente en un valor <span class="math inline">\(b_0 &lt; x_{\max}\)</span> y el algoritmo no avanzaría
al máximo.</p>
</div>
<div id="máxima-verosimilitud-para-más-de-un-parámetro" class="section level2 unnumbered hasAnchor">
<h2>Máxima verosimilitud para más de un parámetro<a href="estimación-por-máxima-verosimilitud.html#máxima-verosimilitud-para-más-de-un-parámetro" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Si nuestro modelo contiene más de un parámetro desconocido podemos también usar
máxima verosimilitud. En este caso, optimizamos sobre todos los parámetros usando
cálculo o alguna rutina numérica.</p>
<p><strong>Ejemplo.</strong> Considera el caso de <span class="math inline">\(n\)</span> muestras iid de un modelo Gaussiano. Es decir,
<span class="math inline">\(X_1, \ldots, X_n \sim \mathsf{N}(\mu, \sigma^2).\)</span> Consideremos que ambos parámetros son desconocidos y nos gustaria
encontrar el <span class="math inline">\(\textsf{MLE}\)</span>. Para este problema denotamos <span class="math inline">\(\theta \in \mathbb{R}^2\)</span>, donde <span class="math inline">\(\theta_1 = \mu\)</span> y <span class="math inline">\(\theta_2 = \sigma^2.\)</span></p>
<p>La función de verosimiltud se puede calcular (ignorando algunas constantes multiplicativas) como
<span class="math display">\[\begin{align}
\mathcal{L}_n(\theta) &amp;= \prod_{i = 1}^n \frac{1}{\sigma} \, \exp\left( - \frac{(x_i - \mu)^2}{2\sigma^2}\right) \\
  &amp;= \theta_2^{-\frac{n}{2}}\exp\left( - \frac{1}{2 \theta_2} \sum_{i = 1}^n (x_i - \theta_1)^2 \right).
\end{align}\]</span></p>
<p>A continuación mostramos la representación gráfica de la función de verosimilitud de este ejemplo.
Notamos lo mismo que para los ejemplos anteriores. Conforme más datos tenemos, más nos acercamos a los valores
reales que no conocemos.</p>
<p><img src="images/mle-normal.png" style="display: block; margin: auto;" /></p>
<p><strong>Ejemplo</strong>. Como ejercicio, podemos encontrar los estimadores de máxima
verosimilitud cuando tenemos una muestra <span class="math inline">\(X_1, \ldots, X_n \sim \mathsf{N}(\mu, \sigma^2).\)</span>
(puedes derivar e igualar el cero para encontrar el mínimo). También podemos resolver numéricamente,
por ejemplo:</p>
<p>Supongamos que tenemos la siguiente muestra:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="estimación-por-máxima-verosimilitud.html#cb304-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">41852</span>)</span>
<span id="cb304-2"><a href="estimación-por-máxima-verosimilitud.html#cb304-2" aria-hidden="true" tabindex="-1"></a>muestra <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">150</span>, <span class="at">mean =</span> <span class="dv">1</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>La función generadora de la log verosimilitud para una muestra es (ve la expresión
del ejercicio anterior y calcula su logaritmo), y generamos la función de verosimilitud
para nuestra muestra:</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="estimación-por-máxima-verosimilitud.html#cb305-1" aria-hidden="true" tabindex="-1"></a>crear_log_p <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb305-2"><a href="estimación-por-máxima-verosimilitud.html#cb305-2" aria-hidden="true" tabindex="-1"></a>  log_p <span class="ot">&lt;-</span> <span class="cf">function</span>(pars){</span>
<span id="cb305-3"><a href="estimación-por-máxima-verosimilitud.html#cb305-3" aria-hidden="true" tabindex="-1"></a>    media <span class="ot">=</span> pars[<span class="dv">1</span>]</span>
<span id="cb305-4"><a href="estimación-por-máxima-verosimilitud.html#cb305-4" aria-hidden="true" tabindex="-1"></a>    desv_est <span class="ot">=</span> pars[<span class="dv">2</span>]</span>
<span id="cb305-5"><a href="estimación-por-máxima-verosimilitud.html#cb305-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ve la ecuación del ejercicio anterior</span></span>
<span id="cb305-6"><a href="estimación-por-máxima-verosimilitud.html#cb305-6" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> (x <span class="sc">-</span> media) <span class="sc">/</span> desv_est</span>
<span id="cb305-7"><a href="estimación-por-máxima-verosimilitud.html#cb305-7" aria-hidden="true" tabindex="-1"></a>    log_verosim <span class="ot">&lt;-</span> <span class="sc">-</span>(<span class="fu">log</span>(desv_est) <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">mean</span>(z <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb305-8"><a href="estimación-por-máxima-verosimilitud.html#cb305-8" aria-hidden="true" tabindex="-1"></a>    log_verosim</span>
<span id="cb305-9"><a href="estimación-por-máxima-verosimilitud.html#cb305-9" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb305-10"><a href="estimación-por-máxima-verosimilitud.html#cb305-10" aria-hidden="true" tabindex="-1"></a>  log_p</span>
<span id="cb305-11"><a href="estimación-por-máxima-verosimilitud.html#cb305-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb305-12"><a href="estimación-por-máxima-verosimilitud.html#cb305-12" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="fu">crear_log_p</span>(muestra)</span></code></pre></div>
<p>Ahora optimizamos:</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="estimación-por-máxima-verosimilitud.html#cb306-1" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), log_p, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">fnscale =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">maxit =</span> <span class="dv">1000</span>), <span class="at">method =</span> <span class="st">&quot;Nelder-Mead&quot;</span>)</span>
<span id="cb306-2"><a href="estimación-por-máxima-verosimilitud.html#cb306-2" aria-hidden="true" tabindex="-1"></a>res<span class="sc">$</span>convergence</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="estimación-por-máxima-verosimilitud.html#cb308-1" aria-hidden="true" tabindex="-1"></a>est_mv <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">parametro =</span> <span class="fu">c</span>(<span class="st">&quot;media&quot;</span>, <span class="st">&quot;sigma&quot;</span>), <span class="at">estimador =</span> res<span class="sc">$</span>par) <span class="sc">%&gt;%</span> </span>
<span id="cb308-2"><a href="estimación-por-máxima-verosimilitud.html#cb308-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">column_to_rownames</span>(<span class="at">var =</span> <span class="st">&quot;parametro&quot;</span>)</span>
<span id="cb308-3"><a href="estimación-por-máxima-verosimilitud.html#cb308-3" aria-hidden="true" tabindex="-1"></a>est_mv</span></code></pre></div>
<pre><code>##       estimador
## media  1.136001
## sigma  1.838421</code></pre>
<p>Verifica que el estimador de la media y de la desviación estándar
es el que esperábamos (y que puedes derivar analíticamente):</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="estimación-por-máxima-verosimilitud.html#cb310-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(muestra)</span>
<span id="cb310-2"><a href="estimación-por-máxima-verosimilitud.html#cb310-2" aria-hidden="true" tabindex="-1"></a>sd_n <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">sqrt</span>( <span class="fu">mean</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb310-3"><a href="estimación-por-máxima-verosimilitud.html#cb310-3" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">media =</span> <span class="fu">mean</span>(muestra), <span class="at">sigma =</span> <span class="fu">sd_n</span>(muestra)) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">4</span>)</span></code></pre></div>
<pre><code>##  media  sigma 
## 1.1364 1.8392</code></pre>
<p><strong>Ejemplo.</strong> Supongamos que en una población de estudiantes tenemos dos tipos: unos llenaron un
examen de opción múltiple al azar (1 de 5), y otros contestaron las preguntas intentando
sacar una buena calificación. Suponemos que una vez que conocemos el tipo de
estudiante, todas las preguntas tienen la misma probabilidad de ser contestadas
correctamente, de manera independiente. El modelo
teórico está representado por la siguiente simulación:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="estimación-por-máxima-verosimilitud.html#cb312-1" aria-hidden="true" tabindex="-1"></a>sim_formas <span class="ot">&lt;-</span> <span class="cf">function</span>(p_azar, p_corr){</span>
<span id="cb312-2"><a href="estimación-por-máxima-verosimilitud.html#cb312-2" aria-hidden="true" tabindex="-1"></a>  tipo <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span> <span class="sc">-</span> p_azar)</span>
<span id="cb312-3"><a href="estimación-por-máxima-verosimilitud.html#cb312-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(tipo<span class="sc">==</span><span class="dv">0</span>){</span>
<span id="cb312-4"><a href="estimación-por-máxima-verosimilitud.html#cb312-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># al azar</span></span>
<span id="cb312-5"><a href="estimación-por-máxima-verosimilitud.html#cb312-5" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">5</span>)</span>
<span id="cb312-6"><a href="estimación-por-máxima-verosimilitud.html#cb312-6" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb312-7"><a href="estimación-por-máxima-verosimilitud.html#cb312-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># no al azar</span></span>
<span id="cb312-8"><a href="estimación-por-máxima-verosimilitud.html#cb312-8" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, p_corr)</span>
<span id="cb312-9"><a href="estimación-por-máxima-verosimilitud.html#cb312-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb312-10"><a href="estimación-por-máxima-verosimilitud.html#cb312-10" aria-hidden="true" tabindex="-1"></a>  x</span>
<span id="cb312-11"><a href="estimación-por-máxima-verosimilitud.html#cb312-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Y una muestra se ve como sigue:</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="estimación-por-máxima-verosimilitud.html#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12</span>)</span>
<span id="cb313-2"><a href="estimación-por-máxima-verosimilitud.html#cb313-2" aria-hidden="true" tabindex="-1"></a>muestra <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>, <span class="sc">~</span> <span class="fu">sim_formas</span>(<span class="fl">0.3</span>, <span class="fl">0.75</span>))</span>
<span id="cb313-3"><a href="estimación-por-máxima-verosimilitud.html#cb313-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(muestra)</span></code></pre></div>
<p><img src="09-max-verosimilitud_files/figure-html/unnamed-chunk-29-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Supongamos que no conocemos la probabildad de contestar correctamente ni la
proporción de estudiantes que contestó al azar. ¿Como estimamos estas dos cantidades?</p>
<p>Escribimos la verosimilitud:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="estimación-por-máxima-verosimilitud.html#cb314-1" aria-hidden="true" tabindex="-1"></a>crear_log_p <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb314-2"><a href="estimación-por-máxima-verosimilitud.html#cb314-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb314-3"><a href="estimación-por-máxima-verosimilitud.html#cb314-3" aria-hidden="true" tabindex="-1"></a>  log_p <span class="ot">&lt;-</span> <span class="cf">function</span>(pars){</span>
<span id="cb314-4"><a href="estimación-por-máxima-verosimilitud.html#cb314-4" aria-hidden="true" tabindex="-1"></a>    p_azar <span class="ot">=</span> pars[<span class="dv">1</span>]</span>
<span id="cb314-5"><a href="estimación-por-máxima-verosimilitud.html#cb314-5" aria-hidden="true" tabindex="-1"></a>    p_corr <span class="ot">=</span> pars[<span class="dv">2</span>]</span>
<span id="cb314-6"><a href="estimación-por-máxima-verosimilitud.html#cb314-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">log</span>(p_azar <span class="sc">*</span> <span class="fu">dbinom</span>(x, <span class="dv">10</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">5</span>) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> p_azar) <span class="sc">*</span> <span class="fu">dbinom</span>(x, <span class="dv">10</span>, p_corr)))</span>
<span id="cb314-7"><a href="estimación-por-máxima-verosimilitud.html#cb314-7" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb314-8"><a href="estimación-por-máxima-verosimilitud.html#cb314-8" aria-hidden="true" tabindex="-1"></a>  log_p</span>
<span id="cb314-9"><a href="estimación-por-máxima-verosimilitud.html#cb314-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Creamos la función de verosimilitud con los datos</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="estimación-por-máxima-verosimilitud.html#cb315-1" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="fu">crear_log_p</span>(muestra)</span></code></pre></div>
<p>y optimizamos</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="estimación-por-máxima-verosimilitud.html#cb316-1" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>), log_p, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">fnscale =</span> <span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb316-2"><a href="estimación-por-máxima-verosimilitud.html#cb316-2" aria-hidden="true" tabindex="-1"></a>res<span class="sc">$</span>par</span></code></pre></div>
<pre><code>## [1] 0.2827061 0.7413276</code></pre>
<p>En este caso, obtenemos estimaciones razonables de ambos parámetros.
Nota: dependiendo de los datos, este problema
puede estar mal condicionado. Por ejemplo, ¿qué pasa si la probabilidad de acertar
cuando se contesta bien está cercano al azar?</p>
<p>La siguiente pregunta qué nos interesa hacer es: ¿cómo estimamos la variabilidad
de estos estimadores? Más adelante veremos una respuesta basada en teoría, pero
también podemos resolver este problema usando el bootstrap.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Chihara" class="csl-entry">
Chihara, Laura M., and Tim C. Hesterberg. 2018. <em>Mathematical Statistics with Resampling and r</em>. 2nd ed. Hoboken, NJ: John Wiley &amp; Sons. <a href="https://sites.google.com/site/chiharahesterberg/home">https://sites.google.com/site/chiharahesterberg/home</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intervalos-de-confianza-y-remuestreo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bootstrap-paramétrico.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/09-max-verosimilitud.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["fundamentos-estadistica.Rmd"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"depth": 1
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
