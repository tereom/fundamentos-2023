<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Sección 12 Métodos de Cadenas de Markov Monte Carlo | Fundamentos de Estadística con Remuestreo</title>
  <meta name="description" content="Curso de Fundamentos de Estadística con Remuestreo, maestría en Ciencia de Datos, ITAM, Otoño 2023." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Sección 12 Métodos de Cadenas de Markov Monte Carlo | Fundamentos de Estadística con Remuestreo" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Curso de Fundamentos de Estadística con Remuestreo, maestría en Ciencia de Datos, ITAM, Otoño 2023." />
  <meta name="github-repo" content="tereom/fundamentos-2023" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Sección 12 Métodos de Cadenas de Markov Monte Carlo | Fundamentos de Estadística con Remuestreo" />
  
  <meta name="twitter:description" content="Curso de Fundamentos de Estadística con Remuestreo, maestría en Ciencia de Datos, ITAM, Otoño 2023." />
  

<meta name="author" content="Teresa Ortiz, Alfredo Garbuno, Felipe González" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="calibración-bayesiana-y-regularización.html"/>
<link rel="next" href="apéndice-principios-de-visualizacion.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Fundamentos de Estadística con Remuestreo</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a>
<ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#plan-semanal"><i class="fa fa-check"></i>Plan semanal</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#evaluación"><i class="fa fa-check"></i>Evaluación</a></li>
<li class="chapter" data-level="0.1" data-path="temario.html"><a href="temario.html#referencias"><i class="fa fa-check"></i><b>0.1</b> Referencias</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html"><i class="fa fa-check"></i><b>1</b> Análisis exploratorio</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#el-papel-de-la-exploración-en-el-análisis-de-datos"><i class="fa fa-check"></i>El papel de la exploración en el análisis de datos</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#preguntas-y-datos"><i class="fa fa-check"></i>Preguntas y datos</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#algunos-conceptos-básicos"><i class="fa fa-check"></i>Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#histogramas"><i class="fa fa-check"></i>Histogramas</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#media-y-desviación-estándar"><i class="fa fa-check"></i>Media y desviación estándar</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#ejemplos"><i class="fa fa-check"></i>Ejemplos</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#precios-de-casas"><i class="fa fa-check"></i>Precios de casas</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#prueba-enlace"><i class="fa fa-check"></i>Prueba Enlace</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#estados-y-calificaciones-en-sat"><i class="fa fa-check"></i>Estados y calificaciones en SAT</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#tablas-de-conteos"><i class="fa fa-check"></i>Tablas de conteos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#suavizamiento-loess"><i class="fa fa-check"></i>Suavizamiento loess</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#opcional-cálculo-del-suavizador"><i class="fa fa-check"></i>Opcional: cálculo del suavizador</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#caso-de-estudio-nacimientos-en-méxico"><i class="fa fa-check"></i>Caso de estudio: nacimientos en México</a>
<ul>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#datos-de-natalidad-para-méxico"><i class="fa fa-check"></i>Datos de natalidad para México</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#tendencia"><i class="fa fa-check"></i>Tendencia</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#componente-anual"><i class="fa fa-check"></i>Componente anual</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#día-de-la-semana"><i class="fa fa-check"></i>Día de la semana</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#residuales"><i class="fa fa-check"></i>Residuales</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#reestimación"><i class="fa fa-check"></i>Reestimación</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#análisis-de-componentes"><i class="fa fa-check"></i>Análisis de componentes</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#residuales-antes-y-después-de-2006"><i class="fa fa-check"></i>Residuales: antes y después de 2006</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#otros-días-especiales-más-de-residuales"><i class="fa fa-check"></i>Otros días especiales: más de residuales</a></li>
<li class="chapter" data-level="" data-path="análisis-exploratorio.html"><a href="análisis-exploratorio.html#semana-santa"><i class="fa fa-check"></i>Semana santa</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html"><i class="fa fa-check"></i><b>2</b> Tipos de estudio y experimentos</a>
<ul>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#motivación"><i class="fa fa-check"></i>Motivación</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#proceso-generador-de-datos"><i class="fa fa-check"></i>Proceso Generador de Datos</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#ejemplo-prevalencia-de-anemia"><i class="fa fa-check"></i>Ejemplo: Prevalencia de anemia</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#muestreo-aleatorio"><i class="fa fa-check"></i>Muestreo aleatorio</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#pero-si-no-podemos-hacer-muestreo-aleatorio"><i class="fa fa-check"></i>Pero si no podemos hacer muestreo aleatorio?</a>
<ul>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#ejemplo-policías-y-tráfico"><i class="fa fa-check"></i>Ejemplo: Policías y tráfico</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#el-estimador-estándar"><i class="fa fa-check"></i>El estimador estándar</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#experimentos-tradicionales"><i class="fa fa-check"></i>Experimentos tradicionales</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#bloqueo"><i class="fa fa-check"></i>Bloqueo</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#variables-desconocidas"><i class="fa fa-check"></i>Variables desconocidas</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#aleatorizando-el-tratamiento"><i class="fa fa-check"></i>Aleatorizando el tratamiento</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#selección-de-unidades-y-tratamiento"><i class="fa fa-check"></i>Selección de unidades y tratamiento</a></li>
<li class="chapter" data-level="" data-path="tipos-de-estudio-y-experimentos.html"><a href="tipos-de-estudio-y-experimentos.html#asignación-natural-del-tratamiento"><i class="fa fa-check"></i>Asignación natural del tratamiento</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>3</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#comparación-con-poblaciones-de-referencia"><i class="fa fa-check"></i>Comparación con poblaciones de referencia</a>
<ul>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#comparando-distribuciones"><i class="fa fa-check"></i>Comparando distribuciones</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#prueba-de-permutaciones-y-el-lineup"><i class="fa fa-check"></i>Prueba de permutaciones y el <em>lineup</em></a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#comparaciones-usando-lineup-continuación"><i class="fa fa-check"></i>Comparaciones usando <em>lineup</em> (continuación)</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#prueba-de-permutaciones-para-proporciones"><i class="fa fa-check"></i>Prueba de permutaciones para proporciones</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis-tradicionales"><i class="fa fa-check"></i>Pruebas de hipótesis tradicionales</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tomadores-de-té-continuación"><i class="fa fa-check"></i>Tomadores de té (continuación)</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-permutación-implementación."><i class="fa fa-check"></i>Pruebas de permutación: implementación.</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo-tiempos-de-fusión"><i class="fa fa-check"></i>Ejemplo: tiempos de fusión</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo-tiempos-de-fusión-continuación"><i class="fa fa-check"></i>Ejemplo: tiempos de fusión (continuación)</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#separación-de-grupos"><i class="fa fa-check"></i>Separación de grupos</a>
<ul>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#avispas-opcional"><i class="fa fa-check"></i>Avispas (opcional)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#la-crisis-de-replicabilidad"><i class="fa fa-check"></i>La “crisis de replicabilidad”</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-jardín-de-los-senderos-que-se-bifurcan"><i class="fa fa-check"></i>El jardín de los senderos que se bifurcan</a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#ejemplo-decisiones-de-análisis-y-valores-p"><i class="fa fa-check"></i>Ejemplo: decisiones de análisis y valores <em>p</em></a></li>
<li class="chapter" data-level="" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#alternativas-o-soluciones"><i class="fa fa-check"></i>Alternativas o soluciones</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html"><i class="fa fa-check"></i><b>4</b> Estimación y distribución de muestreo</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-precios-de-casas"><i class="fa fa-check"></i>Ejemplo: precios de casas</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#distribución-de-muestreo"><i class="fa fa-check"></i>Distribución de muestreo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#más-ejemplos"><i class="fa fa-check"></i>Más ejemplos</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#el-error-estándar"><i class="fa fa-check"></i>El error estándar</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-valor-de-casas"><i class="fa fa-check"></i>Ejemplo: valor de casas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#calculando-la-distribución-de-muestreo"><i class="fa fa-check"></i>Calculando la distribución de muestreo</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-1"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#teorema-central-del-límite"><i class="fa fa-check"></i>Teorema central del límite</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#normalidad-y-gráficas-de-cuantiles-normales"><i class="fa fa-check"></i>Normalidad y gráficas de cuantiles normales</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#prueba-de-hipótesis-de-normalidad"><i class="fa fa-check"></i>Prueba de hipótesis de normalidad</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-3"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-4"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#ejemplo-5"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="estimación-y-distribución-de-muestreo-1.html"><a href="estimación-y-distribución-de-muestreo-1.html#más-del-teorema-central-del-límite"><i class="fa fa-check"></i>Más del Teorema central del límite</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html"><i class="fa fa-check"></i><b>5</b> Intervalos de confianza y remuestreo</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-introductorio"><i class="fa fa-check"></i>Ejemplo introductorio</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#la-idea-del-bootstrap"><i class="fa fa-check"></i>La idea del bootstrap</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#el-principio-de-plug-in"><i class="fa fa-check"></i>El principio de plug-in</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-6"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#discusión-propiedades-de-la-distribución-bootstrap"><i class="fa fa-check"></i>Discusión: propiedades de la distribución bootstrap</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-7"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#variación-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#error-estándar-bootstrap-e-intervalos-normales"><i class="fa fa-check"></i>Error estándar bootstrap e intervalos normales</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-tomadores-de-té-negro"><i class="fa fa-check"></i>Ejemplo: tomadores de té negro</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-inventario-de-casas-vendidas"><i class="fa fa-check"></i>Ejemplo: inventario de casas vendidas</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#calibración-de-intervalos-de-confianza"><i class="fa fa-check"></i>Calibración de intervalos de confianza</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#interpretación-de-intervalos-de-confianza"><i class="fa fa-check"></i>Interpretación de intervalos de confianza</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#sesgo"><i class="fa fa-check"></i>Sesgo</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#intervalos-bootstrap-de-percentiles"><i class="fa fa-check"></i>Intervalos bootstrap de percentiles</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-8"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-para-dos-muestras"><i class="fa fa-check"></i>Bootstrap para dos muestras</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-9"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#datos-pareados"><i class="fa fa-check"></i>Datos pareados</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-y-otras-estadísticas"><i class="fa fa-check"></i>Bootstrap y otras estadísticas</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-estimadores-de-razón"><i class="fa fa-check"></i>Ejemplo: estimadores de razón</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#ejemplo-suavizadores"><i class="fa fa-check"></i>Ejemplo: suavizadores</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-y-estimadores-complejos-tablas-de-perfiles"><i class="fa fa-check"></i>Bootstrap y estimadores complejos: tablas de perfiles</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-y-muestras-complejas"><i class="fa fa-check"></i>Bootstrap y muestras complejas</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#bootstrap-en-r"><i class="fa fa-check"></i>Bootstrap en R</a></li>
<li class="chapter" data-level="" data-path="intervalos-de-confianza-y-remuestreo.html"><a href="intervalos-de-confianza-y-remuestreo.html#conclusiones-y-observaciones"><i class="fa fa-check"></i>Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html"><i class="fa fa-check"></i><b>6</b> Estimación por máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#introducción-a-estimación-por-máxima-verosimilitud"><i class="fa fa-check"></i>Introducción a estimación por máxima verosimilitud</a></li>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#máxima-verosimilitud-para-observaciones-continuas"><i class="fa fa-check"></i>Máxima verosimilitud para observaciones continuas</a></li>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#aspectos-numéricos"><i class="fa fa-check"></i>Aspectos numéricos</a></li>
<li class="chapter" data-level="" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#máxima-verosimilitud-para-más-de-un-parámetro"><i class="fa fa-check"></i>Máxima verosimilitud para más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html"><i class="fa fa-check"></i><b>7</b> <em>Bootstrap</em> paramétrico</a>
<ul>
<li class="chapter" data-level="" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html#ventajas-y-desventajas-de-bootstrap-paramétrico"><i class="fa fa-check"></i>Ventajas y desventajas de <em>bootstrap</em> paramétrico</a></li>
<li class="chapter" data-level="" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html#verificando-los-supuestos-distribucionales"><i class="fa fa-check"></i>Verificando los supuestos distribucionales</a></li>
<li class="chapter" data-level="" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html#modelos-mal-identificados"><i class="fa fa-check"></i>Modelos mal identificados</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html"><i class="fa fa-check"></i><b>8</b> Propiedades teóricas de MLE</a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-10"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#consistencia"><i class="fa fa-check"></i>Consistencia</a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-11"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#equivarianza-del-textsfmle"><i class="fa fa-check"></i>Equivarianza del <span class="math inline">\(\textsf{MLE}\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-12"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#normalidad-asintótica"><i class="fa fa-check"></i>Normalidad asintótica</a>
<ul>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-información-de-fisher"><i class="fa fa-check"></i>Ejemplo: Información de Fisher</a></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#ejemplo-normalidad"><i class="fa fa-check"></i>Ejemplo: Normalidad</a></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#el-método-delta"><i class="fa fa-check"></i>El método delta</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="propiedades-teóricas-de-mle.html"><a href="propiedades-teóricas-de-mle.html#optimalidad-del-textsfmle"><i class="fa fa-check"></i>Optimalidad del <span class="math inline">\(\textsf{MLE}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html"><i class="fa fa-check"></i><b>9</b> Más de pruebas de hipótesis e intervalos</a>
<ul>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#prueba-de-wald"><i class="fa fa-check"></i>Prueba de Wald</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#observación-pruebas-t-y-práctica-estadística"><i class="fa fa-check"></i>Observación: pruebas <span class="math inline">\(t\)</span> y práctica estadística</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#prueba-de-wald-para-dos-medias-o-proporciones"><i class="fa fa-check"></i>Prueba de Wald para dos medias o proporciones</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#datos-pareados-1"><i class="fa fa-check"></i>Datos pareados</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#pruebas-de-cociente-de-verosimilitud"><i class="fa fa-check"></i>Pruebas de cociente de verosimilitud</a>
<ul>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#distribución-de-referencia-para-pruebas-de-cocientes"><i class="fa fa-check"></i>Distribución de referencia para pruebas de cocientes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#otro-tipo-de-pruebas"><i class="fa fa-check"></i>Otro tipo de pruebas</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#errores-tipo-i-y-tipo-ii"><i class="fa fa-check"></i>Errores tipo I y tipo II</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#consideraciones-prácticas"><i class="fa fa-check"></i>Consideraciones prácticas</a></li>
<li class="chapter" data-level="" data-path="más-de-pruebas-de-hipótesis-e-intervalos.html"><a href="más-de-pruebas-de-hipótesis-e-intervalos.html#pruebas-múltiples"><i class="fa fa-check"></i>Pruebas múltiples</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html"><i class="fa fa-check"></i><b>10</b> Introducción a inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#un-primer-ejemplo-completo-de-inferencia-bayesiana"><i class="fa fa-check"></i>Un primer ejemplo completo de inferencia bayesiana</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-estimando-una-proporción"><i class="fa fa-check"></i>Ejemplo: estimando una proporción</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-observaciones-uniformes"><i class="fa fa-check"></i>Ejemplo: observaciones uniformes</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#probabilidad-a-priori"><i class="fa fa-check"></i>Probabilidad a priori</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#análisis-conjugado"><i class="fa fa-check"></i>Análisis conjugado</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-13"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#pasos-de-un-análisis-de-datos-bayesiano"><i class="fa fa-check"></i>Pasos de un análisis de datos bayesiano</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#verificación-predictiva-posterior"><i class="fa fa-check"></i>Verificación predictiva posterior</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-estaturas-de-tenores"><i class="fa fa-check"></i>Ejemplo: estaturas de tenores</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-modelo-poisson"><i class="fa fa-check"></i>Ejemplo: modelo Poisson</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#predicción"><i class="fa fa-check"></i>Predicción</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-cantantes"><i class="fa fa-check"></i>Ejemplo: cantantes</a></li>
<li class="chapter" data-level="" data-path="introducción-a-inferencia-bayesiana-1.html"><a href="introducción-a-inferencia-bayesiana-1.html#ejemplo-posterior-predictiva-de-pareto-uniforme."><i class="fa fa-check"></i>Ejemplo: posterior predictiva de Pareto-Uniforme.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html"><i class="fa fa-check"></i><b>11</b> Calibración bayesiana y Regularización</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#enfoque-bayesiano-y-frecuentista"><i class="fa fa-check"></i>Enfoque bayesiano y frecuentista</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-estimación-de-una-proporción"><i class="fa fa-check"></i>Ejemplo: estimación de una proporción</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#intervalos-de-agresti-coull"><i class="fa fa-check"></i>Intervalos de Agresti-Coull</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#incorporando-información-inicial"><i class="fa fa-check"></i>Incorporando información inicial</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-porporción-de-hogares-de-ingresos-grandes"><i class="fa fa-check"></i>Ejemplo: porporción de hogares de ingresos grandes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#inferencia-bayesiana-y-regularización"><i class="fa fa-check"></i>Inferencia bayesiana y regularización</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-modelo-normal-y-estaturas"><i class="fa fa-check"></i>Ejemplo: modelo normal y estaturas</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-estimación-de-proporciones"><i class="fa fa-check"></i>Ejemplo: estimación de proporciones</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#teoría-de-decisión"><i class="fa fa-check"></i>Teoría de decisión</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-riesgo-frecuentista"><i class="fa fa-check"></i>Ejemplo: riesgo frecuentista</a></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-riesgo-posterior"><i class="fa fa-check"></i>Ejemplo: riesgo posterior</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#riesgo-de-bayes"><i class="fa fa-check"></i>Riesgo de Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="calibración-bayesiana-y-regularización.html"><a href="calibración-bayesiana-y-regularización.html#ejemplo-14"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html"><i class="fa fa-check"></i><b>12</b> Métodos de Cadenas de Markov Monte Carlo</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#integrales-mediante-subdivisiones"><i class="fa fa-check"></i>Integrales mediante subdivisiones</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-estimación-de-una-proporción-1"><i class="fa fa-check"></i>Ejemplo: estimación de una proporción</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#más-de-un-parámetro"><i class="fa fa-check"></i>Más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#métodos-monte-carlo"><i class="fa fa-check"></i>Métodos Monte Carlo</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-15"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-varias-pruebas-independientes"><i class="fa fa-check"></i>Ejemplo: varias pruebas independientes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#simulando-de-la-posterior"><i class="fa fa-check"></i>Simulando de la posterior</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#método-de-metrópolis"><i class="fa fa-check"></i>Método de Metrópolis</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ajustando-el-tamaño-de-salto"><i class="fa fa-check"></i>Ajustando el tamaño de salto</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-16"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#por-qué-funciona-metrópolis"><i class="fa fa-check"></i>¿Por qué funciona Metrópolis?</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#metrópolis-con-varios-parámetros"><i class="fa fa-check"></i>Metrópolis con varios parámetros</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-el-modelo-normal"><i class="fa fa-check"></i>Ejemplo: el modelo normal</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-observaciones-normales-no-conjugado"><i class="fa fa-check"></i>Ejemplo: observaciones normales, no conjugado</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-exámenes"><i class="fa fa-check"></i>Ejemplo: exámenes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#muestreador-de-gibbs"><i class="fa fa-check"></i>Muestreador de Gibbs</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-dos-proporciones"><i class="fa fa-check"></i>Ejemplo: dos proporciones</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-modelo-normal-no-conjugado"><i class="fa fa-check"></i>Ejemplo: Modelo normal no conjugado</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-17"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#conclusiones-y-observaciones-metrópolis-y-gibbs"><i class="fa fa-check"></i>Conclusiones y observaciones Metrópolis y Gibbs</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#hmc-y-stan"><i class="fa fa-check"></i>HMC y Stan</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#diagnósticos-generales-para-mcmc"><i class="fa fa-check"></i>Diagnósticos generales para MCMC</a>
<ul>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#representatividad"><i class="fa fa-check"></i>Representatividad</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#precisión"><i class="fa fa-check"></i>Precisión</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#eficiencia"><i class="fa fa-check"></i>Eficiencia</a></li>
<li class="chapter" data-level="" data-path="métodos-de-cadenas-de-markov-monte-carlo.html"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#recomendaciones-generales"><i class="fa fa-check"></i>Recomendaciones generales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html"><i class="fa fa-check"></i>Apéndice: Principios de visualizacion</a>
<ul>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#el-cuarteto-de-anscombe"><i class="fa fa-check"></i>El cuarteto de Anscombe</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#introducción"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#visualización-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#teoría-de-visualización-de-datos"><i class="fa fa-check"></i>Teoría de visualización de datos</a>
<ul>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#principios-generales-del-diseño-analítico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#técnicas-de-visualización"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#indicadores-de-calidad-gráfica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#factor-de-engaño-y-chartjunk"><i class="fa fa-check"></i>Factor de engaño y Chartjunk</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#pequeños-múltiplos-y-densidad-gráfica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#decoración"><i class="fa fa-check"></i>Decoración</a></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#percepción-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndice-principios-de-visualizacion.html"><a href="apéndice-principios-de-visualizacion.html#ejemplo-gráfica-de-minard"><i class="fa fa-check"></i>Ejemplo: gráfica de Minard</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a>
<ul>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html#análisis-exploratorio-1"><i class="fa fa-check"></i>1. Análisis Exploratorio</a></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html#análisis-exploratorio---loess"><i class="fa fa-check"></i>2. Análisis Exploratorio - loess</a></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html#tipos-de-estudio-y-pgd"><i class="fa fa-check"></i>3. Tipos de estudio y PGD</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias-1.html"><a href="referencias-1.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/tereom/fundamentos-2023" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Estadística con Remuestreo</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="métodos-de-cadenas-de-markov-monte-carlo" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Sección 12</span> Métodos de Cadenas de Markov Monte Carlo<a href="métodos-de-cadenas-de-markov-monte-carlo.html#métodos-de-cadenas-de-markov-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Hasta ahora, hemos considerado modelos bayesianos <em>conjugados</em>, donde la
posterior tiene una forma conocida. Esto nos permitió simular directamente
de la posterior usando las rutinas estándar de <code>R</code>, o utilizar cálculos teóricos
o funciones estándar de <code>R</code> para calcular resúmenes de interés, como medias o
medianas posteriores o intervalos de credibilidad.</p>
<p>Sin embargo, en aplicaciones rara vez es factible este tipo de análisis tan
simple, pues:</p>
<ol style="list-style-type: decimal">
<li>Los modelos que estamos considerando son más complejos y la distribución posterior
conjunta de los parámetros no tiene una forma simple conocida.</li>
<li>Queremos usar distribuciones iniciales que no son conjugadas para utilizar correctamente
nuestra información inicial.</li>
</ol>
<p>Recordamos que tenemos expresiones explícitas para la inicial <span class="math inline">\(p(\theta)\)</span> y la verosimilitud
<span class="math inline">\(p(x|\theta)\)</span>, así que conocemos explícitamente la posterior, módulo la constante de
normalización,</p>
<p><span class="math display">\[p(\theta|x) \propto p(x|\theta) \,  p(\theta).\]</span></p>
<p>Supongamos por ejemplo que quisiéramos calcular las medias posteriores de los
parámetros <span class="math inline">\(\theta\)</span>. En teoría, tendríamos que calcular</p>
<p><span class="math display">\[\hat \theta = \mathbb{E}[{\theta}\, |\, x] = \int \theta \, p(\theta|x) \, d\theta\]</span>
Entonces es necesario calcular también <span class="math inline">\(p(x)\)</span>, que resulta de la integral
<span class="math display">\[p(x) = \int p(x|\theta) \, p(\theta)\, d\theta\]</span></p>
<p>Si no tenemos expresiones analíticas simples, tendremos que aproximar numéricamente
estas integrales de alguna forma.</p>
<ol style="list-style-type: decimal">
<li>Si la posterior tiene una forma conocida, podemos calcular cantidades de interés usando
fórmulas o rutinas de simulación de distribuciones conocidas que producen muestras independientes.</li>
</ol>
<p>Cuando la posterior no tiene una forma conocida, sin embargo:</p>
<ol start="2" style="list-style-type: decimal">
<li>Podemos intentar usar integración numérica usual. Como veremos, este enfoque no es muy escalable.</li>
<li>Podemos usar simulaciones bajo cadenas de Markov (<strong>Markov Chain Monte Carlo</strong>, MCMC),
que es un enfoque más escalable.</li>
</ol>
<p>Mucho del uso generalizado actual de la estadística bayesiana se debe a que gracias al
poder de cómputo disponible y los métodos MCMC, no estamos restringidos al uso de 1 y 2,
que tienen desventajas grandes. Primero mostraremos cómo el método de integración
por subdivisión no es escalable.</p>
<div id="integrales-mediante-subdivisiones" class="section level2 unnumbered hasAnchor">
<h2>Integrales mediante subdivisiones<a href="métodos-de-cadenas-de-markov-monte-carlo.html#integrales-mediante-subdivisiones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como tenemos una expresión analítica para el integrando, podemos intentar una
rutina numérica de integración. Una vez calculada, podríamos entonces
usar otra rutina numérica para calcular las medias posteriores <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p>Las rutinas usuales de integración pueden sernos útiles cuando el número de parámetros
es chico. Consideremos primero el caso de 1 dimensión, y supongamos que <span class="math inline">\(a\leq\theta\leq b\)</span>.</p>
<p>Si dividimos el rango de <span class="math inline">\(\theta\)</span> en intervalos determinados
por <span class="math inline">\(a = \theta^1&lt;\theta^2&lt;\cdots \theta^M =b\)</span>, tales que <span class="math inline">\(\Delta\theta = \theta^{i+1} -\theta^{i}\)</span>,
podríamos aproximar con</p>
<p><span class="math display">\[p(x) \approx \sum_{i=1}^M p(x|\theta^i)p(\theta^i) \Delta\theta\]</span>
Lo que requiere <span class="math inline">\(M\)</span> evaluaciones del factor <span class="math inline">\(p(x|\theta)p(\theta)\)</span>. Podríamos usar
por ejemplo <span class="math inline">\(M=100\)</span> para tener precisión razonable.</p>
<div id="ejemplo-estimación-de-una-proporción-1" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: estimación de una proporción<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-estimación-de-una-proporción-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Teníamos que <span class="math inline">\(p(S_n = k|\theta) \propto \theta^k(1-\theta)^{n-k}\)</span> cuando observamos <span class="math inline">\(k\)</span> éxitos
en <span class="math inline">\(n\)</span> pruebas independientes. Supongamos que nuestra inicial es <span class="math inline">\(p(\theta) = 2\theta\)</span>
(checa que es una densidad), es decir, creemos que es más probable a priori
observar proporciones altas. Podemos integrar numéricamente</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-1" aria-hidden="true" tabindex="-1"></a>crear_log_post <span class="ot">&lt;-</span> <span class="cf">function</span>(n, k){</span>
<span id="cb559-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(theta){</span>
<span id="cb559-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-3" aria-hidden="true" tabindex="-1"></a>    verosim <span class="ot">&lt;-</span> k <span class="sc">*</span> <span class="fu">log</span>(theta) <span class="sc">+</span> (n <span class="sc">-</span> k) <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> theta)</span>
<span id="cb559-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-4" aria-hidden="true" tabindex="-1"></a>    inicial <span class="ot">&lt;-</span> <span class="fu">log</span>(theta)</span>
<span id="cb559-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-5" aria-hidden="true" tabindex="-1"></a>    log_p_factor <span class="ot">&lt;-</span> verosim <span class="sc">+</span> inicial</span>
<span id="cb559-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-6" aria-hidden="true" tabindex="-1"></a>    log_p_factor</span>
<span id="cb559-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb559-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb559-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-9" aria-hidden="true" tabindex="-1"></a><span class="co"># observamos 3 éxitos en 4 pruebas:</span></span>
<span id="cb559-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-10" aria-hidden="true" tabindex="-1"></a>log_post <span class="ot">&lt;-</span> <span class="fu">crear_log_post</span>(<span class="dv">4</span>, <span class="dv">3</span>)</span>
<span id="cb559-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-11" aria-hidden="true" tabindex="-1"></a>prob_post <span class="ot">&lt;-</span> <span class="cf">function</span>(x) { <span class="fu">exp</span>(<span class="fu">log_post</span>(x))}</span>
<span id="cb559-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-12" aria-hidden="true" tabindex="-1"></a><span class="co"># integramos numéricamente</span></span>
<span id="cb559-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-13" aria-hidden="true" tabindex="-1"></a>p_x <span class="ot">&lt;-</span> <span class="fu">integrate</span>(prob_post, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>, <span class="at">subdivisions =</span> 100L)</span>
<span id="cb559-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb559-14" aria-hidden="true" tabindex="-1"></a>p_x</span></code></pre></div>
<pre><code>## 0.03333333 with absolute error &lt; 3.7e-16</code></pre>
<p>Y ahora podemos calcular la media posterior:</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb561-1" aria-hidden="true" tabindex="-1"></a>media_funcion <span class="ot">&lt;-</span> <span class="cf">function</span>(theta){</span>
<span id="cb561-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb561-2" aria-hidden="true" tabindex="-1"></a>  theta <span class="sc">*</span> <span class="fu">prob_post</span>(theta) <span class="sc">/</span> p_x<span class="sc">$</span>value</span>
<span id="cb561-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb561-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb561-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb561-4" aria-hidden="true" tabindex="-1"></a>integral_media <span class="ot">&lt;-</span> <span class="fu">integrate</span>(media_funcion, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>, <span class="at">subdivisions =</span> 100L)</span>
<span id="cb561-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb561-5" aria-hidden="true" tabindex="-1"></a>media_post <span class="ot">&lt;-</span> integral_media<span class="sc">$</span>value </span>
<span id="cb561-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb561-6" aria-hidden="true" tabindex="-1"></a>media_post</span></code></pre></div>
<pre><code>## [1] 0.7142857</code></pre>
<p>Podemos verificar nuestro trabajo pues sabemos que la posterior es <span class="math inline">\(\mathsf{Beta}(5, 2)\)</span>
cuya media es</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb563-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span><span class="sc">/</span>(<span class="dv">2</span><span class="sc">+</span><span class="dv">5</span>)</span></code></pre></div>
<pre><code>## [1] 0.7142857</code></pre>
<p>Y podríamos intentar una estrategia similar, por ejemplo, para calcular intervalos
de credibilidad. Sin embargo, veremos abajo que este método no escala con el número de
parámetros.</p>
</div>
<div id="más-de-un-parámetro" class="section level3 unnumbered hasAnchor">
<h3>Más de un parámetro<a href="métodos-de-cadenas-de-markov-monte-carlo.html#más-de-un-parámetro" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora supongamos que tenemos <span class="math inline">\(2\)</span> parámetros. Dividiríamos cada parámetro
en 100 intervalos, y luego tendríamos que calcular</p>
<p><span class="math display">\[p(x) \approx \sum_{i=1}^M \sum_{j=1}^M p(x|\theta_1^i, \theta_2^j)p(\theta_1^i, \theta_2^j) \Delta\theta_1\Delta\theta_2\]</span>
Y esto requeriría <span class="math inline">\(M^2 = 10,000\)</span> evaluaciones de <span class="math inline">\(p(x|\theta)p(\theta)\)</span>.</p>
<p>Si tenemos <span class="math inline">\(p\)</span> parámetros, entonces tendríamos que hacer <span class="math inline">\(M^p\)</span> evaluaciones de la
posterior. Incluso cuando <span class="math inline">\(p=10\)</span>, <strong>esta estrategia es infactible</strong>, pues tendríamos
que hacer más de millones de millones de millones de evaluaciones de la posterior. Si sólo
tenemos esta técnica disponible, el análisis bayesiano está considerablemente
restringido. Regresión bayesiana con unas 10 covariables por ejemplo, no podría hacerse.</p>
<p>De modo que tenemos que replantearnos cómo atacar el problema de calcular o aproximar
estas integrales.</p>
</div>
</div>
<div id="métodos-monte-carlo" class="section level2 unnumbered hasAnchor">
<h2>Métodos Monte Carlo<a href="métodos-de-cadenas-de-markov-monte-carlo.html#métodos-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En varias ocasiones anteriormente hemos usado el método Monte Carlo para
aproximar integrales: por ejemplo, para calcular medias posteriores.</p>
<p>Supongamos que tenemos una densidad <span class="math inline">\(p(\theta)\)</span>.</p>

<div class="mathblock">
<p><strong>Integración Monte Carlo</strong>. Supongamos que queremos calcular el valor esperado de
<span class="math inline">\(g(X)\)</span>, donde <span class="math inline">\(X\sim p(X\,|\,\theta).\)</span> Es decir, la variable aleatoria <span class="math inline">\(X\)</span> se
distribuye de acuerdo al modelo probabilistico <span class="math inline">\(p(X \, | \, \theta),\)</span> de tal forma que
lo que nos interesa calcular es</p>
<p><span class="math display">\[\mathbb{E}[g(X)] =  \int g(x) p(x|\theta)\, dx.\]</span></p>
<p>Si tomamos una muestra
<span class="math inline">\(x^{(1)},x^{(2)}, \ldots x^{(N)} \overset{iid}{\sim} p(x|\theta)\)</span>, entonces</p>
<p><span class="math display">\[\mathbb{E}[g(X)] \approx  \,  \frac1N \,  \sum_{n = 1}^N g(x^{(n)})\]</span></p>
cuando <span class="math inline">\(N\)</span> es grande.
</div>
<p>Esto es simplemente una manera de escribir la ley de los grandes números, y hemos
aplicado este teorema en varias ocasiones. Nos ha sido útil cuando
<strong>sabemos cómo simular de distribución</strong> <span class="math inline">\(p(\theta | x)\)</span> (usando alguna rutina de <code>R</code>, por
ejemplo, o usando un método estándar como inversión de la función de distribución acumulada).</p>
<div id="ejemplo-15" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-15" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este ejemplo repetimos cosas que ya hemos visto. En el caso de estimación
de una proporción <span class="math inline">\(\theta\)</span>, tenemos como inicial
<span class="math inline">\(p(\theta) \propto \theta\)</span>, que es <span class="math inline">\(\mathsf{Beta}(2,1)\)</span>. Si observamos 3 éxitos en 4 pruebas,
entonces sabemos que la posterior es <span class="math inline">\(p(\theta|x)\propto \theta^4(1-\theta)\)</span>, que
es <span class="math inline">\(\mathsf{Beta}(5, 2)\)</span>. Si queremos calcular media y segundo momento posterior para <span class="math inline">\(\theta\)</span>,
en teoría necesitamos calcular</p>
<p><span class="math display">\[\mu = \int_0^1 \theta p(\theta|X = 3)\, d\theta,\,\, \mu_2=\int_0^1 \theta^2 p(\theta|X = 3)\, d\theta\]</span></p>
<p>integramos con Monte Carlo</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb565-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">10000</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb565-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb565-2" aria-hidden="true" tabindex="-1"></a>media_post <span class="ot">&lt;-</span> <span class="fu">mean</span>(theta)</span>
<span id="cb565-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb565-3" aria-hidden="true" tabindex="-1"></a>momento_2_post <span class="ot">&lt;-</span> <span class="fu">mean</span>(theta<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb565-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb565-4" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(media_post, momento_2_post)</span></code></pre></div>
<pre><code>## [1] 0.7147522 0.5358191</code></pre>
<p>Y podemos aproximar de esta manera cualquier cantidad de interés que esté basada
en integrales, como probabilidades asociadas a <span class="math inline">\(\theta\)</span> o cuantiles asociados.
Por ejemplo, podemos aproximar fácilmente <span class="math inline">\(P(e^{\theta}&gt; 2|x)\)</span> haciendo</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb567-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">exp</span>(theta) <span class="sc">&gt;</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.5957</code></pre>
<p>y así sucesivamente.</p>
<p>Este enfoque, sin embargo, es mucho más flexible y poderoso.</p>
</div>
<div id="ejemplo-varias-pruebas-independientes" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: varias pruebas independientes<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-varias-pruebas-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que probamos el nivel de gusto para 4 sabores distintos de una paleta. Usamos
4 muestras de aproximadamente
50 personas diferentes para cada sabor, y cada uno evalúa si le gustó mucho o no.
Obtenemos los siguientes resultados:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb569-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb569-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb569-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">sabor =</span> <span class="fu">c</span>(<span class="st">&quot;fresa&quot;</span>, <span class="st">&quot;limón&quot;</span>, <span class="st">&quot;mango&quot;</span>, <span class="st">&quot;guanábana&quot;</span>),</span>
<span id="cb569-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb569-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">45</span>, <span class="dv">51</span>, <span class="dv">50</span>), <span class="at">gusto =</span> <span class="fu">c</span>(<span class="dv">36</span>, <span class="dv">35</span>, <span class="dv">42</span>, <span class="dv">29</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb569-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb569-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prop_gust =</span> gusto <span class="sc">/</span> n)</span>
<span id="cb569-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb569-5" aria-hidden="true" tabindex="-1"></a>datos</span></code></pre></div>
<pre><code>## # A tibble: 4 × 4
##   sabor         n gusto prop_gust
##   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
## 1 fresa        50    36     0.72 
## 2 limón        45    35     0.778
## 3 mango        51    42     0.824
## 4 guanábana    50    29     0.58</code></pre>
<p>Usaremos como inicial <span class="math inline">\(\mathsf{Beta}(2, 1)\)</span> (pues hemos obervado cierto sesgo de
cortesía en la calificación de sabores, y no es tan probable tener valores muy
bajos) para todos los sabores, es decir <span class="math inline">\(p(\theta_i)\)</span> es la funcion de densidad
de una <span class="math inline">\(\mathsf{Beta}(2, 1)\)</span>. La inicial conjunta la definimos entonces, usando
idependiencia inicial, como</p>
<p><span class="math display">\[p(\theta_1,\theta_2, \theta_3,\theta_4) = p(\theta_1)p(\theta_2)p(\theta_3)p(\theta_4).\]</span>
Pues inicialmente establecemos que ningún parámetro da información sobre otro:
saber que mango es muy gustado no nos dice nada acerca del gusto por fresa. Bajo
este supuesto, y el supuesto adicional de que las muestras de cada sabor son
independientes, podemos mostrar que las posteriores son independientes:</p>
<p><span class="math display">\[p(\theta_1,\theta_2,\theta_3, \theta_4|k_1,k_2,k_3,k_4) = p(\theta_4|k_1)p(\theta_4|k_2)p(\theta_4|k_3)p(\theta_4|k_4)\]</span></p>
<p>De forma que podemos trabajar individualmente con cada muestra. Calculamos los parámetros de las posteriores individuales:</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb571-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> datos <span class="sc">%&gt;%</span> </span>
<span id="cb571-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb571-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">a_post =</span> gusto <span class="sc">+</span> <span class="dv">2</span>, <span class="at">b_post =</span> n <span class="sc">-</span> gusto <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb571-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb571-3" aria-hidden="true" tabindex="-1"></a>datos</span></code></pre></div>
<pre><code>## # A tibble: 4 × 6
##   sabor         n gusto prop_gust a_post b_post
##   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 fresa        50    36     0.72      38     15
## 2 limón        45    35     0.778     37     11
## 3 mango        51    42     0.824     44     10
## 4 guanábana    50    29     0.58      31     22</code></pre>
<p>Ahora nos preguntamos, ¿cuál es la probabilidad posterior de que mango sea el sabor
más preferido de la población? Conocemos la posterior para cada parámetro, y sabemos
que los parámetros son independientes para la posterior. Eso quiere decir
que podemos simular de cada parámetro independientemente para obtener simulaciones
de la conjunta posterior.</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb573-1" aria-hidden="true" tabindex="-1"></a>simular_conjunta <span class="ot">&lt;-</span> <span class="cf">function</span>(rep, datos){</span>
<span id="cb573-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb573-2" aria-hidden="true" tabindex="-1"></a>  datos <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">valor_sim =</span> <span class="fu">map2_dbl</span>(a_post, b_post, <span class="sc">~</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, .x, .y))) <span class="sc">%&gt;%</span> </span>
<span id="cb573-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb573-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(sabor, valor_sim) </span>
<span id="cb573-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb573-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb573-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb573-5" aria-hidden="true" tabindex="-1"></a><span class="fu">simular_conjunta</span>(<span class="dv">1</span>, datos) </span></code></pre></div>
<pre><code>## # A tibble: 4 × 2
##   sabor     valor_sim
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 fresa         0.752
## 2 limón         0.796
## 3 mango         0.889
## 4 guanábana     0.557</code></pre>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="co"># esta no es una manera muy rápida, podríamos calcular todas las</span></span>
<span id="cb575-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb575-2" aria-hidden="true" tabindex="-1"></a><span class="co"># simulaciones de cada parámetro de manera vectorizada</span></span>
<span id="cb575-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb575-3" aria-hidden="true" tabindex="-1"></a>sims_posterior <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">rep =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5000</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb575-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb575-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sims =</span> <span class="fu">map</span>(rep, <span class="sc">~</span> <span class="fu">simular_conjunta</span>(.x, datos))) <span class="sc">%&gt;%</span> </span>
<span id="cb575-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb575-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> sims)</span>
<span id="cb575-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb575-6" aria-hidden="true" tabindex="-1"></a>sims_posterior</span></code></pre></div>
<pre><code>## # A tibble: 20,000 × 3
##      rep sabor     valor_sim
##    &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;
##  1     1 fresa         0.793
##  2     1 limón         0.836
##  3     1 mango         0.861
##  4     1 guanábana     0.621
##  5     2 fresa         0.777
##  6     2 limón         0.819
##  7     2 mango         0.895
##  8     2 guanábana     0.711
##  9     3 fresa         0.677
## 10     3 limón         0.840
## # ℹ 19,990 more rows</code></pre>
<p>Y ahora podemos aproximar fácilmente la probabilidad de interés:</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-1" aria-hidden="true" tabindex="-1"></a>sims_posterior <span class="sc">%&gt;%</span> </span>
<span id="cb577-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(rep) <span class="sc">%&gt;%</span> </span>
<span id="cb577-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sabor =</span> sabor[<span class="fu">which.max</span>(valor_sim)]) <span class="sc">%&gt;%</span> </span>
<span id="cb577-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(sabor) <span class="sc">%&gt;%</span> </span>
<span id="cb577-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb577-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb577-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb577-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prop =</span> n <span class="sc">/</span> <span class="fu">sum</span>(n))</span></code></pre></div>
<pre><code>## # A tibble: 4 × 3
##   sabor         n   prop
##   &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;
## 1 fresa      1192 0.0596
## 2 guanábana     8 0.0004
## 3 limón      5504 0.275 
## 4 mango     13296 0.665</code></pre>
<p>Y vemos que los mejores sabores son mango y limón. La probabilidad posterior de
que mango sea el sabor preferido por la población es de 66%. La integral correspondiente
no es trivial.</p>

<div class="ejercicio">
<ul>
<li>¿Cuáles son las probabilidades a priori de que cada sabor sea el preferido
por la población?</li>
<li>¿Cuál es la integral correspondiente a las probabilidades que acabamos de calcular?
¿Qué tan fácil es hacer esta integral de manera analítica?</li>
<li>Calcula la probabilidad de que mango sea preferido a limón?</li>
<li>¿Qué conclusión práctica sacas de estos resultados?
</div></li>
</ul>
</div>
</div>
<div id="simulando-de-la-posterior" class="section level2 unnumbered hasAnchor">
<h2>Simulando de la posterior<a href="métodos-de-cadenas-de-markov-monte-carlo.html#simulando-de-la-posterior" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hemos establecido que podemos contestar varias preguntas de inferencia
usando simulación Monte Carlo, y que este enfoque es potencialmente
escalable (en contraste con métodos de integración numérica por cuadrícula). Ahora
el problema que necesitamos resolver es el siguiente:</p>
<ul>
<li>Conocemos <span class="math inline">\(p(\theta |x)\)</span> módulo una constante de integración.</li>
<li>En general, <span class="math inline">\(p(\theta|x)\)</span> no tiene una forma reconocible que corresponda a un
simulador estándar.</li>
<li>¿Cómo simulamos de esta posterior cuando sólo sabemos calcular <span class="math inline">\(p(x|\theta)p(\theta)\)</span>?</li>
</ul>
<p>Hay varias maneras de hacer esto. Presentaremos los algoritmos en términos
de una distribución cualquiera <span class="math inline">\(p(\theta) = K f(\theta)\)</span>, donde sólo conocemos
la función <span class="math inline">\(f(\theta)\)</span>.</p>
</div>
<div id="método-de-metrópolis" class="section level2 unnumbered hasAnchor">
<h2>Método de Metrópolis<a href="métodos-de-cadenas-de-markov-monte-carlo.html#método-de-metrópolis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el método de Metrópolis, uno de los más antiguos, comenzamos
con un valor inicial de los parámetros <span class="math inline">\(\theta^{(0)}\)</span> en el soporte de <span class="math inline">\(p(\theta)\)</span>,
es decir <span class="math inline">\(p(\theta^{(0)})&gt;0.\)</span></p>
<p>Para <span class="math inline">\(i=1, \ldots, M\)</span>, hacemos:</p>
<ol style="list-style-type: decimal">
<li>Partiendo de <span class="math inline">\(\theta^{(i)}\)</span>, hacemos un salto
corto en una dirección al azar para obtener una propuesta <span class="math inline">\(\theta^* \sim q(\theta \, |\, \theta^{(i)}).\)</span></li>
<li>Aceptamos or rechazamos el salto:</li>
</ol>
<ul>
<li>Si <span class="math inline">\(\alpha = \frac{f(\theta^*)}{f(\theta^{(i)})} \geq 1\)</span>, aceptamos el salto
y ponemos <span class="math inline">\(\theta^{(i+1)}=\theta^*\)</span>. Regresamos a 1 para la siguiente
iteración <span class="math inline">\(i\leftarrow i + 1.\)</span></li>
<li>Si <span class="math inline">\(\alpha = \frac{f(\theta^*)}{f(\theta^{(i)})} &lt; 1\)</span>, entonces aceptamos
con probabilidad <span class="math inline">\(\alpha\)</span> el salto, ponemos <span class="math inline">\(\theta^{(i+1)}=\theta^*\)</span> y
regresamos a 1 para la siguiente iteración <span class="math inline">\(i\leftarrow i + 1\)</span>. Si rechazamos
el salto, ponemos entonces <span class="math inline">\(\theta^{(i+1)}=\theta^{(i)}\)</span> y regresamos a 1 para
la siguiente iteración <span class="math inline">\(i\leftarrow i + 1.\)</span></li>
</ul>
<p>Requerimos también que la función que propone los saltos sea simétrica: es
decir, <span class="math inline">\(q(\theta^*|\theta^{(i)})\)</span> debe ser igual a <span class="math inline">\(q(\theta^{(i)}|\theta^*)\)</span>.
Se puede modificar el algoritmo para tratar con una propuesta que no sea
simétrica.</p>
<p>Una elección común es escoger <span class="math inline">\(q(\theta^* |\theta^{(i)})\)</span> como
una <span class="math inline">\(\mathsf{N}(\theta^{(i)}, \sigma_{salto})\)</span>.</p>
<div class="comentario">
<p>
En este curso, escribiremos varios métodos de cadenas de Markov para
estimación Monte Carlo (<em>Markov Chain Monte Carlo</em>, MCMC) desde
cero para entender los básicos de cómo funciona. Sin embargo, <strong>en
la práctica no hacemos esto</strong>, sino que usamos software estándar
(Stan, JAGS, BUGS, etc.) para hacer este trabajo.
</p>
<p>
<strong>Expertos</strong> en MCMC, métodos numéricos, y estadística a
veces escriben partes de sus rutinas de simulación, y pueden lograr
mejoras de desempeño considerables. Excepto para modelos simples, esto
no es trivial de hacer garantizando resultados correctos.
</p>
</div>
<p>En resumen, todo el código de esta sección es de carácter ilustrativo.
Utiliza implementaciones establecidas en las aplicaciones.</p>
<p>Abajo implementamos el algoritmo con un salto de tipo normal:</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-1" aria-hidden="true" tabindex="-1"></a>crear_metropolis <span class="ot">&lt;-</span> <span class="cf">function</span>(fun_log, <span class="at">sigma_salto =</span> <span class="fl">0.1</span>){</span>
<span id="cb579-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># la entrada es la log posterior</span></span>
<span id="cb579-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-3" aria-hidden="true" tabindex="-1"></a>  iterar_metropolis <span class="ot">&lt;-</span> <span class="cf">function</span>(theta_inicial, n){</span>
<span id="cb579-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-4" aria-hidden="true" tabindex="-1"></a>    p <span class="ot">&lt;-</span> <span class="fu">length</span>(theta_inicial)</span>
<span id="cb579-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-5" aria-hidden="true" tabindex="-1"></a>    nombres <span class="ot">&lt;-</span> <span class="fu">names</span>(theta_inicial)</span>
<span id="cb579-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-6" aria-hidden="true" tabindex="-1"></a>    iteraciones <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n, <span class="at">ncol =</span> p)</span>
<span id="cb579-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">colnames</span>(iteraciones) <span class="ot">&lt;-</span> nombres</span>
<span id="cb579-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-8" aria-hidden="true" tabindex="-1"></a>    iteraciones[<span class="dv">1</span>,] <span class="ot">&lt;-</span> theta_inicial</span>
<span id="cb579-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb579-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-10" aria-hidden="true" tabindex="-1"></a>      theta <span class="ot">&lt;-</span> iteraciones[i <span class="sc">-</span> <span class="dv">1</span>, ]</span>
<span id="cb579-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-11" aria-hidden="true" tabindex="-1"></a>      theta_prop <span class="ot">&lt;-</span> theta <span class="sc">+</span> <span class="fu">rnorm</span>(p, <span class="dv">0</span>, sigma_salto)</span>
<span id="cb579-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-12" aria-hidden="true" tabindex="-1"></a>      <span class="co"># exp(log(p) - log(q)) = p/q</span></span>
<span id="cb579-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-13" aria-hidden="true" tabindex="-1"></a>      cociente <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fun_log</span>(theta_prop) <span class="sc">-</span> <span class="fu">fun_log</span>(theta))</span>
<span id="cb579-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-14" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(cociente <span class="sc">&gt;=</span> <span class="dv">1</span> <span class="sc">||</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">&lt;</span> cociente){</span>
<span id="cb579-15"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-15" aria-hidden="true" tabindex="-1"></a>        iteraciones[i, ] <span class="ot">&lt;-</span> theta_prop</span>
<span id="cb579-16"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-16" aria-hidden="true" tabindex="-1"></a>      } <span class="cf">else</span> {</span>
<span id="cb579-17"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-17" aria-hidden="true" tabindex="-1"></a>        iteraciones[i, ] <span class="ot">&lt;-</span> theta  </span>
<span id="cb579-18"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-18" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb579-19"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-19" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb579-20"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-20" aria-hidden="true" tabindex="-1"></a>    iteraciones_tbl <span class="ot">&lt;-</span> iteraciones <span class="sc">%&gt;%</span> </span>
<span id="cb579-21"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb579-22"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">iter_num =</span> <span class="fu">row_number</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb579-23"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">select</span>(iter_num, <span class="fu">everything</span>())</span>
<span id="cb579-24"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-24" aria-hidden="true" tabindex="-1"></a>    iteraciones_tbl</span>
<span id="cb579-25"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb579-26"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-26" aria-hidden="true" tabindex="-1"></a>  iterar_metropolis</span>
<span id="cb579-27"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb579-27" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>E intentamos simular de una exponencial no normalizada:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-1" aria-hidden="true" tabindex="-1"></a>exp_no_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb580-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-2" aria-hidden="true" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(x <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="fu">exp</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> x), <span class="dv">0</span>)</span>
<span id="cb580-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">log</span>(z)</span>
<span id="cb580-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb580-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb580-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-6" aria-hidden="true" tabindex="-1"></a>iterador_metro <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(exp_no_norm, <span class="at">sigma_salto =</span> <span class="fl">0.25</span>)</span>
<span id="cb580-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-7" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="ot">&lt;-</span> <span class="fu">iterador_metro</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.5</span>), <span class="dv">50000</span>)</span>
<span id="cb580-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb580-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sims_tbl, <span class="fu">aes</span>(<span class="at">x =</span> theta)) <span class="sc">+</span> <span class="fu">geom_histogram</span>()</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-15-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Ahora probemos con una <span class="math inline">\(\mathsf{Beta}(3, 2):\)</span></p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-1" aria-hidden="true" tabindex="-1"></a>beta_no_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb581-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-2" aria-hidden="true" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(x <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;&amp;</span> x <span class="sc">&lt;</span> <span class="dv">1</span>, (x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>x), <span class="dv">0</span>)</span>
<span id="cb581-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">log</span>(z)</span>
<span id="cb581-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb581-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb581-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-6" aria-hidden="true" tabindex="-1"></a>iterador_metro <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(beta_no_norm, <span class="at">sigma_salto =</span> <span class="fl">0.04</span>)</span>
<span id="cb581-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-7" aria-hidden="true" tabindex="-1"></a>sims_metro_tbl <span class="ot">&lt;-</span> <span class="fu">iterador_metro</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.5</span>), <span class="dv">50000</span>)</span>
<span id="cb581-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-8" aria-hidden="true" tabindex="-1"></a>sims_indep_tbl <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">iter_num =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">30000</span>, <span class="at">theta =</span> <span class="fu">rbeta</span>(<span class="dv">30000</span>, <span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb581-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-9" aria-hidden="true" tabindex="-1"></a>g_1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_metro_tbl, <span class="fu">aes</span>(<span class="at">x =</span> theta)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb581-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Metrópolis&quot;</span>)</span>
<span id="cb581-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-11" aria-hidden="true" tabindex="-1"></a>g_2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_indep_tbl, <span class="fu">aes</span>(<span class="at">x =</span> theta)) <span class="sc">+</span> </span>
<span id="cb581-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb581-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;rbeta&quot;</span>)</span>
<span id="cb581-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb581-14" aria-hidden="true" tabindex="-1"></a>g_1 <span class="sc">+</span> g_2</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-16-1.png" width="480" style="display: block; margin: auto;" />
Y vemos que esto funciona. Revisa el ejemplo de las islas en <span class="citation">Kruschke (<a href="#ref-Kruschke" role="doc-biblioref">2015</a>)</span> (7.2) para
tener más intuición de cómo funciona este algoritmo.</p>
<p>Nótese sin embargo un aspecto de estas simulaciones que no habíamos encontrado
en el curso. Aunque la distribución final de las simulaciones es muy cercana
a la de la distribución que queremos simular, lo cual era nuestro propósito,
las <strong>simulaciones no son extracciones independientes</strong> de esa distribución.</p>
<p>La construcción del algoritmo muestra eso, pero podemos también graficar las
simulaciones:</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-1" aria-hidden="true" tabindex="-1"></a>g_metropolis <span class="ot">&lt;-</span> sims_metro_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb582-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb582-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> theta)) <span class="sc">+</span></span>
<span id="cb582-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Metrópolis&quot;</span>)</span>
<span id="cb582-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-5" aria-hidden="true" tabindex="-1"></a>g_indep <span class="ot">&lt;-</span> sims_indep_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb582-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb582-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> theta)) <span class="sc">+</span></span>
<span id="cb582-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Independientes&quot;</span>)</span>
<span id="cb582-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb582-9" aria-hidden="true" tabindex="-1"></a>g_metropolis <span class="sc">+</span> g_indep</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-17-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Donde vemos claramente que las simulaciones de metropolis están autocorrelacionadas:
la siguiente simulación depende de la anterior. Esto define una cadena de Markov.</p>
<p>En cualquiera de los dos casos, como vimos en los histogramas de arriba,
las simulaciones “visitan” cada parte [0,1] de manera proporcional a la densidad,
de manera que podemos usar ambos tipos de simulaciones para aproximar la integral
o cantidad que nos interesa. Por ejemplo, la media posterior es:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb583-1" aria-hidden="true" tabindex="-1"></a>media_1 <span class="ot">&lt;-</span> sims_metro_tbl <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">media_post =</span> <span class="fu">mean</span>(theta)) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(media_post)</span>
<span id="cb583-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb583-2" aria-hidden="true" tabindex="-1"></a>media_2 <span class="ot">&lt;-</span> sims_indep_tbl <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">media_post =</span> <span class="fu">mean</span>(theta)) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(media_post)</span>
<span id="cb583-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb583-3" aria-hidden="true" tabindex="-1"></a>media_exacta <span class="ot">&lt;-</span> <span class="dv">3</span><span class="sc">/</span>(<span class="dv">3</span> <span class="sc">+</span> <span class="dv">2</span>)</span>
<span id="cb583-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb583-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">metodo =</span> <span class="fu">c</span>(<span class="st">&quot;sim Metrópolis&quot;</span>, <span class="st">&quot;sim Independiente&quot;</span>, <span class="st">&quot;exacto&quot;</span>),</span>
<span id="cb583-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb583-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">media_post =</span> <span class="fu">c</span>(media_1, media_2, media_exacta))</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   metodo            media_post
##   &lt;chr&gt;                  &lt;dbl&gt;
## 1 sim Metrópolis         0.603
## 2 sim Independiente      0.599
## 3 exacto                 0.6</code></pre>
<div class="mathblock">
<p>
Supongamos que queremos simular de una distribución <span class="math inline"><span class="math inline">\(p(\theta)\)</span></span>, pero sólo conocemos <span class="math inline"><span class="math inline">\(p(\theta)\)</span></span> módulo una constante. Bajo
ciertas condiciones de regularidad:
</p>
<p>
El <strong>algoritmo Metrópolis</strong> para la distribución <span class="math inline"><span class="math inline">\(p(\theta)\)</span></span> define una <strong>cadena de
Markov</strong> cuya distribución a largo plazo es <span class="math inline"><span class="math inline">\(p(\theta)\)</span></span>. Esto implica que si <span class="math inline"><span class="math inline">\(\theta^{(1)},\theta^{(2)}, \ldots, \theta^{(M)}\)</span></span> es una simulación de esta cadena, y <span class="math inline"><span class="math inline">\(M\)</span></span> es suficientemente grande
</p>
<ol style="list-style-type: decimal">
<li>
La distribución de las <span class="math inline"><span class="math inline">\(\theta^{(i)}\)</span></span> es aproximadamente <span class="math inline"><span class="math inline">\(p(\theta)\)</span></span>,
</li>
<li>
Tenemos que <span class="math display"><span class="math display">\[ \frac1M \sum_{m = 1}^M
h(\theta^{(m)}) \to \int h(\theta)p(\theta)\, d\theta\]</span></span> cuando
<span class="math inline"><span class="math inline">\(M\to \infty\)</span></span>
</li>
</ol>
</div>
<p><strong>Observaciones</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Aunque hay distintas <em>condiciones de regularidad</em> que pueden funcionar,
generalmente el supuesto es que la cadena de Markov construída es
<a href="https://en.wikipedia.org/wiki/Ergodic_theory">ergódica</a>, y hay varias
condiciones que garantizan esta propiedad. Una condición simple, por ejemplo, es
que el soporte de la distribución <span class="math inline">\(p(\theta)\)</span> es un conjunto conexo del espacio
de parámetros.</p></li>
<li><p>Más crucialmente, este resultado no dice qué tan grande debe ser <span class="math inline">\(M\)</span> para que
la aproximación sea buena. Esto depende de cómo es <span class="math inline">\(p(\theta)\)</span>, y de la
distribución que se utiliza para obtener los saltos propuestos. Dependiendo de
estos dos factores, la convergencia puede ser rápida (exponencial) o tan lenta
que es infactible usarla. Más adelante veremos diagnósticos para descartar los
peores casos de falta de convergencia.</p></li>
</ol>
</div>
<div id="ajustando-el-tamaño-de-salto" class="section level2 unnumbered hasAnchor">
<h2>Ajustando el tamaño de salto<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ajustando-el-tamaño-de-salto" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el algoritmo Metrópolis, generalmente es importante escoger la
dispersión de la distribución que genera propuestas con cuidado.</p>
<ul>
<li>Si la dispersión de la propuesta es demasiado grande, tenderemos a rechazar mucho,
y la convergencia será lenta.</li>
<li>Si la dispersión de la propuesta es demasiado chica, tardaremos mucho tiempo
en explorar las distintas partes de la distribución objetivo.</li>
</ul>
<div id="ejemplo-16" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-16" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que queremos simular usando metróplis de una distribución
<span class="math inline">\(\textsf{Gamma}(20, 100)\)</span>. Abajo vemos la forma de esta distribución:</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb585-1" aria-hidden="true" tabindex="-1"></a>sim_indep <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">theta =</span> <span class="fu">rgamma</span>(<span class="dv">10000</span>, <span class="dv">20</span>, <span class="dv">100</span>))</span>
<span id="cb585-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb585-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_indep, <span class="fu">aes</span>(<span class="at">x =</span> theta)) <span class="sc">+</span> <span class="fu">geom_histogram</span>()</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-20-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-1" aria-hidden="true" tabindex="-1"></a><span class="co"># logaritmo de densidad no normalizada</span></span>
<span id="cb586-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-2" aria-hidden="true" tabindex="-1"></a>log_f_dist <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="dv">210</span> <span class="sc">+</span> <span class="fu">dgamma</span>(x, <span class="dv">20</span>, <span class="dv">100</span>, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb586-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-3" aria-hidden="true" tabindex="-1"></a><span class="co"># iterar</span></span>
<span id="cb586-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-4" aria-hidden="true" tabindex="-1"></a>iterador_metro_chico <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_f_dist, <span class="at">sigma_salto =</span> <span class="fl">0.001</span>)</span>
<span id="cb586-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-5" aria-hidden="true" tabindex="-1"></a>sims_chico_tbl <span class="ot">&lt;-</span> <span class="fu">iterador_metro_chico</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.02</span>), <span class="dv">50000</span>)</span>
<span id="cb586-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-6" aria-hidden="true" tabindex="-1"></a>g_sim <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_chico_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">3000</span>), <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> theta)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb586-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-7" aria-hidden="true" tabindex="-1"></a>dist_bplot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">rgamma</span>(<span class="dv">10000</span>, <span class="dv">20</span>, <span class="dv">100</span>)), <span class="fu">aes</span>(<span class="at">y =</span> x, <span class="at">x =</span> <span class="st">&quot;a&quot;</span>)) <span class="sc">+</span> <span class="fu">geom_violin</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;&quot;</span>) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb586-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb586-8" aria-hidden="true" tabindex="-1"></a>g_sim <span class="sc">+</span> dist_bplot <span class="sc">+</span> <span class="fu">plot_layout</span>(<span class="at">widths =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-21-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Nótese que después de 5 mil iteraciones estamos muy lejos de tener una muestra
que se aproxime a la distribución objetivo. Empezamos en un lugar bajo, y la
cadena sólo ha ido lentamente hacia las zonas de alta densidad. <em>Cualquier
resumen con esta cadena estaría fuertemente sesgado</em> al valor donde iniciamos la
iteración. Decimos que la cadena todavía no <em>mezcla</em> en las primeras 5 mil
iteraciones.</p>
<p>Ahora vemos qué pasa si ponemos el tamaño de salto demasiado grande:</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb587-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">831</span>)</span>
<span id="cb587-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb587-2" aria-hidden="true" tabindex="-1"></a>iterador_metro_grande <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_f_dist, <span class="at">sigma_salto =</span> <span class="dv">20</span>)</span>
<span id="cb587-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb587-3" aria-hidden="true" tabindex="-1"></a>sims_grande_tbl <span class="ot">&lt;-</span> <span class="fu">iterador_metro_grande</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.02</span>), <span class="dv">50000</span>)</span>
<span id="cb587-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb587-4" aria-hidden="true" tabindex="-1"></a>g_sim <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_grande_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">3000</span>), <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> theta)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb587-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb587-5" aria-hidden="true" tabindex="-1"></a>g_sim <span class="sc">+</span> dist_bplot <span class="sc">+</span> <span class="fu">plot_layout</span>(<span class="at">widths =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-22-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>En este caso, la cadena se <em>atora</em> muchas veces, pues las propuestas tienen
probabilidad muy baja, y tendemos a tener una tasa de rechazos muy alta. Esto
quiere decir que la información que tenemos acerca de la posterior es
relativamente poca, pues muchos datos son repeticiones del mismo valor.
<em>Cualquier resumen con esta cadena podría estar muy lejos del verdadero valor,</em>
pues su varianza es alta - otra corrida se “atoraría” en otros valores
distintos.</p>
<p>Nótese que cualquiera de estas cadenas, si la corremos suficientemente tiempo,
nos daría resultados buenos. Sin embargo, el número de simulaciones puede ser
infactible.</p>
<p>Un valor intermedio nos dará mucho mejores resultados:</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb588-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">831</span>)</span>
<span id="cb588-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb588-2" aria-hidden="true" tabindex="-1"></a>iterador_metro_apropiada <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_f_dist, <span class="at">sigma_salto =</span> <span class="fl">0.1</span>)</span>
<span id="cb588-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb588-3" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="ot">&lt;-</span><span class="fu">iterador_metro_apropiada</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.02</span>), <span class="dv">50000</span>)</span>
<span id="cb588-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb588-4" aria-hidden="true" tabindex="-1"></a>g_sim <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">3000</span>), </span>
<span id="cb588-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb588-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> theta)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb588-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb588-6" aria-hidden="true" tabindex="-1"></a>g_sim <span class="sc">+</span> dist_bplot <span class="sc">+</span> <span class="fu">plot_layout</span>(<span class="at">widths =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-23-1.png" width="480" style="display: block; margin: auto;" />
Donde vemos que esta cadena parece mezclar bien (está explorando la totalidad
de la distribución objetivo), y también parece estar en un estado estable.</p>
<p>Comparemos cómo saldría por ejemplo la media posterior aproximada según
los tres métodos:</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-1" aria-hidden="true" tabindex="-1"></a>estimaciones_media <span class="ot">&lt;-</span> <span class="fu">map_dfr</span>(</span>
<span id="cb589-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(sims_chico_tbl, sims_grande_tbl, sims_tbl), </span>
<span id="cb589-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span> <span class="fu">filter</span>(.x, iter_num <span class="sc">&lt;</span> <span class="dv">3000</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb589-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">media =</span> <span class="fu">mean</span>(theta))) <span class="sc">%&gt;%</span> </span>
<span id="cb589-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">tipo =</span> <span class="fu">c</span>(<span class="st">&quot;salto chico&quot;</span>, <span class="st">&quot;salto grande&quot;</span>, <span class="st">&quot;salto apropiado&quot;</span>))</span>
<span id="cb589-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-6" aria-hidden="true" tabindex="-1"></a>estimaciones_media <span class="sc">%&gt;%</span> <span class="fu">bind_rows</span>(<span class="fu">tibble</span>(<span class="at">tipo =</span> <span class="st">&quot;exacta&quot;</span>, <span class="at">media =</span> <span class="dv">20</span><span class="sc">/</span><span class="dv">100</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb589-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb589-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(tipo, media)</span></code></pre></div>
<pre><code>## # A tibble: 4 × 2
##   tipo            media
##   &lt;chr&gt;           &lt;dbl&gt;
## 1 salto chico     0.101
## 2 salto grande    0.190
## 3 salto apropiado 0.203
## 4 exacta          0.2</code></pre>
<p>Veamos otra corrida:</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6222131</span>)</span>
<span id="cb591-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-2" aria-hidden="true" tabindex="-1"></a>sims_chica_tbl <span class="ot">&lt;-</span> <span class="fu">iterador_metro_chico</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.02</span>), <span class="dv">5000</span>)</span>
<span id="cb591-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-3" aria-hidden="true" tabindex="-1"></a>sims_grande_tbl <span class="ot">&lt;-</span> <span class="fu">iterador_metro_grande</span>(<span class="fu">c</span>(<span class="at">theta =</span> <span class="fl">0.02</span>), <span class="dv">5000</span>)</span>
<span id="cb591-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-4" aria-hidden="true" tabindex="-1"></a>estimaciones_media <span class="ot">&lt;-</span> <span class="fu">map_dfr</span>(</span>
<span id="cb591-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(sims_chica_tbl, sims_grande_tbl, sims_tbl), </span>
<span id="cb591-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-6" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> <span class="fu">filter</span>(.x, iter_num <span class="sc">&lt;</span> <span class="dv">3000</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb591-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">media =</span> <span class="fu">mean</span>(theta))) <span class="sc">%&gt;%</span> </span>
<span id="cb591-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">tipo =</span> <span class="fu">c</span>(<span class="st">&quot;salto chico&quot;</span>, <span class="st">&quot;salto grande&quot;</span>, <span class="st">&quot;salto apropiado&quot;</span>))</span>
<span id="cb591-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-9" aria-hidden="true" tabindex="-1"></a>estimaciones_media <span class="sc">%&gt;%</span> <span class="fu">bind_rows</span>(<span class="fu">tibble</span>(<span class="at">tipo =</span> <span class="st">&quot;exacta&quot;</span>, <span class="at">media =</span> <span class="dv">20</span><span class="sc">/</span><span class="dv">100</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb591-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb591-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(tipo, media)</span></code></pre></div>
<pre><code>## # A tibble: 4 × 2
##   tipo            media
##   &lt;chr&gt;           &lt;dbl&gt;
## 1 salto chico     0.124
## 2 salto grande    0.229
## 3 salto apropiado 0.203
## 4 exacta          0.2</code></pre>
<div class="ejercicio">
<p>
Repite este proceso varias veces. Verifica que:
</p>
<ul>
<li>
Si el tamaño de paso es muy chico, las estimaciones de la media
tienen sesgo alto.
</li>
<li>
Si el tamaño de paso es muy grande, las estimaciones tienen varianza
alta.
</li>
<li>
Si el tamaño de paso es adecuado, obtenemos buena precisión en la
estimación de la media posterior.
</li>
<li>
Explica estos tres casos en términos de la convergencia de las
realizaciones de la cadena de Markov. Explica cómo afecta a cada caso el
valor inicial de las simulaciones de Metrópolis.
</li>
<li>
Repite para otra estadística, como la desviación estándar o el
rangon intercuartil.
</li>
</ul>
</div>
</div>
</div>
<div id="por-qué-funciona-metrópolis" class="section level2 unnumbered hasAnchor">
<h2>¿Por qué funciona Metrópolis?<a href="métodos-de-cadenas-de-markov-monte-carlo.html#por-qué-funciona-metrópolis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Veremos un ejemplo relativemente simple que nos puede ayudar
a mejorar nuestra intuición acerca de este algoritmo.</p>
<p>Supongamos que un vendedor de <em>Yakult</em> trabaja a lo largo de una cadena de
islas:</p>
<ul>
<li><p>Constantemente viaja entre las islas ofreciendo sus productos;</p></li>
<li><p>Al final de un día de trabajo decide si permanece en la misma isla o se
transporta a una de las <span class="math inline">\(2\)</span> islas vecinas;</p></li>
<li><p>El vendedor ignora la distribución de la población en las islas y el número
total de islas; sin embargo, una vez que se encuentra en una isla puede
investigar la población de la misma y también de la isla a la que se propone
viajar después.</p></li>
<li><p>El objetivo del vendedor es visitar las islas de manera proporcional a la
población de cada una. Con esto en mente el vendedor utiliza el siguiente
proceso:</p>
<ol style="list-style-type: decimal">
<li>Lanza un volado, si el resultado es águila se propone ir a la isla
del lado izquierdo de su ubicación actual y si es sol a la del lado derecho.</li>
<li>Si la isla propuesta en el paso anterior tiene población mayor a la
población de la isla actual, el vendedor decide viajar a ella. Si la isla vecina
tiene población menor, entonces visita la isla propuesta con una probabilidad que
depende de la población de las islas. Sea <span class="math inline">\(P^*\)</span> la población de la isla
propuesta y <span class="math inline">\(P_{t}\)</span> la población de la isla actual. Entonces el vendedor
cambia de isla con probabilidad
<span class="math display">\[q_{mover}=P^*/P_{t}\]</span></li>
</ol></li>
</ul>
<p>A la larga, si el vendedor sigue la heurística anterior la probabilidad de que
el vendedor este en alguna de las islas coincide con la población relativa de
la isla.</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-1" aria-hidden="true" tabindex="-1"></a>islas <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">islas =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">pob =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb593-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-2" aria-hidden="true" tabindex="-1"></a>camina_isla <span class="ot">&lt;-</span> <span class="cf">function</span>(i){ <span class="co"># i: isla actual</span></span>
<span id="cb593-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-3" aria-hidden="true" tabindex="-1"></a>    u <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>) <span class="co"># volado</span></span>
<span id="cb593-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-4" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(u <span class="sc">&lt;</span> <span class="fl">0.5</span>, i <span class="sc">-</span> <span class="dv">1</span>, i <span class="sc">+</span> <span class="dv">1</span>)  <span class="co"># isla vecina (índice)</span></span>
<span id="cb593-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (v <span class="sc">&lt;</span> <span class="dv">1</span> <span class="sc">|</span> v <span class="sc">&gt;</span> <span class="dv">10</span>) { <span class="co"># si estas en los extremos y el volado indica salir</span></span>
<span id="cb593-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(i)</span>
<span id="cb593-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb593-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-8" aria-hidden="true" tabindex="-1"></a>    u2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb593-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-9" aria-hidden="true" tabindex="-1"></a>    p_move <span class="ot">=</span> <span class="fu">min</span>(islas<span class="sc">$</span>pob[v] <span class="sc">/</span> islas<span class="sc">$</span>pob[i], <span class="dv">1</span>)</span>
<span id="cb593-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (p_move  <span class="sc">&gt;</span> u2) {</span>
<span id="cb593-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(v) <span class="co"># isla destino</span></span>
<span id="cb593-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-12" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb593-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> {</span>
<span id="cb593-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(i) <span class="co"># me quedo en la misma isla</span></span>
<span id="cb593-15"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-15" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb593-16"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb593-17"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-17" aria-hidden="true" tabindex="-1"></a>pasos <span class="ot">&lt;-</span> <span class="dv">100000</span></span>
<span id="cb593-18"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-18" aria-hidden="true" tabindex="-1"></a>iteraciones <span class="ot">&lt;-</span> <span class="fu">numeric</span>(pasos)</span>
<span id="cb593-19"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-19" aria-hidden="true" tabindex="-1"></a>iteraciones[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">1</span>) <span class="co"># isla inicial</span></span>
<span id="cb593-20"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>pasos) {</span>
<span id="cb593-21"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-21" aria-hidden="true" tabindex="-1"></a>    iteraciones[j] <span class="ot">&lt;-</span> <span class="fu">camina_isla</span>(iteraciones[j <span class="sc">-</span> <span class="dv">1</span>])</span>
<span id="cb593-22"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb593-23"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-23" aria-hidden="true" tabindex="-1"></a>caminata <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">pasos =</span> <span class="dv">1</span><span class="sc">:</span>pasos, <span class="at">isla =</span> iteraciones)</span>
<span id="cb593-24"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-24" aria-hidden="true" tabindex="-1"></a>plot_caminata <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(caminata[<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>, ], <span class="fu">aes</span>(<span class="at">x =</span> pasos, <span class="at">y =</span> isla)) <span class="sc">+</span></span>
<span id="cb593-25"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb593-26"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb593-27"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_flip</span>() <span class="sc">+</span> </span>
<span id="cb593-28"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Caminata aleatoria&quot;</span>) <span class="sc">+</span></span>
<span id="cb593-29"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="fu">expression</span>(theta), <span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb593-30"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="st">&quot;Tiempo&quot;</span>)</span>
<span id="cb593-31"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-31" aria-hidden="true" tabindex="-1"></a>plot_dist <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(caminata, <span class="fu">aes</span>(<span class="at">x =</span> isla)) <span class="sc">+</span></span>
<span id="cb593-32"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb593-33"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="fu">expression</span>(theta), <span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb593-34"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Distribución objetivo&quot;</span>, </span>
<span id="cb593-35"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">expression</span>(<span class="fu">P</span>(theta)))</span>
<span id="cb593-36"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb593-36" aria-hidden="true" tabindex="-1"></a>plot_caminata <span class="sc">/</span> plot_dist</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-27-1.png" width="336" style="display: block; margin: auto;" /></p>
<p>Entonces:</p>
<ul>
<li><p>Para aproximar la distribución objetivo debemos permitir que el vendedor
recorra las islas durante una sucesión larga de pasos y registramos sus visitas.</p></li>
<li><p>Nuestra aproximación de la distribución es justamente el registro de sus
visitas.</p></li>
<li><p>Más aún, debemos tener cuidado y excluir la porción de las visitas que se
encuentran bajo la influencia de la posición inicial. Esto es, debemos excluir
el <strong>periodo de calentamiento</strong>.</p></li>
<li><p>Una vez que tenemos un registro <em>largo</em> de los viajes del vendedor (excluyendo
el calentamiento) podemos aproximar la distribución objetivo
simplemente contando el número relativo de veces que el vendedor visitó
dicha isla.</p></li>
</ul>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">1000</span>, <span class="dv">5000</span>)</span>
<span id="cb594-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-2" aria-hidden="true" tabindex="-1"></a>plots_list <span class="ot">&lt;-</span> <span class="fu">map</span>(t, <span class="cf">function</span>(i){</span>
<span id="cb594-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(caminata[<span class="dv">1</span><span class="sc">:</span>i, ], <span class="fu">aes</span>(<span class="at">x =</span> isla)) <span class="sc">+</span></span>
<span id="cb594-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb594-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">x =</span> <span class="st">&quot;&quot;</span>, <span class="at">title =</span> <span class="fu">paste</span>(<span class="st">&quot;t = &quot;</span>, i, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>)) <span class="sc">+</span></span>
<span id="cb594-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">scale_x_continuous</span>(<span class="fu">expression</span>(theta), <span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">11</span>))</span>
<span id="cb594-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb594-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb594-8" aria-hidden="true" tabindex="-1"></a><span class="fu">wrap_plots</span>(plots_list)</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-28-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Escribamos el algoritmo, para esto indexamos las islas por el valor
<span class="math inline">\(\theta\)</span>, es así que la isla del extremo oeste corresponde a <span class="math inline">\(\theta=1\)</span> y la
población relativa de cada isla es <span class="math inline">\(P(\theta)\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>El vendedor se ubica en <span class="math inline">\(\theta^{(i)}\)</span> y propone moverse a la izquierda
o derecha con probabilidad <span class="math inline">\(0.5\)</span>.<br />
El rango de los posibles valores para moverse, y la probabilidad de proponer
cada uno se conoce como <strong>distribución propuesta</strong>, en nuestro ejemplo sólo
toma dos valores cada uno con probabilidad <span class="math inline">\(0.5\)</span>.</p></li>
<li><p>Una vez que se propone un movimiento, decidimos si aceptarlo. La decisión de
aceptar se basa en el valor de la distribución <strong>objetivo</strong> en la posición
propuesta, relativo al valor de la distribución objetivo en la posición actual:
<span class="math display">\[\alpha=\min\bigg\{\frac{P(\theta^*)}{P(\theta^{(i)})},1\bigg\},\]</span>
donde <span class="math inline">\(\alpha\)</span> denota la probabilidad de hacer el cambio de isla.</p></li>
</ol>
<p>Notemos que la distribución objetivo <span class="math inline">\(P(\theta)\)</span> no necesita estar normalizada,
esto es porque lo que nos interesa es el cociente <span class="math inline">\(P(\theta^*)/P(\theta^{(i)})\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li>Una vez que propusimos un movimiento y calculamos la probabilidad de aceptar
el movimiento aceptamos o rechazamos el movimiento generando un valor de una
distribución uniforme, si dicho valor es menor a la probabilidad de cambio,
<span class="math inline">\(\alpha,\)</span> entonces hacemos el movimiento.</li>
</ol>
<p>Entonces, para utilizar el algoritmo necesitamos ser capaces de:</p>
<ul>
<li><p>Generar un valor de la distribución propuesta, que hemos denotado por <span class="math inline">\(q,\)</span>
(para crear <span class="math inline">\(\theta^*\)</span>).</p></li>
<li><p>Evaluar la distribución objetivo en cualquier valor propuesto (para calcular
<span class="math inline">\(P(\theta^*)/P(\theta^{(i)})\)</span>).</p></li>
<li><p>Generar un valor uniforme (para movernos con probabilidad <span class="math inline">\(\alpha\)</span>).</p></li>
</ul>
<p>Las <span class="math inline">\(3\)</span> puntos anteriores nos permiten generar muestras aleatorias de la
distribución objetivo, sin importar si esta está normalizada. Esta técnica es
particularmente útil cuando cuando la distribución objetivo es una posterior
proporcional a <span class="math inline">\(p(x|\theta)p(\theta)\)</span>.</p>
<p>Para entender porque funciona el algoritmo de Metrópolis hace falta entender <span class="math inline">\(2\)</span>
puntos, primero que la distribución objetivo es <strong>estable</strong>: si la probabilidad
<em>actual</em> de ubicarse en una posición coincide con la probabilidad en la
distribución objetivo, entonces el algoritmo preserva las probabilidades.</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(expm)</span>
<span id="cb595-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-2" aria-hidden="true" tabindex="-1"></a>transMat <span class="ot">&lt;-</span> <span class="cf">function</span>(P){ <span class="co"># recibe vector de probabilidades (o población)</span></span>
<span id="cb595-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-3" aria-hidden="true" tabindex="-1"></a>    T <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb595-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-4" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">&lt;-</span> <span class="fu">length</span>(P <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># número de estados</span></span>
<span id="cb595-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n <span class="sc">-</span> <span class="dv">1</span>) { <span class="co"># llenamos por fila</span></span>
<span id="cb595-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-6" aria-hidden="true" tabindex="-1"></a>        T[j, j <span class="sc">-</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">min</span>(P[j <span class="sc">-</span> <span class="dv">1</span>] <span class="sc">/</span> P[j], <span class="dv">1</span>)</span>
<span id="cb595-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-7" aria-hidden="true" tabindex="-1"></a>        T[j, j] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">min</span>(P[j <span class="sc">-</span> <span class="dv">1</span>] <span class="sc">/</span> P[j], <span class="dv">1</span>)) <span class="sc">+</span> </span>
<span id="cb595-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-8" aria-hidden="true" tabindex="-1"></a>                   <span class="fl">0.5</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">min</span>(P[j <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">/</span> P[j], <span class="dv">1</span>))</span>
<span id="cb595-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-9" aria-hidden="true" tabindex="-1"></a>        T[j, j <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">min</span>(P[j <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">/</span> P[j], <span class="dv">1</span>)</span>
<span id="cb595-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb595-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># faltan los casos j = 1 y j = n</span></span>
<span id="cb595-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-12" aria-hidden="true" tabindex="-1"></a>    T[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">min</span>(P[<span class="dv">2</span>] <span class="sc">/</span> P[<span class="dv">1</span>], <span class="dv">1</span>))</span>
<span id="cb595-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-13" aria-hidden="true" tabindex="-1"></a>    T[<span class="dv">1</span>, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">min</span>(P[<span class="dv">2</span>] <span class="sc">/</span> P[<span class="dv">1</span>], <span class="dv">1</span>)</span>
<span id="cb595-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-14" aria-hidden="true" tabindex="-1"></a>    T[n, n] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">min</span>(P[n <span class="sc">-</span> <span class="dv">1</span>] <span class="sc">/</span> P[n], <span class="dv">1</span>))</span>
<span id="cb595-15"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-15" aria-hidden="true" tabindex="-1"></a>    T[n, n <span class="sc">-</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">min</span>(P[n <span class="sc">-</span> <span class="dv">1</span>] <span class="sc">/</span> P[n], <span class="dv">1</span>)</span>
<span id="cb595-16"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-16" aria-hidden="true" tabindex="-1"></a>    T</span>
<span id="cb595-17"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb595-18"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-18" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="fu">transMat</span>(islas<span class="sc">$</span>pob)</span>
<span id="cb595-19"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-19" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">8</span>))</span>
<span id="cb595-20"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-20" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">1000</span>, <span class="dv">5000</span>)</span>
<span id="cb595-21"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-21" aria-hidden="true" tabindex="-1"></a>expT <span class="ot">&lt;-</span> <span class="fu">map_df</span>(t, <span class="sc">~</span><span class="fu">data.frame</span>(<span class="at">t =</span> ., w <span class="sc">%*%</span> (T <span class="sc">%^%</span> .)))</span>
<span id="cb595-22"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-22" aria-hidden="true" tabindex="-1"></a>expT_long <span class="ot">&lt;-</span> expT <span class="sc">%&gt;%</span></span>
<span id="cb595-23"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gather</span>(theta, P, <span class="sc">-</span>t) <span class="sc">%&gt;%</span> </span>
<span id="cb595-24"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">theta =</span> <span class="fu">parse_number</span>(theta))</span>
<span id="cb595-25"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-25" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(expT_long, <span class="fu">aes</span>(<span class="at">x =</span> theta, <span class="at">y =</span> P)) <span class="sc">+</span></span>
<span id="cb595-26"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;darkgray&quot;</span>) <span class="sc">+</span> </span>
<span id="cb595-27"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span> t) <span class="sc">+</span></span>
<span id="cb595-28"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb595-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="fu">expression</span>(theta), <span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">11</span>))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-29-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>El segundo punto es que el proceso converge a la distribución objetivo.
Podemos ver, (en nuestro ejemplo sencillo) que sin importar el punto de inicio
se alcanza la distribución objetivo.</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-1" aria-hidden="true" tabindex="-1"></a>inicio_p <span class="ot">&lt;-</span> <span class="cf">function</span>(i){</span>
<span id="cb596-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-2" aria-hidden="true" tabindex="-1"></a>    w <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb596-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-3" aria-hidden="true" tabindex="-1"></a>    w[i] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb596-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-4" aria-hidden="true" tabindex="-1"></a>    t <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>)</span>
<span id="cb596-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-5" aria-hidden="true" tabindex="-1"></a>    exp_t <span class="ot">&lt;-</span> <span class="fu">map_df</span>(t, <span class="sc">~</span> <span class="fu">data.frame</span>(<span class="at">t =</span> .x, <span class="at">inicio =</span> i, w <span class="sc">%*%</span> (T <span class="sc">%^%</span> .))) <span class="sc">%&gt;%</span></span>
<span id="cb596-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">gather</span>(theta, P, <span class="sc">-</span>t, <span class="sc">-</span>inicio) <span class="sc">%&gt;%</span> </span>
<span id="cb596-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">theta =</span> <span class="fu">parse_number</span>(theta))</span>
<span id="cb596-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-8" aria-hidden="true" tabindex="-1"></a>    exp_t</span>
<span id="cb596-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb596-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-10" aria-hidden="true" tabindex="-1"></a>exp_t <span class="ot">&lt;-</span> <span class="fu">map_df</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">9</span>), inicio_p)</span>
<span id="cb596-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(exp_t, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.numeric</span>(theta), <span class="at">y =</span> P)) <span class="sc">+</span></span>
<span id="cb596-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;darkgray&quot;</span>) <span class="sc">+</span> </span>
<span id="cb596-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_grid</span>(inicio <span class="sc">~</span> t) <span class="sc">+</span></span>
<span id="cb596-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb596-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="fu">expression</span>(theta), <span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">11</span>))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-30-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="metrópolis-con-varios-parámetros" class="section level2 unnumbered hasAnchor">
<h2>Metrópolis con varios parámetros<a href="métodos-de-cadenas-de-markov-monte-carlo.html#metrópolis-con-varios-parámetros" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ahora aplicaremos el algoritmo Metrópolis cuando tenemos varios parámetros. La idea
es la misma, pero nuestra distribución de salto debe ser multivariada. Una selección
usual es usando saltos normales independientes para cada parámetro, es decir, la
normal multivariada con matriz de varianza y covarianza diagonal.</p>
<div id="ejemplo-el-modelo-normal" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: el modelo normal<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-el-modelo-normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Veremos cómo simular con Metrópolis para el problema de los cantantes.
Sabemos como calcular la posterior:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-1" aria-hidden="true" tabindex="-1"></a>crear_log_posterior_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">x =</span> datos, m_0, n_0, a, b){</span>
<span id="cb597-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># calcula log_posterior</span></span>
<span id="cb597-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-3" aria-hidden="true" tabindex="-1"></a>  log_posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, sigma){</span>
<span id="cb597-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-4" aria-hidden="true" tabindex="-1"></a>      log_verosim <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(x, mu, sigma, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb597-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-5" aria-hidden="true" tabindex="-1"></a>      tau <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb597-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-6" aria-hidden="true" tabindex="-1"></a>      log_inicial <span class="ot">&lt;-</span> </span>
<span id="cb597-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dgamma</span>(tau, a, b, <span class="at">log =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> </span>
<span id="cb597-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(mu, mu_0, sigma<span class="sc">/</span><span class="fu">sqrt</span>(n_0), <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb597-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-9" aria-hidden="true" tabindex="-1"></a>      log_p <span class="ot">&lt;-</span> log_verosim <span class="sc">+</span> log_inicial</span>
<span id="cb597-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-10" aria-hidden="true" tabindex="-1"></a>      log_p</span>
<span id="cb597-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb597-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-12" aria-hidden="true" tabindex="-1"></a>  log_posterior</span>
<span id="cb597-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb597-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-1" aria-hidden="true" tabindex="-1"></a><span class="co"># parametros de inicial y datos</span></span>
<span id="cb598-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-2" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb598-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">140</span></span>
<span id="cb598-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-4" aria-hidden="true" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">175</span></span>
<span id="cb598-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-5" aria-hidden="true" tabindex="-1"></a>n_0 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb598-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3413</span>)</span>
<span id="cb598-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-7" aria-hidden="true" tabindex="-1"></a>cantantes <span class="ot">&lt;-</span> lattice<span class="sc">::</span>singer <span class="sc">%&gt;%</span> </span>
<span id="cb598-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">estatura_cm =</span> <span class="fu">round</span>(<span class="fl">2.54</span> <span class="sc">*</span> height)) <span class="sc">%&gt;%</span> </span>
<span id="cb598-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(voice.part, <span class="st">&quot;Tenor&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb598-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb598-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">20</span>)</span></code></pre></div>
<p>Vemos cómo se ven las primeras iteraciones de nuestra cadena de Markov:</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-1" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="fu">crear_log_posterior_norm</span>(cantantes<span class="sc">$</span>estatura_cm, mu_0, n_0, a, b) </span>
<span id="cb599-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-2" aria-hidden="true" tabindex="-1"></a>log_post <span class="ot">&lt;-</span> <span class="cf">function</span>(pars) { <span class="fu">log_p</span>(pars[<span class="dv">1</span>], pars[<span class="dv">2</span>]) }</span>
<span id="cb599-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">823</span>)</span>
<span id="cb599-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-4" aria-hidden="true" tabindex="-1"></a>metro_normal <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_post, <span class="at">sigma_salto =</span> <span class="fl">0.5</span>)</span>
<span id="cb599-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-5" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="ot">&lt;-</span> <span class="fu">metro_normal</span>(<span class="fu">c</span>(<span class="at">mu =</span> <span class="dv">172</span>, <span class="at">sigma =</span> <span class="dv">3</span>), <span class="dv">50000</span>) </span>
<span id="cb599-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">100</span>), </span>
<span id="cb599-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-7" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma)) <span class="sc">+</span> </span>
<span id="cb599-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>() <span class="sc">+</span></span>
<span id="cb599-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb599-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-33-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y ahora vemos todas las simulaciones:</p>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb600-1" aria-hidden="true" tabindex="-1"></a>g_normal <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sim_tbl, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma)) <span class="sc">+</span> </span>
<span id="cb600-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb600-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.05</span>)<span class="sc">+</span> <span class="fu">coord_equal</span>() <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">14</span>))</span>
<span id="cb600-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb600-3" aria-hidden="true" tabindex="-1"></a>g_normal</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-34-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y las medias posteriores son:</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb601-1" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="fu">across</span>(is_double, mean))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##      mu sigma
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  176.  6.80</code></pre>
</div>
<div id="ejemplo-observaciones-normales-no-conjugado" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: observaciones normales, no conjugado<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-observaciones-normales-no-conjugado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Arriba repetimos el análisis conjugado usando Metrópolis. Aunque
ya no es necesario usar el modelo conjugado, y podemos poner
iniciales que sean más intuitivas y acorde con nuestro conocimiento
existente.</p>
<p>Por ejemplo, podemos poner <span class="math inline">\(p(\mu, \sigma) = p(\mu)p(\sigma)\)</span>, donde la densidad
de <span class="math inline">\(\mu \sim \mathsf{N}(175, 2)\)</span> y <span class="math inline">\(\sigma \sim \mathsf{U}[2, 20].\)</span> Igual que
antes, la verosimilitud <span class="math inline">\(p(x|\mu, \sigma)\)</span> es normal con media <span class="math inline">\(\mu\)</span> y
desviación estándar <span class="math inline">\(\sigma.\)</span></p>
<p>Escribimos la posterior:</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-1" aria-hidden="true" tabindex="-1"></a>crear_log_posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(x, m_0, sigma_0, inf, sup){</span>
<span id="cb603-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># calcula log_posterior</span></span>
<span id="cb603-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-3" aria-hidden="true" tabindex="-1"></a>  log_posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, sigma){</span>
<span id="cb603-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-4" aria-hidden="true" tabindex="-1"></a>      log_verosim <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(x, mu, sigma, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb603-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-5" aria-hidden="true" tabindex="-1"></a>      log_inicial <span class="ot">&lt;-</span> </span>
<span id="cb603-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dunif</span>(sigma, inf, sup, <span class="at">log =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> </span>
<span id="cb603-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(mu, mu_0, sigma_0, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb603-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-8" aria-hidden="true" tabindex="-1"></a>      log_p <span class="ot">&lt;-</span> log_verosim <span class="sc">+</span> log_inicial</span>
<span id="cb603-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-9" aria-hidden="true" tabindex="-1"></a>      log_p</span>
<span id="cb603-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb603-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-11" aria-hidden="true" tabindex="-1"></a>  log_posterior</span>
<span id="cb603-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb603-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb604-1" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="fu">crear_log_posterior</span>(cantantes<span class="sc">$</span>estatura_cm, <span class="dv">175</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">20</span>) </span>
<span id="cb604-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb604-2" aria-hidden="true" tabindex="-1"></a>log_post <span class="ot">&lt;-</span> <span class="cf">function</span>(pars) { <span class="fu">log_p</span>(pars[<span class="dv">1</span>], pars[<span class="dv">2</span>]) }</span></code></pre></div>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb605-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8231</span>)</span>
<span id="cb605-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb605-2" aria-hidden="true" tabindex="-1"></a>metro_normal <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_post, <span class="at">sigma_salto =</span> <span class="fl">0.5</span>)</span>
<span id="cb605-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb605-3" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="ot">&lt;-</span> <span class="fu">metro_normal</span>(<span class="fu">c</span>(<span class="at">mu =</span> <span class="dv">172</span>, <span class="at">sigma =</span> <span class="dv">5</span>), <span class="dv">50000</span>) </span>
<span id="cb605-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb605-4" aria-hidden="true" tabindex="-1"></a>g_normal_2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sim_tbl, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma))  <span class="sc">+</span></span>
<span id="cb605-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb605-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.05</span>) <span class="sc">+</span> <span class="fu">coord_equal</span>() <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">14</span>))</span>
<span id="cb605-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb605-6" aria-hidden="true" tabindex="-1"></a>g_normal <span class="sc">+</span> g_normal_2</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-38-1.png" width="672" style="display: block; margin: auto;" />
Los resultados son similares, pero en
nuestras estimaciones bajo el segundo modelo, la <span class="math inline">\(\sigma\)</span> está
concentrada en valores un poco más bajos que el modelo normal-gamma inversa.
Las medias posteriores son:</p>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb606-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb606-1" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="fu">across</span>(is.numeric, mean))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   iter_num    mu sigma
##      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   25000.  176.  6.54</code></pre>
<p>Nótese que la inicial para el modelo normal-gamma inversa pone muy poca
probabilidad para valores bajos de <span class="math inline">\(\sigma\)</span>, mientras que el segundo
modelo hay un 10% de probabilidad de que la <span class="math inline">\(\sigma\)</span> sea menor que 4.</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb608-1" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">5000</span>, <span class="dv">3</span>, <span class="dv">150</span>)</span>
<span id="cb608-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb608-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(tau)</span>
<span id="cb608-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb608-3" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(sigma, <span class="fu">c</span>(<span class="fl">0.01</span>,<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.99</span>))</span></code></pre></div>
<pre><code>##        1%       10%       90%       99% 
##  4.219278  5.276228 11.579358 19.038529</code></pre>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb610-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">runif</span>(<span class="dv">5000</span>, <span class="dv">2</span>, <span class="dv">25</span>), <span class="fu">c</span>(<span class="fl">0.01</span>,<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.99</span>))</span></code></pre></div>
<pre><code>##        1%       10%       90%       99% 
##  2.261297  4.254128 22.691760 24.719630</code></pre>
</div>
<div id="ejemplo-exámenes" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: exámenes<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-exámenes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recordamos un ejemplo que vimos en la sección de máxima verosimilitud.
Supongamos que en una población de estudiantes tenemos dos tipos: unos llenaron
un examen de opción múltiple al azar (1 de 5), y otros contestaron las
preguntas intentando sacar una buena calificación. Suponemos que una vez que
conocemos el tipo de estudiante, todas las preguntas tienen la misma
probabilidad de ser contestadas correctamente, de manera independiente. El
modelo teórico está representado por la siguiente simulación:</p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-1" aria-hidden="true" tabindex="-1"></a>sim_formas <span class="ot">&lt;-</span> <span class="cf">function</span>(p_azar, p_corr){</span>
<span id="cb612-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-2" aria-hidden="true" tabindex="-1"></a>  tipo <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span> <span class="sc">-</span> p_azar)</span>
<span id="cb612-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(tipo<span class="sc">==</span><span class="dv">0</span>){</span>
<span id="cb612-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># al azar</span></span>
<span id="cb612-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-5" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">5</span>)</span>
<span id="cb612-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-6" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb612-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># no al azar</span></span>
<span id="cb612-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-8" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, p_corr)</span>
<span id="cb612-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb612-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-10" aria-hidden="true" tabindex="-1"></a>  x</span>
<span id="cb612-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb612-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Y una muestra se ve como sigue:</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb613-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb613-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12</span>)</span>
<span id="cb613-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb613-2" aria-hidden="true" tabindex="-1"></a>muestra <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>, <span class="sc">~</span> <span class="fu">sim_formas</span>(<span class="fl">0.35</span>, <span class="fl">0.5</span>))</span>
<span id="cb613-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb613-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(muestra)</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-42-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Supongamos que no conocemos la probabildad de contestar correctamente ni la
proporción de estudiantes que contestó al azar. ¿Como estimamos estas dos cantidades?</p>
<p>La verosimilitud la escribimos en el ejercicio anterior en la sección de máxima verosimilitud, está dada, para las repuestas de un estudiante, por:</p>
<p><span class="math display">\[p(X = k|\theta_{azar}, \theta_{corr}) \propto \theta_{azar}(1/5)^k(4/5)^{10-k} +
(1-\theta_{azar})\theta_{corr}^k(1-\theta_{corr})^{10-k}\]</span></p>
<p>Suponiendo que todas las preguntas tienen la misma dificultad, y que
los estudiantes que estudiaron son homogéneos (podemos discutir qué haríamos
para introducir heterogeneidad que típicamente observaríamos).</p>
<p>Creemos que la mayoría de los estudiantes no contesta al azar, así que pondremos
como inicial</p>
<p><span class="math display">\[\theta_{azar} \sim \mathsf{Beta}(1, 5)\]</span></p>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb614-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qbeta</span>(<span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>), <span class="dv">1</span>, <span class="dv">5</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.02 0.37</code></pre>
<p>Ahora tenemos que pensar en la probabilidad <span class="math inline">\(\theta_{corr}\)</span> para los estudiantes
que sí estudiaron. Imaginemos que lo probamos con un estudiante que
sabemos que sí estudió, y obtuvo un porcentaje de correctos de 7/10, Podríamos
poner entonces (vimos 10 intentos, con 3 fracasos y 7 éxitos):</p>
<p><span class="math display">\[\theta_{corr} \sim \mathsf{Beta}(7, 3)\]</span>
Finalmente, necesitamos la conjunta inicial. Pondremos
<span class="math display">\[p(\theta_{azar},\theta_{corr}) = p(\theta_{azar})p(\theta_{corr})\]</span>
con lo que expresamos que inicialmente no creemos que estos dos parámetros estén
relacionados. Si pensáramos, por ejemplo, que cuando hacemos exámenes difíciles
menos estudiantes estudian, entonces deberíamos intentar otra conjunta.</p>
<p>Escribimos el producto de la verosimilitud con la inicial:</p>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-1" aria-hidden="true" tabindex="-1"></a>crear_log_posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb616-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb616-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-3" aria-hidden="true" tabindex="-1"></a>  log_posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(theta_azar, theta_corr){</span>
<span id="cb616-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-4" aria-hidden="true" tabindex="-1"></a>    log_verosim <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(theta_azar <span class="sc">*</span> <span class="fu">dbinom</span>(x, <span class="dv">10</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb616-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-5" aria-hidden="true" tabindex="-1"></a>                          (<span class="dv">1</span> <span class="sc">-</span> theta_azar) <span class="sc">*</span> <span class="fu">dbinom</span>(x, <span class="dv">10</span>, theta_corr)))</span>
<span id="cb616-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-6" aria-hidden="true" tabindex="-1"></a>    log_inicial <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta_azar, <span class="dv">1</span>, <span class="dv">5</span>, <span class="at">log =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb616-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">dbeta</span>(theta_corr, <span class="dv">7</span>, <span class="dv">3</span>, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb616-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-8" aria-hidden="true" tabindex="-1"></a>    log_post <span class="ot">&lt;-</span> log_verosim <span class="sc">+</span> log_inicial</span>
<span id="cb616-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-9" aria-hidden="true" tabindex="-1"></a>    log_post</span>
<span id="cb616-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-10" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb616-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-11" aria-hidden="true" tabindex="-1"></a>  log_posterior</span>
<span id="cb616-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb616-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb616-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Creamos la función de verosimilitud con los datos</p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-1" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="fu">crear_log_posterior</span>(muestra)</span>
<span id="cb617-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-2" aria-hidden="true" tabindex="-1"></a>log_post <span class="ot">&lt;-</span> <span class="cf">function</span>(pars) { <span class="fu">log_p</span>(pars[<span class="dv">1</span>], pars[<span class="dv">2</span>]) }</span>
<span id="cb617-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8231</span>)</span>
<span id="cb617-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-4" aria-hidden="true" tabindex="-1"></a>metro_examenes <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_post, <span class="at">sigma_salto =</span> <span class="fl">0.02</span>)</span>
<span id="cb617-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-5" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="ot">&lt;-</span> <span class="fu">metro_examenes</span>(<span class="fu">c</span>(<span class="at">theta_azar =</span> <span class="fl">0.5</span>, <span class="at">theta_corr =</span> <span class="fl">0.5</span>), <span class="dv">20000</span>)</span>
<span id="cb617-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-6" aria-hidden="true" tabindex="-1"></a>g_1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sim_tbl, <span class="fu">aes</span>(<span class="at">x =</span> theta_azar, <span class="at">y =</span> theta_corr))  <span class="sc">+</span></span>
<span id="cb617-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.05</span>) <span class="sc">+</span> <span class="fu">coord_equal</span>() </span>
<span id="cb617-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb617-8" aria-hidden="true" tabindex="-1"></a>g_1</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-45-1.png" width="480" style="display: block; margin: auto;" />
Nótese que hay cierta correlación entre las dos proporciones, y esto produce
intervalos posteriores relativamente amplios. Esto es de esperarse, pues
los datos son consistentes con una proporción relativamente chica de
estudiantes que contestan al azar, y tasas de correctos más altas entre los
que sí estudian, y una proporción más grande de respuestas al azar con
tasas de correctos más altas.</p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>)</span>
<span id="cb618-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-2" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb618-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>iter_num, <span class="at">names_to =</span> <span class="st">&quot;parametro&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;valor&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb618-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(parametro) <span class="sc">%&gt;%</span> </span>
<span id="cb618-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">cuantil =</span> <span class="fu">quantile</span>(valor, f), <span class="at">f =</span> f) <span class="sc">%&gt;%</span> </span>
<span id="cb618-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cuantil =</span> <span class="fu">round</span>(cuantil, <span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb618-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb618-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> f, <span class="at">values_from =</span> cuantil)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
## # Groups:   parametro [2]
##   parametro  `0.05` `0.5` `0.95`
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1 theta_azar    0.3  0.38   0.45
## 2 theta_corr    0.5  0.52   0.56</code></pre>
</div>
</div>
<div id="muestreador-de-gibbs" class="section level2 unnumbered hasAnchor">
<h2>Muestreador de Gibbs<a href="métodos-de-cadenas-de-markov-monte-carlo.html#muestreador-de-gibbs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El algoritmo de Metrópolis es muy general y se puede aplicar a una gran variedad
de problemas. Sin embargo, afinar los parámetros de la distribución propuesta
para que el algoritmo funcione correctamente puede ser complicado. El
muestredor de Gibbs no necesita de una distribución propuesta y por lo tanto
no requiere afinar estos parámetros.</p>
<p><strong>Para implementar un muestreador de Gibbs se necesita ser capaz de generar
muestras de la distribución posterior condicional a cada uno de los
parámetros individuales.</strong> Esto es, el muestreador de Gibbs permite generar
muestras de la posterior:
<span class="math display">\[p(\theta_1,...,\theta_p|x)\]</span>
siempre y cuando podamos generar valores de todas las distribuciones
condicionales:
<span class="math display">\[\theta_k \sim p(\theta_k|\theta_1,...,\theta_{k-1},\theta_{k+1},...,\theta_p,x).\]</span></p>
<p>El proceso del muestreador de Gibbs es una caminata aleatoria a lo largo del
espacio de parámetros. La caminata inicia en un punto arbitrario y en cada
tiempo el siguiente paso depende únicamente de la posición actual. Por tanto
el muestredor de Gibbs es un proceso cadena de Markov vía Monte Carlo. La
diferencia entre Gibbs y Metrópolis radica en como se deciden los pasos.</p>
<p><strong>Muestreador Gibbs</strong></p>
<p>En cada punto de la caminata se selecciona uno de los
componentes del vector de parámetros (típicamente se cicla en orden):</p>
<ol style="list-style-type: decimal">
<li><p>Supongamos que se selecciona el parámetro <span class="math inline">\(k\)</span>-ésimo después de haber
modificado los <span class="math inline">\(k-1\)</span> anteriores, entonces obtenemos un nuevo valor para este
parámetro generando una simulación de la distribución condicional
<span class="math display">\[\theta_k^{(i+1)} \sim p(\theta_k|\theta_1^{(i+1)},\ldots,\theta_{k-1}^{(i+1)},\theta_{k+1}^{(i)},\ldots,\theta_p^{(i)},x)\]</span></p></li>
<li><p>El nuevo valor <span class="math inline">\(\theta_k^{(i+1)}\)</span> junto con los valores
<span class="math inline">\(\theta_1^{(i+1)},\ldots,\theta_{k-1}^{(i+1)},\theta_{k+1}^{(i)},\ldots,\theta_p^{(i)}\)</span>
constituyen la nueva posición en la caminata aleatoria.</p></li>
<li><p>Seleccionamos una nueva componente <span class="math inline">\(\theta_{k+1}^{(i+1)}\)</span> y repetimos el proceso.</p></li>
</ol>
<p>El muestreador de Gibbs es útil cuando no podemos determinar de manera analítica
la distribución conjunta y no se puede simular directamente de ella, pero sí
podemos determinar todas las distribuciones condicionales y simular de ellas.</p>
<div id="ejemplo-dos-proporciones" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: dos proporciones<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-dos-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que queremos evaluar el balanceo de <em>dos dados</em> de 20 lados que
produce una fábrica. En particular, evaluar la probabilidad de tirar un 20, y
quizá escoger el dado que nos de mayor probabilidad de tirar un 20.</p>
<p>Tiramos cada dado <span class="math inline">\(n\)</span> veces, y denotamos por <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> el número
de 20’s que tiramos en cada ocasión. El modelo de datos está dado por
<span class="math display">\[p(x_1, x_2|\theta_1, \theta_2)\propto \theta_1^{x_1}(1-\theta_1)^{n - x_1}\theta_2^{x_2}(1-\theta_2)^{n - x_2},\]</span>
que es el producto de dos densidades binomiales, pues suponemos que
las tiradas son independientes cuando conocemos los parámetros
<span class="math inline">\(\theta_1\)</span> y <span class="math inline">\(\theta_2\)</span>.</p>
<p>Ahora ponemos una inicial
<span class="math display">\[p(\theta_i)\sim \mathsf{Beta}(100, 1900)\]</span></p>
<p>y aquí están las razones de nuestra elección:</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb620-1" aria-hidden="true" tabindex="-1"></a>media <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">20</span></span>
<span id="cb620-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb620-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb620-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb620-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> media <span class="sc">*</span> k</span>
<span id="cb620-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb620-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> (<span class="dv">1</span> <span class="sc">-</span> media) <span class="sc">*</span> k</span>
<span id="cb620-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb620-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(a,b)</span></code></pre></div>
<pre><code>## [1]  100 1900</code></pre>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb622-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qbeta</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>), a, b) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.042 0.058</code></pre>
<p>y suponemos que</p>
<p><span class="math display">\[p(\theta_1,\theta_2) = p (\theta_1)p(\theta_2)\]</span></p>
<p>es decir, apriori saber el desempeño de un dado no nos da información adicional del otro (esto podría no ser cierto, por ejemplo, si el defecto es
provocado por la impresión del número 20).</p>
<p>Por lo tanto, la posterior es</p>
<p><span class="math display">\[p(\theta_1,\theta_2|x_1, x_2)\propto \theta_1^{x_1+100-1}(1-\theta_1)^{n - x_1 + 1900-1}\theta_2^{x_2+100 -1}(1-\theta_2)^{n - x_2 + 1900-1}\]</span></p>
<p>Ahora consideramoso qué pasa cuando conocemos <span class="math inline">\(\theta_2\)</span> y los datos. Pensamos en todo lo que no sea <span class="math inline">\(\theta_1\)</span> como constante de modo que nos
queda:</p>
<p><span class="math display">\[p(\theta_1 | \theta_2, x) \propto \theta_1^{x_1+100 -1}(1-\theta_1)^{n - x_1 + 1900 -1}\]</span>
que es <span class="math inline">\(\mathsf{Beta}(x_1 + 100, n - x_1 + 1900)\)</span>, y por la misma razón,</p>
<p><span class="math display">\[p(\theta_2 | \theta_1, x) \propto \theta_2^{x_2+100-1}(1-\theta_2)^{n - x_2 + 1900-1}\]</span></p>
<p>que también es es <span class="math inline">\(\mathsf{Beta}(x_1 + 100, n - x_1 + 1900)\)</span></p>
<p>De hecho, estas condicionales son fáciles de deducir de otra manera: en
realidad estamos haciendo dos experimentos separados (pues suponemos
que las iniciales son independientes y las pruebas también), así que
podriamos usar el análisis Beta-Binomial para cada uno de ellos. En realidad no es necesario usar MCMC para este ejemplo.</p>
<p>Usaremos esta función para hacer nuestras iteraciones de Gibbs:</p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-1" aria-hidden="true" tabindex="-1"></a>iterar_gibbs <span class="ot">&lt;-</span> <span class="cf">function</span>(pasos, n, x_1, x_2){</span>
<span id="cb624-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-2" aria-hidden="true" tabindex="-1"></a>  iteraciones <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> pasos <span class="sc">+</span> <span class="dv">1</span>, <span class="at">ncol =</span> <span class="dv">2</span>) <span class="co"># vector guardará las simulaciones</span></span>
<span id="cb624-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-3" aria-hidden="true" tabindex="-1"></a>  iteraciones[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="co"># valor inicial media</span></span>
<span id="cb624-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(iteraciones) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;theta_1&quot;</span>, <span class="st">&quot;theta_2&quot;</span>)</span>
<span id="cb624-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Generamos la caminata aleatoria</span></span>
<span id="cb624-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="fu">seq</span>(<span class="dv">2</span>, pasos, <span class="dv">2</span>)) {</span>
<span id="cb624-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># theta_1</span></span>
<span id="cb624-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-8" aria-hidden="true" tabindex="-1"></a>    a <span class="ot">&lt;-</span> x_2 <span class="sc">+</span> <span class="dv">100</span> <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb624-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-9" aria-hidden="true" tabindex="-1"></a>    b <span class="ot">&lt;-</span> n <span class="sc">-</span> x_2 <span class="sc">+</span> <span class="dv">1900</span> <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb624-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-10" aria-hidden="true" tabindex="-1"></a>    iteraciones[j, <span class="st">&quot;theta_2&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, a, b) <span class="co"># Actualizar theta_1</span></span>
<span id="cb624-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-11" aria-hidden="true" tabindex="-1"></a>    iteraciones[j, <span class="st">&quot;theta_1&quot;</span>] <span class="ot">&lt;-</span> iteraciones[j<span class="dv">-1</span>, <span class="st">&quot;theta_1&quot;</span>]</span>
<span id="cb624-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># theta_2</span></span>
<span id="cb624-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-13" aria-hidden="true" tabindex="-1"></a>    a <span class="ot">&lt;-</span> x_1 <span class="sc">+</span> <span class="dv">100</span> <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb624-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-14" aria-hidden="true" tabindex="-1"></a>    b <span class="ot">&lt;-</span> n <span class="sc">-</span> x_1 <span class="sc">+</span> <span class="dv">1900</span> <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb624-15"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-15" aria-hidden="true" tabindex="-1"></a>    iteraciones[j <span class="sc">+</span> <span class="dv">1</span>, <span class="st">&quot;theta_1&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, a, b) <span class="co"># Actualizar theta_1</span></span>
<span id="cb624-16"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-16" aria-hidden="true" tabindex="-1"></a>    iteraciones[j <span class="sc">+</span> <span class="dv">1</span>, <span class="st">&quot;theta_2&quot;</span>] <span class="ot">&lt;-</span> iteraciones[j, <span class="st">&quot;theta_2&quot;</span>]</span>
<span id="cb624-17"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb624-18"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-18" aria-hidden="true" tabindex="-1"></a>  iteraciones</span>
<span id="cb624-19"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb624-19" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Y supongamos que estamos comparando los dados de dos compañías: Chessex y GameScience. Tiramos cada dado 10 mil veces, y obtenemos:</p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb625-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos de https://www.awesomedice.com/blogs/news/d20-dice-randomness-test-chessex-vs-gamescience</span></span>
<span id="cb625-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb625-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb625-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb625-3" aria-hidden="true" tabindex="-1"></a>x_1 <span class="ot">&lt;-</span> <span class="dv">408</span> <span class="co"># Chessex, alrededor de 0.85 dólares por dado</span></span>
<span id="cb625-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb625-4" aria-hidden="true" tabindex="-1"></a>x_2 <span class="ot">&lt;-</span> <span class="dv">474</span> <span class="co"># GameScience, alrededor 1.60 dólares por dado</span></span></code></pre></div>
<p>E iteramos:</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb626-1" aria-hidden="true" tabindex="-1"></a>iteraciones <span class="ot">&lt;-</span> <span class="fu">iterar_gibbs</span>(<span class="dv">20000</span>, n, x_1, x_2) <span class="sc">%&gt;%</span> </span>
<span id="cb626-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb626-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb626-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb626-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">iter_num =</span> <span class="fu">row_number</span>())</span>
<span id="cb626-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb626-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iteraciones)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##   theta_1 theta_2 iter_num
##     &lt;dbl&gt;   &lt;dbl&gt;    &lt;int&gt;
## 1  0.5     0             1
## 2  0.5     0.0479        2
## 3  0.0442  0.0479        3
## 4  0.0442  0.0452        4
## 5  0.0411  0.0452        5
## 6  0.0411  0.0505        6</code></pre>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb628-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(iteraciones, iter_num <span class="sc">&gt;</span> <span class="dv">1000</span>, iter_num<span class="sc">&lt;</span> <span class="dv">1050</span>), </span>
<span id="cb628-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb628-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> theta_1, <span class="at">y =</span> theta_2)) <span class="sc">+</span> </span>
<span id="cb628-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb628-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">geom_point</span>() </span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-51-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-1" aria-hidden="true" tabindex="-1"></a>g_1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(iteraciones, </span>
<span id="cb629-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> theta_1, <span class="at">y =</span> theta_2)) <span class="sc">+</span> </span>
<span id="cb629-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">geom_point</span>() </span>
<span id="cb629-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-4" aria-hidden="true" tabindex="-1"></a>g_2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(iteraciones <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&gt;</span> <span class="dv">10</span>), </span>
<span id="cb629-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-5" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> theta_1, <span class="at">y =</span> theta_2)) <span class="sc">+</span> </span>
<span id="cb629-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb629-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb629-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span> <span class="fu">tibble</span>(<span class="at">theta_1=</span><span class="dv">1</span><span class="sc">/</span><span class="dv">20</span>, <span class="at">theta_2=</span><span class="dv">1</span><span class="sc">/</span><span class="dv">20</span>), <span class="at">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="at">size =</span> <span class="dv">5</span>)</span>
<span id="cb629-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb629-9" aria-hidden="true" tabindex="-1"></a>g_1 <span class="sc">+</span> g_2</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-52-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Notamos el dado de Cheesex no es consistente con 1/20 de tiros de 20s,
pero el dado de GameScience sí lo es. De este gráfica vemos
que Cheesex está sesgado hacia abajo, así que deberíamos escoger
el dado de GameScience</p>
<p>Podemos ver directamente cómo se distribuye la diferencia <span class="math inline">\(\theta_1 - \theta_2\)</span>. Cualquier estadística es fácil de evaluar, pues simplemente
la calculamos para cada simulación y después resumimos:</p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb630-1" aria-hidden="true" tabindex="-1"></a>iteraciones <span class="ot">&lt;-</span> iteraciones <span class="sc">%&gt;%</span> </span>
<span id="cb630-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb630-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dif =</span> theta_1 <span class="sc">-</span> theta_2)</span>
<span id="cb630-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb630-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(iteraciones <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&gt;</span> <span class="dv">10</span>), <span class="fu">aes</span>(<span class="at">x =</span> dif)) <span class="sc">+</span></span>
<span id="cb630-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb630-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">100</span>) <span class="sc">+</span></span>
<span id="cb630-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb630-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">colour =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-53-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y vemos que es altamente probable que el dado de Cheesex produce
más 20’s que el dado de GameScience.</p>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb631-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb631-1" aria-hidden="true" tabindex="-1"></a>iteraciones <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">theta_1_mayor =</span> dif <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb631-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb631-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob_theta_1_mayor =</span> <span class="fu">mean</span>(theta_1_mayor))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   prob_theta_1_mayor
##                &lt;dbl&gt;
## 1             0.0215</code></pre>
<p>Finalmente, verificamos nuestro modelo y cuánto aprendimos. Podemos
hacerlo simulando de la inicial y comparando con la posterior:</p>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb633-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-1" aria-hidden="true" tabindex="-1"></a>inicial_tbl <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">theta_1 =</span> <span class="fu">rbeta</span>(<span class="dv">20000</span>, <span class="dv">100</span>, <span class="dv">1900</span>),</span>
<span id="cb633-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">theta_2 =</span> <span class="fu">rbeta</span>(<span class="dv">20000</span>, <span class="dv">100</span>, <span class="dv">1900</span>),</span>
<span id="cb633-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">dist =</span> <span class="st">&quot;inicial&quot;</span>)</span>
<span id="cb633-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-4" aria-hidden="true" tabindex="-1"></a>posterior_tbl <span class="ot">&lt;-</span> iteraciones <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&gt;</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb633-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dist =</span> <span class="st">&quot;posterior&quot;</span>)</span>
<span id="cb633-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-6" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(inicial_tbl, posterior_tbl)</span>
<span id="cb633-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sims_tbl, <span class="fu">aes</span>(<span class="at">x =</span> theta_1, <span class="at">y =</span> theta_2, <span class="at">colour =</span> dist)) <span class="sc">+</span></span>
<span id="cb633-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb633-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-55-1.png" width="480" style="display: block; margin: auto;" />
donde vemos que el resultado que obtuvimos es razonablemente consistente
con nuestra información inicial, y las 10 mil tiradas de dado
fueron altamente informativas.</p>

<div class="ejercicio">
<ul>
<li><p>¿Qué crees que pasaría si sólo hubieramos tirado 40 veces cada
dado? ¿Qué tanto habríamos aprendido? Puedes usar datos
simulados y repetir este ejercicio.</p></li>
<li><p>Puedes examinar los resultados para cada cara con los datos originales.
Un modelo apropiado es el Dirichlet-Multinomial.</p></li>
</ul>
</div>
</div>
<div id="ejemplo-modelo-normal-no-conjugado" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo: Modelo normal no conjugado<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-modelo-normal-no-conjugado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Retomemos el caso de observaciones normales, supongamos que tenemos una muestra
<span class="math inline">\(X_1,...,X_n\)</span> de observaciones independientes e identicamente distribuidas,
con <span class="math inline">\(X_i \sim \mathsf{N}(\mu, \sigma^2)\)</span>.</p>
<p>Usaremos iniciales distintas al modelo anterior:</p>
<p><span class="math display">\[p(\mu, \sigma^2) = p(\sigma^2)p(\mu)\]</span>
con <span class="math inline">\(\mu\)</span> <span class="math inline">\(\mathsf{N}(\mu_0, \sigma_0)\)</span> y <span class="math inline">\(\tau = 1/\sigma^2\)</span> con distribución
<span class="math inline">\(\mathsf{Gamma}(a,b)\)</span>. Esto no nos da el modelo conjugado que vimos antes (nota
la diferencia de la especificación de la inicial conjunta).</p>
<p>Comenzamos por escribir</p>
<p><span class="math display">\[p(\mu, \sigma^2|x) \propto \frac{1}{{\sigma^{n/2}}}  \exp(-\sum\frac{(x_i-\mu)²}{2\sigma^2}) \exp(- \frac{(\mu - \mu_0)^2}{2\sigma_0^2}) \frac{1}{(\sigma^2)^{a + 1}}\exp (-\beta/\sigma^2 )\]</span></p>
<p>Comenzamos analizando <span class="math inline">\(p(\mu|\sigma^2, x)\)</span>. Por la ecuación de arriba, e ignorando
los términos que <strong>no</strong> dependen de <span class="math inline">\(\mu\)</span>:
<span class="math display">\[p(\mu|\sigma^2, x) \propto \exp [ - \sum_i (\frac{(\mu - x_i)^2}{2\sigma^2} - \frac{(\mu - \mu_0)^2}{2n\sigma_0^2})]\]</span>
que es una distribución normal (completa cuadrados):</p>
<p><span class="math display">\[\mu|\sigma^2,x \sim \mathsf{N}\bigg(\frac{\sigma^2}{\sigma^2 + n\sigma_0^2}\mu_0 + \frac{n\sigma_0^2}{\sigma^2 + n \sigma_0^2}\bar{x}, \frac{\sigma \sigma_0}{\sqrt{\sigma^2 + n\sigma_0^2}}\bigg)\]</span></p>
<p>Ahora consideramos <span class="math inline">\(p(\sigma^2|mu,x)\)</span>. Ignoramos en <span class="math inline">\(p(\mu,\sigma^2|x)\)</span> los términos que *no** dependen de <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[p(\sigma^2|\mu, x) \propto \frac{1}{\sigma^{n/2}}  \exp(-\sum\frac{(x_i-\mu)²}{2\sigma^2}) \frac{1}{(\sigma^2)^{a + 1}}\exp (-\beta/\sigma^2)\]</span>
que simplificando da</p>
<p><span class="math display">\[ = \frac{1}{\sigma^{n/2 + a + 1}}\exp( -\frac{\beta +\frac{1}{2}\sum(x_i - \mu)^2}{\sigma^2}  )\]</span>
de modo que</p>
<p><span class="math display">\[\sigma^2|\mu, x \sim \mathsf{GI}(a +n/2, b + \frac{1}{2}\sum(x_i -\mu)^2)\]</span></p>
</div>
<div id="ejemplo-17" class="section level3 unnumbered hasAnchor">
<h3>Ejemplo<a href="métodos-de-cadenas-de-markov-monte-carlo.html#ejemplo-17" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Usaremos este muestreador para el problema de la estaturas de
los tenores. Comenzamos definiendo las distribuciones iniciales:</p>
<ul>
<li><p><span class="math inline">\(\mu \sim \mathsf{N}(175, 3)\)</span></p></li>
<li><p><span class="math inline">\(\tau = 1/\sigma^2 \sim \mathsf{GI}(3, 150)\)</span>, esto es <span class="math inline">\(a = 3\)</span> y <span class="math inline">\(b = 150\)</span>.</p></li>
</ul>
<p>Escribimos el muestreador de Gibbs.</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb634-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> cantantes<span class="sc">$</span>estatura_cm</span>
<span id="cb634-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-3" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">175</span>; sigma_0 <span class="ot">&lt;-</span> <span class="dv">3</span>; alpha <span class="ot">&lt;-</span> <span class="dv">3</span>; beta <span class="ot">&lt;-</span> <span class="dv">150</span> <span class="co"># parámetros de iniciales</span></span>
<span id="cb634-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-4" aria-hidden="true" tabindex="-1"></a>pasos <span class="ot">&lt;-</span> <span class="dv">20000</span></span>
<span id="cb634-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-5" aria-hidden="true" tabindex="-1"></a>iteraciones <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> pasos <span class="sc">+</span> <span class="dv">1</span>, <span class="at">ncol =</span> <span class="dv">2</span>) <span class="co"># vector guardará las simulaciones</span></span>
<span id="cb634-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-6" aria-hidden="true" tabindex="-1"></a>iteraciones[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># valor inicial media</span></span>
<span id="cb634-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(iteraciones) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>)</span>
<span id="cb634-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generamos la caminata aleatoria</span></span>
<span id="cb634-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="fu">seq</span>(<span class="dv">2</span>, pasos, <span class="dv">2</span>)) {</span>
<span id="cb634-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sigma^2</span></span>
<span id="cb634-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-11" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> iteraciones[j <span class="sc">-</span> <span class="dv">1</span>, <span class="st">&quot;mu&quot;</span>]</span>
<span id="cb634-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-12" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> n <span class="sc">/</span> <span class="dv">2</span> <span class="sc">+</span> alpha</span>
<span id="cb634-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-13" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> <span class="fu">sum</span>((x  <span class="sc">-</span> mu) <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">/</span> <span class="dv">2</span> <span class="sc">+</span> beta</span>
<span id="cb634-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-14" aria-hidden="true" tabindex="-1"></a>  iteraciones[j, <span class="st">&quot;sigma&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(<span class="dv">1</span>, a, b)) <span class="co"># Actualizar sigma</span></span>
<span id="cb634-15"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-15" aria-hidden="true" tabindex="-1"></a>  iteraciones[j, <span class="st">&quot;mu&quot;</span>] <span class="ot">&lt;-</span> iteraciones[j<span class="dv">-1</span>, <span class="st">&quot;mu&quot;</span>]</span>
<span id="cb634-16"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># mu</span></span>
<span id="cb634-17"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-17" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> iteraciones[j, <span class="st">&quot;sigma&quot;</span>]</span>
<span id="cb634-18"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-18" aria-hidden="true" tabindex="-1"></a>  media <span class="ot">&lt;-</span> (n <span class="sc">*</span> sigma_0<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(x) <span class="sc">+</span> sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> m) <span class="sc">/</span> (n <span class="sc">*</span> sigma_0<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> sigma<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb634-19"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-19" aria-hidden="true" tabindex="-1"></a>  varianza <span class="ot">&lt;-</span> sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> sigma_0<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (n <span class="sc">*</span> sigma_0<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> sigma<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb634-20"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-20" aria-hidden="true" tabindex="-1"></a>  iteraciones[j<span class="sc">+</span><span class="dv">1</span>, <span class="st">&quot;mu&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, media, <span class="at">sd =</span> <span class="fu">sqrt</span>(varianza)) <span class="co"># actualizar mu</span></span>
<span id="cb634-21"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-21" aria-hidden="true" tabindex="-1"></a>  iteraciones[j<span class="sc">+</span><span class="dv">1</span>, <span class="st">&quot;sigma&quot;</span>] <span class="ot">&lt;-</span> iteraciones[j, <span class="st">&quot;sigma&quot;</span>]</span>
<span id="cb634-22"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb634-23"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-23" aria-hidden="true" tabindex="-1"></a>caminata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">pasos =</span> <span class="dv">1</span><span class="sc">:</span>pasos, <span class="at">mu =</span> iteraciones[<span class="dv">1</span><span class="sc">:</span>pasos, <span class="st">&quot;mu&quot;</span>], </span>
<span id="cb634-24"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> iteraciones[<span class="dv">1</span><span class="sc">:</span>pasos, <span class="st">&quot;sigma&quot;</span>])</span>
<span id="cb634-25"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-25" aria-hidden="true" tabindex="-1"></a>caminata_g <span class="ot">&lt;-</span> caminata <span class="sc">%&gt;%</span></span>
<span id="cb634-26"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(parametro, val, mu, sigma) <span class="sc">%&gt;%</span></span>
<span id="cb634-27"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb634-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(pasos)</span></code></pre></div>
<p>Veamos primero algunos pasos:</p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb635-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb635-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(caminata, pasos <span class="sc">&gt;</span> <span class="dv">1000</span>, pasos<span class="sc">&lt;</span> <span class="dv">1010</span>), </span>
<span id="cb635-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb635-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma)) <span class="sc">+</span> </span>
<span id="cb635-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb635-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">geom_point</span>() </span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-58-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Donde vemos cómo en cada iteración se actualiza un solo parámetro.
Una alternativa es conservar únicamente ciclos completos de la
caminata u esto es lo que hacen varios programas que implementan Gibbs, sin
embargo ambas cadenas (cadenas completas y conservando únicamente ciclos
completos) convergen a la misma distribución posterior.</p>
<p>Si tomamos iteraciones completas:</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb636-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(caminata, pasos <span class="sc">&gt;</span> <span class="dv">1000</span>, pasos<span class="sc">&lt;</span> <span class="dv">1020</span>, pasos <span class="sc">%%</span> <span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>), </span>
<span id="cb636-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb636-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma)) <span class="sc">+</span> </span>
<span id="cb636-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb636-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">geom_point</span>() </span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-59-1.png" width="480" style="display: block; margin: auto;" />
Y ahora vemos cómo se ven las simulaciones:</p>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb637-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb637-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(caminata, pasos <span class="sc">&gt;</span> <span class="dv">1000</span>, pasos<span class="sc">&lt;</span> <span class="dv">10000</span>, pasos <span class="sc">%%</span> <span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>), </span>
<span id="cb637-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb637-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma)) <span class="sc">+</span>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.1</span>) </span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-60-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y el diagnóstico de cada cadena:</p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb638-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(caminata_g, pasos <span class="sc">&gt;</span> <span class="dv">15000</span>), <span class="fu">aes</span>(<span class="at">x =</span> pasos, <span class="at">y =</span> val)) <span class="sc">+</span></span>
<span id="cb638-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb638-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb638-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb638-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>parametro, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb638-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb638-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-61-1.png" width="480" style="display: block; margin: auto;" />
Estas cadenas parecen estar mezclando bien. Podemos resumirlas:</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb639-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(caminata_g, pasos <span class="sc">&gt;</span> <span class="dv">5000</span>), <span class="fu">aes</span>(<span class="at">x =</span> val)) <span class="sc">+</span></span>
<span id="cb639-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb639-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>) <span class="sc">+</span></span>
<span id="cb639-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb639-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>parametro, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) </span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-62-1.png" width="384" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-1" aria-hidden="true" tabindex="-1"></a>caminata_g <span class="sc">%&gt;%</span></span>
<span id="cb640-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(pasos <span class="sc">&gt;</span> <span class="dv">1000</span>) <span class="sc">%&gt;%</span> <span class="co"># eliminamos la etapa de calentamiento</span></span>
<span id="cb640-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(parametro) <span class="sc">%&gt;%</span></span>
<span id="cb640-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb640-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(val), </span>
<span id="cb640-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sd</span>(val), </span>
<span id="cb640-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">median</span>(val)</span>
<span id="cb640-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-8" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb640-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb640-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(is_double, round, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   parametro `mean(val)` `sd(val)` `median(val)`
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 mu             176.        1.32        176.  
## 2 sigma            6.54      0.95          6.44</code></pre>
<p>Y obtenemos un resultado similar a los anteriores.</p>
</div>
</div>
<div id="conclusiones-y-observaciones-metrópolis-y-gibbs" class="section level2 unnumbered hasAnchor">
<h2>Conclusiones y observaciones Metrópolis y Gibbs<a href="métodos-de-cadenas-de-markov-monte-carlo.html#conclusiones-y-observaciones-metrópolis-y-gibbs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Una generalización del algoritmo de Metrópolis es Metrópolis-Hastings.</p>
<p>El algoritmo de Metrópolis es como sigue:</p>
<ol style="list-style-type: decimal">
<li>Generamos un punto inicial tal que <span class="math inline">\(p(\theta)&gt;0\)</span>.</li>
<li>Para <span class="math inline">\(i = 1,2,...\)</span>
<ul>
<li>Se propone un nuevo valor <span class="math inline">\(\theta^*\)</span> con una distribución
propuesta <span class="math inline">\(g(\theta^*|\theta^{(i)})\)</span> es común que <span class="math inline">\(g(\theta^*|\theta^{(i)})\)</span> sea una normal centrada en
<span class="math inline">\(\theta^{(i)}\)</span>.</li>
</ul></li>
<li>Calculamos la probabilidad de aceptación</li>
</ol>
<p><span class="math display">\[\alpha=\min\bigg\{\frac{p(\theta^*)}{p(\theta^{(i)})},1\bigg\},\]</span>
y aceptamos <span class="math inline">\(\theta^*\)</span> con probabilidad <span class="math inline">\(p_{mover}\)</span>. Es así que el
algorito requiere que podamos calcular el cociente en <span class="math inline">\(p_{mover}\)</span> para todo
<span class="math inline">\(\theta^{(i)}\)</span> y <span class="math inline">\(\theta^*\)</span>, así como simular de la distribución propuesta
<span class="math inline">\(g(\theta^*|\theta^{(i)})\)</span>, adicionalmente debemos poder generar valores
uniformes para decidir si aceptar/rechazar.</p>
<p>En el caso de <strong>Metrópolis</strong> un requerimiento adicional es que la distribución
propuesta <span class="math inline">\(g(\theta_{a}|\theta_b)\)</span> debe ser simétrica, es decir
<span class="math inline">\(g(\theta_{a}|\theta_b) = g(\theta_{b}|\theta_a)\)</span> para todo <span class="math inline">\(\theta_{a}\)</span>,
<span class="math inline">\(\theta_{b}\)</span>.</p>
<p><strong>Metrópolis-Hastings</strong> generaliza Metrópolis, eliminando la restricción de
simetría en la distribución propuesta <span class="math inline">\(g(\theta_{a}|\theta_b)\)</span>, sin embargo para
corregir por esta asimetría debemos calcular <span class="math inline">\(\alpha\)</span> como sigue:</p>
<p><span class="math display">\[\alpha=\min\bigg\{ \frac{p(\theta^*)}{g(\theta^*|\theta^{(i)})} \cdot  \frac{g(\theta^{(i)}|\theta^*)}{p(\theta^{(i)})},1\bigg\}\]</span>
La generalización de Metrópolis-Hastings puede resultar en algoritmos más
veloces.</p></li>
<li><p>Se puede ver Gibbs como una generalización de Metrópolis-Hastings, cuando
estamos actualizando un componente de los parámetros, la distribución propuesta
es la distribución posterior para ese parámetro, por tanto siempre es aceptado.</p></li>
<li><p>Comparado con Metrópolis, Gibbs tiene la ventaja de que no se necesita afinar
los parámetros de una distribución propuesta (o seleccionar siquiera una
distribución propuesta). Además que no hay pérdida de simulaciones debido a
rechazo. Por su parte, la desventaja debemos conocer las distribuciones
condicionales y poder simular de ellas.</p></li>
<li><p>En el caso de modelos complicados se utilizan combinaciones de Gibbs y
Metrópolis. Cuando se consideran estos dos algoritmos Gibbs es un método más
simple y es la primera opción para modelos condicionalmente conjugados. Sí solo
podemos simular de un subconjunto de las distribuciones condicionales
posteriores, entonces podemos usar Gibbs siempre que se pueda y Metrópolis
unidimensional para el resto, o de manera más general separamos en bloques, un
bloque se actualiza con Gibbs y otro con Metrópolis.</p></li>
<li><p>El algoritmo de Gibbs puede <em>atorarse</em> cuando hay correlación alta entre los
parámetros, reparametrizar puede ayudar, o se pueden usar otros algoritmos.</p></li>
<li><p><a href="http://mcmc-jags.sourceforge.net">JAGS</a> (Just Another Gibbs Sampler), WinBUGS
y OpenBUGS son programas que implementan métodos MCMC para generar simulaciones
de distribuciones posteriores. Los paquetes <code>rjags</code> y <code>R2jags</code> permiten ajustar
modelos en JAGS desde <code>R</code>. Es muy fácil utilizar estos programas pues uno
simplemente debe especificar las distribuciones iniciales, la verosimilitud y
los datos observados. Para aprender a usar JAGS se puede revisar la sección
correspondiente en las <a href="https://tereom.github.io/est-computacional-2018/jags.html">notas de 2018</a>,
ahora nos concentraremos en el uso de Stan.</p></li>
</ul>
</div>
<div id="hmc-y-stan" class="section level2 unnumbered hasAnchor">
<h2>HMC y Stan<a href="métodos-de-cadenas-de-markov-monte-carlo.html#hmc-y-stan" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p>It appears to be quite a general principle that, whenever there is a
randomized way of doinf something, then there is a nonrandomized way that
delivers better performance but requires more thought. -E.T. Jaynes</p>
</blockquote>
<p><code>Stan</code> es un programa para generar muestras de una distribución posterior de los
parámetros de un modelo, el nombre del programa hace referencia a <a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">Stanislaw Ulam (1904-1984)</a> que fue pionero en
los métodos de Monte Carlo. A diferencia de JAGS y BUGS, los pasos de la cadena
de Markov se generan con un método llamado <em>Monte Carlo Hamiltoniano</em> (HMC). HMC
es computacionalmente más costoso que Metrópolis o Gibbs, sin embargo, sus
propuestas suelen ser más eficientes, y por consiguiente no necesita muestras
tan grandes. En particular cuando se ajustan modelos grandes y complejos (por
ejemplo, con variables con correlación alta) HMC supera a otros.</p>
</div>
<div id="diagnósticos-generales-para-mcmc" class="section level2 unnumbered hasAnchor">
<h2>Diagnósticos generales para MCMC<a href="métodos-de-cadenas-de-markov-monte-carlo.html#diagnósticos-generales-para-mcmc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando generamos una muestra de la distribución posterior usando MCMC, sin
importar el método (Metrópolis, Gibbs, HMC), buscamos que:</p>
<ol style="list-style-type: decimal">
<li><p>Los valores simulados sean representativos de la distribución posterior. Esto implica que no deben estar influenciados por el valor inicial (arbitrario) y deben explorar todo el rango de la posterior, con suficientes retornos para evaluar cuánta masa hay en cada región.</p></li>
<li><p>Debemos tener suficientes simulaciones de tal manera que las
estimaciones sean precisas y estables.</p></li>
<li><p>Queremos tener un método eficiente para generar las simulaciones.</p></li>
</ol>
<p>En la práctica intentamos cumplir lo más posible estos objetivos, pues aunque en principio los métodos MCMC garantizan que una cadena infinitamente larga logrará una representación perfecta, siempre debemos tener un criterio para cortar la cadena y evaluar la calidad de las simulaciones.</p>
<div id="representatividad" class="section level3 unnumbered hasAnchor">
<h3>Representatividad<a href="métodos-de-cadenas-de-markov-monte-carlo.html#representatividad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Burn-in e iteraciones iniciales</strong>- En primer lugar, en muchas ocasiones las condiciones iniciales de las
cadenas están en partes del espacio de parámetros que son “atípicos” en
términos de la posterior. Así que es común quitar algunas observaciones
iniciales (iteraciones de <em>burn-in</em>) para minimizar su efecto en
resúmenes posteriores.</p>
<p>Por ejemplo, para el ejemplo de los cantantes, podemos
ver que las iteraciones iniciales tienen como función principal
llegar a las regiones de probabilidad posterior alta:</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb642-1" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="fu">crear_log_posterior_norm</span>(cantantes<span class="sc">$</span>estatura_cm, mu_0, n_0, a, b) </span>
<span id="cb642-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb642-2" aria-hidden="true" tabindex="-1"></a>log_post <span class="ot">&lt;-</span> <span class="cf">function</span>(pars) { <span class="fu">log_p</span>(pars[<span class="dv">1</span>], pars[<span class="dv">2</span>]) }</span>
<span id="cb642-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb642-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">823</span>)</span>
<span id="cb642-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb642-4" aria-hidden="true" tabindex="-1"></a>metro_normal <span class="ot">&lt;-</span> <span class="fu">crear_metropolis</span>(log_post, <span class="at">sigma_salto =</span> <span class="fl">0.5</span>)</span>
<span id="cb642-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb642-5" aria-hidden="true" tabindex="-1"></a>sim_tbl <span class="ot">&lt;-</span> <span class="fu">metro_normal</span>(<span class="fu">c</span>(<span class="at">mu =</span> <span class="dv">162</span>, <span class="at">sigma =</span> <span class="dv">1</span>), <span class="dv">5000</span>) </span>
<span id="cb642-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb642-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">500</span>), <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> sigma)) <span class="sc">+</span> <span class="fu">geom_path</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">colour =</span> iter_num))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-64-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>De modo que puede ser buena idea eliminar las
primeras iteraciones. En teoría, no es necesario hacer esto si
hacemos suficientes iteraciones, pues la cadena va a terminar
en su estado estable explorando la posterior. En la práctica, y
con pocas iteraciones, puede ayudar un poco a mejorar la precisión
numérica de las cantidades que queramos calcular.</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-1" aria-hidden="true" tabindex="-1"></a>sim_g <span class="ot">&lt;-</span> sim_tbl <span class="sc">%&gt;%</span> <span class="fu">pivot_longer</span>(<span class="sc">-</span>iter_num, </span>
<span id="cb643-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-2" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">names_to =</span> <span class="st">&quot;parametro&quot;</span>,</span>
<span id="cb643-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-3" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">values_to =</span> <span class="st">&quot;valor&quot;</span>)</span>
<span id="cb643-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-4" aria-hidden="true" tabindex="-1"></a>todas <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sim_g, <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> valor)) <span class="sc">+</span></span>
<span id="cb643-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb643-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> parametro, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="sc">+</span></span>
<span id="cb643-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Todas las simulaciones&quot;</span>)</span>
<span id="cb643-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-8" aria-hidden="true" tabindex="-1"></a>sin_burnin <span class="ot">&lt;-</span> </span>
<span id="cb643-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-9" aria-hidden="true" tabindex="-1"></a>  sim_g <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&gt;</span> <span class="dv">200</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb643-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> valor)) <span class="sc">+</span></span>
<span id="cb643-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb643-12"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> parametro, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="sc">+</span></span>
<span id="cb643-13"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Quitando 200 de burn-in&quot;</span>)</span>
<span id="cb643-14"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb643-14" aria-hidden="true" tabindex="-1"></a>todas <span class="sc">+</span> sin_burnin</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-65-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>Convergencia a estado límite</strong>. Para determinar la convergencia es conveniente
realizar <strong>más de una cadena</strong>: buscamos ver si realmente se ha olvidado el
estado inicial, si las distribuciones de cada cadena son consistentes unas con
otras, y revisar que algunas cadenas no hayan quedado <em>atoradas</em> en regiones
inusuales del espacio de parámetros.</p>
<p>Inicializamos las cadenas con valores al azar en rangos
razonables (por ejemplo simulando de la inicial):</p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb644-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8513</span>)</span>
<span id="cb644-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-2" aria-hidden="true" tabindex="-1"></a>valores_iniciales  <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">mu_0 =</span> <span class="fu">rnorm</span>(<span class="dv">4</span>, <span class="dv">160</span>, <span class="dv">20</span>), </span>
<span id="cb644-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">sigma_0 =</span> <span class="fu">runif</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">20</span>),</span>
<span id="cb644-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">cadena =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb644-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-5" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="ot">&lt;-</span> valores_iniciales <span class="sc">%&gt;%</span> </span>
<span id="cb644-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sims =</span> <span class="fu">map2</span>(mu_0, sigma_0, </span>
<span id="cb644-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> <span class="fu">metro_normal</span>(<span class="fu">c</span>(<span class="at">mu =</span> .x, <span class="at">sigma =</span> .y), <span class="dv">300</span>) )) <span class="sc">%&gt;%</span> </span>
<span id="cb644-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(sims)</span>
<span id="cb644-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb644-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sims_tbl, <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> sigma, <span class="at">colour =</span> <span class="fu">factor</span>(cadena))) <span class="sc">+</span></span>
<span id="cb644-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb644-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-66-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y este es un ejemplo donde claramente las cadenas <strong>no</strong> han alcanzado
un estado estable: tienen muy distintas medias y varianzas. Por ejemplo:</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">83243</span>)</span>
<span id="cb645-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-2" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="ot">&lt;-</span> valores_iniciales <span class="sc">%&gt;%</span> </span>
<span id="cb645-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sims =</span> <span class="fu">map2</span>(mu_0, sigma_0, </span>
<span id="cb645-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-4" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> <span class="fu">metro_normal</span>(<span class="fu">c</span>(<span class="at">mu =</span> .x, <span class="at">sigma =</span> .y), <span class="dv">20000</span>) )) <span class="sc">%&gt;%</span> </span>
<span id="cb645-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(sims)</span>
<span id="cb645-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb645-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sims_tbl, <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> sigma, <span class="at">colour =</span> <span class="fu">factor</span>(cadena))) <span class="sc">+</span></span>
<span id="cb645-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb645-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-67-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Y este resultado se ve mejor. La parte <em>transición</em> hacia las zonas
de alta probabilidad pasa antes de unas 1000 iteraciones. Podemos
hacer más simulaciones, o eliminar como <em>burn-in</em> las primiras iteraciones:</p>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-1" aria-hidden="true" tabindex="-1"></a>media_g <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&gt;</span> <span class="dv">2000</span>),</span>
<span id="cb646-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-2" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> mu, <span class="at">colour =</span> <span class="fu">factor</span>(cadena))) <span class="sc">+</span></span>
<span id="cb646-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span>
<span id="cb646-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-4" aria-hidden="true" tabindex="-1"></a>sigma_g <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sims_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(iter_num <span class="sc">&gt;</span> <span class="dv">2000</span>),</span>
<span id="cb646-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-5" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">aes</span>(<span class="at">x =</span> iter_num, <span class="at">y =</span> sigma, <span class="at">colour =</span> <span class="fu">factor</span>(cadena))) <span class="sc">+</span></span>
<span id="cb646-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span>
<span id="cb646-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb646-7" aria-hidden="true" tabindex="-1"></a>media_g <span class="sc">/</span> sigma_g</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-68-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Las gráficas anteriores nos ayudan a determinar si elegimos un periodo de
calentamiento adecuado o si alguna cadena está alejada del resto.</p>
<p>Una vez que las cadenas están en estado estable, podemos usar
<strong>todas</strong> las simulaciones juntas para resumir:</p>
<div class="sourceCode" id="cb647"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb647-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb647-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(sims_tbl)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 6
##    mu_0 sigma_0 cadena iter_num    mu sigma
##   &lt;dbl&gt;   &lt;dbl&gt;  &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  155.    3.16      1        1  155.  3.16
## 2  155.    3.16      1        2  155.  3.16
## 3  155.    3.16      1        3  155.  3.16
## 4  155.    3.16      1        4  155.  3.16
## 5  155.    3.16      1        5  155.  3.50
## 6  155.    3.16      1        6  155.  3.81</code></pre>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb649-1" aria-hidden="true" tabindex="-1"></a><span class="co"># medias posteriores</span></span>
<span id="cb649-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb649-2" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb649-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb649-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mu =</span> <span class="fu">mean</span>(mu), <span class="at">sigma =</span> <span class="fu">mean</span>(sigma))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##      mu sigma
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  176.  6.77</code></pre>
<p>Además de realizar gráficas podemos usar la medida de convergencia <span class="math inline">\(\hat{R}\)</span>. La medida <span class="math inline">\(\hat{R}\)</span> se conoce como el <strong>factor de reducción potencial de
escala</strong> o <em>diagnóstico de convergencia de Gelman-Rubin</em>, esta es una estimación
de la posible reducción en la longitud de un intervalo de confianza si las
simulaciones continuaran infinitamente. <span class="math inline">\(\hat{R}\)</span> es aproximadamente la raíz
cuadrada de la varianza de todas las
cadenas juntas dividida entre la varianza dentro de cada cadena. Si <span class="math inline">\(\hat{R}\)</span> es
mucho mayor a 1 esto indica que las cadenas no se han mezclado bien. Una regla
usual es iterar hasta alcanzar un valor <span class="math inline">\(\hat{R} \leq 1.1\)</span> para todos los
parámetros.</p>
<p><span class="math display">\[\hat{R} \approx \sqrt{\frac{\hat{V}}{W}}\]</span></p>
<p>donde <span class="math inline">\(B\)</span> es la varianza entre las cadenas, <span class="math inline">\(W\)</span> es la varianza dentro de las cadenas</p>
<p><span class="math display">\[B = \frac{N}{M-1}\sum_m (\hat{\theta}_m - \hat{\theta})^2\]</span>
<span class="math display">\[W = \frac{1}{M}\sum_m \hat{\sigma}_m^2\]</span></p>
<p>Y <span class="math inline">\(\hat{V}\)</span> es una estimación del varianza de posterior de <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\hat{V} = \frac{N-1}{N}W + \frac{M+1}{MN}B\]</span>
#### Ejemplo {-}
En nuestro ejemplo anterior, tenemos</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-1" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb651-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(mu<span class="sc">:</span>sigma, <span class="at">names_to =</span> <span class="st">&quot;parametro&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;valor&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb651-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(parametro, cadena) <span class="sc">%&gt;%</span> </span>
<span id="cb651-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">media =</span> <span class="fu">mean</span>(valor), <span class="at">num =</span> <span class="fu">n</span>(), <span class="at">sigma2 =</span> <span class="fu">var</span>(valor)) <span class="sc">%&gt;%</span> </span>
<span id="cb651-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">N =</span> <span class="fu">first</span>(num),</span>
<span id="cb651-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">M =</span> <span class="fu">n_distinct</span>(cadena), </span>
<span id="cb651-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">B =</span> N <span class="sc">*</span> <span class="fu">var</span>(media),</span>
<span id="cb651-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">W =</span> <span class="fu">mean</span>(sigma2),</span>
<span id="cb651-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">V_hat =</span> ((N <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> N) <span class="sc">*</span> W <span class="sc">+</span> (M <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">/</span>(M <span class="sc">*</span> N) <span class="sc">*</span> B, </span>
<span id="cb651-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb651-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">R_hat =</span> <span class="fu">sqrt</span>(V_hat <span class="sc">/</span> W))  </span></code></pre></div>
<pre><code>## # A tibble: 2 × 7
##   parametro     N     M     B     W V_hat R_hat
##   &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 mu        20000     4 1281.  4.29  4.37  1.01
## 2 sigma     20000     4  121.  1.31  1.32  1.00</code></pre>
<p>Y verificamos que los valores de <span class="math inline">\(\hat{R}\)</span> son cercanos a uno, lo
cual indica que este diagnóstico es aceptable. Si hubiéramos
trabajado con las primeras 300 iteraciones</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-1" aria-hidden="true" tabindex="-1"></a>sims_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb653-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iter_num <span class="sc">&lt;</span> <span class="dv">300</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb653-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(mu<span class="sc">:</span>sigma, <span class="at">names_to =</span> <span class="st">&quot;parametro&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;valor&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb653-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(parametro, cadena) <span class="sc">%&gt;%</span> </span>
<span id="cb653-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">media =</span> <span class="fu">mean</span>(valor), <span class="at">num =</span> <span class="fu">n</span>(), <span class="at">sigma2 =</span> <span class="fu">var</span>(valor)) <span class="sc">%&gt;%</span> </span>
<span id="cb653-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">N =</span> <span class="fu">first</span>(num),</span>
<span id="cb653-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">M =</span> <span class="fu">n_distinct</span>(cadena), </span>
<span id="cb653-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">B =</span> N <span class="sc">*</span> <span class="fu">var</span>(media),</span>
<span id="cb653-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">W =</span> <span class="fu">mean</span>(sigma2),</span>
<span id="cb653-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">V_hat =</span> ((N <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> N) <span class="sc">*</span> W <span class="sc">+</span> (M <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">/</span>(M <span class="sc">*</span> N) <span class="sc">*</span> B, </span>
<span id="cb653-11"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb653-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">R_hat =</span> <span class="fu">sqrt</span>(V_hat <span class="sc">/</span> W))  </span></code></pre></div>
<pre><code>## # A tibble: 2 × 7
##   parametro     N     M      B     W V_hat R_hat
##   &lt;chr&gt;     &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 mu          299     4 32334.  40.4 175.   2.08
## 2 sigma       299     4  7394.  11.9  42.8  1.89</code></pre>
<p>Y estos valores indican problemas en la convergencia de las cadenas. Es
necesario diagnosticar el problema, que en este caso resolvemos
incrementando el número de iteraciones.</p>
</div>
<div id="precisión" class="section level3 unnumbered hasAnchor">
<h3>Precisión<a href="métodos-de-cadenas-de-markov-monte-carlo.html#precisión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez que tenemos una muestra representativa de la
distribución posterior, nuestro objetivo es asegurarnos de que la muestra es lo suficientemente grande
para producir estimaciones estables y precisas de la distribución.</p>
<p>Para ello usaremos el
<strong>tamaño efectivo de muestra</strong>, Si las simulaciones fueran independientes
<span class="math inline">\(N_{eff}\)</span> sería el número total de simulaciones; sin embargo, las simulaciones de MCMC suelen estar correlacionadas, de modo que cada iteración
de MCMC es menos informativa que si fueran independientes.</p>
<p><strong>Ejemplo</strong>: Si graficaramos simulaciones independientes, esperaríamos valores de
autocorrelación chicos:</p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb655-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(<span class="fu">rgamma</span>(<span class="dv">1000</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-72-1.png" width="480" style="display: block; margin: auto;" />
Sin embargo, los valores que simulamos tienen el siguiente perfil de
autocorrelación:</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb656-1" aria-hidden="true" tabindex="-1"></a>sigma_metro_sims <span class="ot">&lt;-</span> sims_tbl <span class="sc">%&gt;%</span> <span class="fu">filter</span>(cadena<span class="sc">==</span><span class="dv">4</span>) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(mu)</span>
<span id="cb656-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb656-2" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(sigma_metro_sims)</span></code></pre></div>
<p><img src="16-bayes-mcmc_files/figure-html/unnamed-chunk-73-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>El tamaño efectivo de muestra nos dice qué tamaño de
muestra de observaciones independientes nos daría la misma información que las
simulaciones de la cadena. Una manera de manera relativamente simple de
estimarlo es:</p>
<p><span class="math display">\[N_{eff} = \frac{N}{1+2\sum_{k=1}^\infty ACF(k)} \]</span></p>
<p>Usualmente nos gustaría obtener un tamaño efectivo de al menos <span class="math inline">\(100\)</span> (para
cálculo de medias y varianzas posteriores). Esta
cantidad usualmente se reporta en el software (con mejores estimaciones que
la de la fórmula de arriba), y es necesario checarlo.</p>
<p>En nuestro ejemplo hacemos una aproximación como sigue:</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-1" aria-hidden="true" tabindex="-1"></a>calc_acf <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb657-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-2" aria-hidden="true" tabindex="-1"></a>  valores_acf <span class="ot">&lt;-</span> <span class="fu">acf</span>(x, <span class="at">lag.max =</span> <span class="dv">1000</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>acf <span class="sc">%&gt;%</span> <span class="fu">as.numeric</span>()</span>
<span id="cb657-3"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-3" aria-hidden="true" tabindex="-1"></a>  valores_acf[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb657-4"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb657-5"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-5" aria-hidden="true" tabindex="-1"></a>acf_tbl <span class="ot">&lt;-</span> sims_tbl <span class="sc">%&gt;%</span> </span>
<span id="cb657-6"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(mu<span class="sc">:</span>sigma, <span class="at">names_to =</span> <span class="st">&quot;parametro&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;valor&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb657-7"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(parametro, cadena) <span class="sc">%&gt;%</span></span>
<span id="cb657-8"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">N =</span> <span class="fu">n_distinct</span>(iter_num), <span class="at">k =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>, <span class="at">acf =</span> <span class="fu">calc_acf</span>(valor)) <span class="sc">%&gt;%</span> </span>
<span id="cb657-9"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">N =</span> <span class="fu">first</span>(N), <span class="at">N_eff =</span> N <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(acf)))</span>
<span id="cb657-10"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb657-10" aria-hidden="true" tabindex="-1"></a>acf_tbl</span></code></pre></div>
<pre><code>## # A tibble: 8 × 4
## # Groups:   parametro [2]
##   parametro cadena     N N_eff
##   &lt;chr&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
## 1 mu             1 20000 251. 
## 2 mu             2 20000 700. 
## 3 mu             3 20000 104. 
## 4 mu             4 20000 394. 
## 5 sigma          1 20000 421. 
## 6 sigma          2 20000 411. 
## 7 sigma          3 20000  93.9
## 8 sigma          4 20000 724.</code></pre>
<p>Nótese que algunas cadenas tienen un tamaño efectivo de muestra relativamente
bajo para el número de iteraciones que hicimos. De cualquier forma, el agregado
sobre todas las cadenas es suficientemente grande para calcular resúmenes básicos:</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb659-1" aria-hidden="true" tabindex="-1"></a>acf_tbl <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(parametro) <span class="sc">%&gt;%</span> </span>
<span id="cb659-2"><a href="métodos-de-cadenas-de-markov-monte-carlo.html#cb659-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">N =</span> <span class="fu">sum</span>(N), <span class="at">N_eff =</span> <span class="fu">sum</span>(N_eff))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   parametro     N N_eff
##   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;
## 1 mu        80000 1450.
## 2 sigma     80000 1650.</code></pre>
<p>Sin embargo, podemos hacer más simulaciones si es necesario, por ejemplo
para aproximar de manera apropiada percentiles en las colas.</p>
</div>
<div id="eficiencia" class="section level3 unnumbered hasAnchor">
<h3>Eficiencia<a href="métodos-de-cadenas-de-markov-monte-carlo.html#eficiencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hay varias maneras para mejorar la eficiencia de un proceso MCMC:</p>
<ul>
<li><p>Paralelizar, no disminuimos el número de pasos en las simulaciones pero
podemos disminuir el tiempo que tarda en correr.</p></li>
<li><p>Cambiar la parametrización del modelo o transformar los datos.</p></li>
<li><p>Adelgazar la muestra cuando tenemos problemas de uso de memoria,</p></li>
</ul>
<p>consiste en guardar únicamente los <span class="math inline">\(k\)</span>-ésimos pasos de la cadena y resulta
en cadenas con menos autocorrelación .</p>
</div>
<div id="recomendaciones-generales" class="section level3 unnumbered hasAnchor">
<h3>Recomendaciones generales<a href="métodos-de-cadenas-de-markov-monte-carlo.html#recomendaciones-generales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="citation">Gelman and Hill (<a href="#ref-gelman-hill" role="doc-biblioref">2006</a>)</span> recomienda los siguientes pasos cuando uno esta simulando de la
posterior:</p>
<ol style="list-style-type: decimal">
<li><p>Cuando definimos un modelo por primera vez establecemos un valor bajo para
el número de iteraciones. La razón es que la mayor parte de las veces los
modelos no funcionan a la primera por lo que sería pérdida de tiempo dejarlo
correr mucho tiempo antes de descubrir el problema.</p></li>
<li><p>Si las simulaciones no han alcanzado convergencia aumentamos las iteraciones
a <span class="math inline">\(500\)</span> ó <span class="math inline">\(1000\)</span> de tal forma que las corridas tarden segundos o unos cuantos
minutos.</p></li>
<li><p>Si tarda más que unos cuantos minutos (para problemas del tamaño que
veremos en la clase) y aún así no alcanza convergencia
entonces <em>juega</em> un poco con el modelo (por ejemplo intenta transformaciones lineales), para JAGS Gelman
sugiere más técnicas para acelerar la convergencia en el
capitulo <span class="math inline">\(19\)</span> del libro
<em>Data Analysis Using Regression and Multilevel/Hierarchical models</em>. En el
caso de Stan veremos ejemplos de reparametrización, y se puede leer más en
la <a href="https://mc-stan.org/docs/2_21/stan-users-guide/reparameterization-section.html">guía</a>.</p></li>
<li><p>Otra técnica conveniente cuando se trabaja con bases de datos grandes
(sobre todo en la parte exploratoria) es trabajar con un
subconjunto de los datos, quizá la mitad o una quinta parte.</p></li>
</ol>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gelman-hill" class="csl-entry">
Gelman, Andrew, and Jennifer Hill. 2006. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. 1st ed. Cambridge University Press. <a href="http://www.amazon.com/Analysis-Regression-Multilevel-Hierarchical-Models/dp/052168689X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1313405184&amp;sr=1-1">http://www.amazon.com/Analysis-Regression-Multilevel-Hierarchical-Models/dp/052168689X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1313405184&amp;sr=1-1</a>.
</div>
<div id="ref-Kruschke" class="csl-entry">
Kruschke, John. 2015. <em>Doing Bayesian Data Analysis (Second Edition)</em>. Academic Press.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="calibración-bayesiana-y-regularización.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="apéndice-principios-de-visualizacion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/16-bayes-mcmc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["fundamentos-estadistica.Rmd"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"depth": 1
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
